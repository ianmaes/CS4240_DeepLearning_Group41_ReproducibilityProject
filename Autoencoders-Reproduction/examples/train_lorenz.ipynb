{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_lorenz import get_lorenz_data\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate training, validation, testing data\n",
    "noise_strength = 1e-6\n",
    "training_data = get_lorenz_data(1024, noise_strength=noise_strength)\n",
    "validation_data = get_lorenz_data(20, noise_strength=noise_strength)\n",
    "training_data['x'] = torch.tensor(training_data['x']).float()\n",
    "training_data['dx'] = torch.tensor(training_data['dx']).float()\n",
    "training_data['t'] = torch.tensor(training_data['t']).float()\n",
    "training_data['z'] = torch.tensor(training_data['z']).float()\n",
    "training_data['dz'] = torch.tensor(training_data['dz']).float()\n",
    "\n",
    "\n",
    "validation_data['x'] = torch.tensor(validation_data['x']).float()\n",
    "validation_data['dx'] = torch.tensor(validation_data['dx']).float()\n",
    "validation_data['t'] = torch.tensor(validation_data['t']).float()\n",
    "validation_data['z'] = torch.tensor(validation_data['z']).float()\n",
    "validation_data['dz'] = torch.tensor(validation_data['dz']).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 64]\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "\n",
    "params['input_dim'] = 128\n",
    "params['latent_dim'] = 3\n",
    "params['model_order'] = 1\n",
    "params['poly_order'] = 3\n",
    "params['include_sine'] = False\n",
    "params['library_dim'] = library_size(params['latent_dim'], params['poly_order'], params['include_sine'], True)\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = True\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 500\n",
    "params['coefficient_mask'] = torch.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_z'] = 0\n",
    "params['loss_weight_sindy_x'] = 1e-4\n",
    "params['loss_weight_sindy_regularization'] = 1e-5\n",
    "\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [64,32]\n",
    "print(params['widths'][::-1])\n",
    "# training parameters\n",
    "params['epoch_size'] = training_data['x'].shape[0]\n",
    "params['batch_size'] = 1024\n",
    "params['learning_rate'] = 1e-3\n",
    "\n",
    "params['data_path'] = os.getcwd() + '/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 1\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 5001\n",
    "params['refinement_epochs'] = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:164: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'x': torch.tensor(data['x'][idxs], dtype=torch.float32),\n",
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:165: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'dx': torch.tensor(data['dx'][idxs], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_total_loss, train_losses, _ = network.define_loss( torch.tensor(train_dict['x'], dtype=torch.float32) , torch.tensor(train_dict['dx'], dtype=torch.float32), params=params)\n",
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_total_loss, val_losses, _ = network.define_loss( torch.tensor(validation_dict['x'], dtype=torch.float32), torch.tensor(validation_dict['dx'], dtype=torch.float32),  params=params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "   Training Total Loss: 0.03638455644249916\n",
      "   Training decoder Loss: 0.03519994020462036\n",
      "   Training sindy_z Loss: 182.57476806640625\n",
      "   Training sindy_x Loss: 11.764410018920898\n",
      "   Training sindy_regularization Loss: 0.8177505135536194\n",
      "   Validation Total Loss: 0.044518351554870605\n",
      "   Validation decoder Loss: 0.04307567700743675\n",
      "   Validation sindy_z Loss: 194.98289489746094\n",
      "   Validation sindy_x Loss: 14.344962120056152\n",
      "   Validation sindy_regularization Loss: 0.8177505135536194\n",
      "Decoder Loss Ratio: 0.221707, Decoder SINDy Loss Ratio: 0.999057\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "   Training Total Loss: 0.028193293139338493\n",
      "   Training decoder Loss: 0.027033640071749687\n",
      "   Training sindy_z Loss: 119.98314666748047\n",
      "   Training sindy_x Loss: 11.52031135559082\n",
      "   Training sindy_regularization Loss: 0.7621705532073975\n",
      "   Validation Total Loss: 0.03528674319386482\n",
      "   Validation decoder Loss: 0.033872924745082855\n",
      "   Validation sindy_z Loss: 140.07217407226562\n",
      "   Validation sindy_x Loss: 14.061970710754395\n",
      "   Validation sindy_regularization Loss: 0.7621705532073975\n",
      "Decoder Loss Ratio: 0.174341, Decoder SINDy Loss Ratio: 0.979348\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "   Training Total Loss: 0.012715580873191357\n",
      "   Training decoder Loss: 0.01158958300948143\n",
      "   Training sindy_z Loss: 149.44229125976562\n",
      "   Training sindy_x Loss: 11.184774398803711\n",
      "   Training sindy_regularization Loss: 0.7520260214805603\n",
      "   Validation Total Loss: 0.016261707991361618\n",
      "   Validation decoder Loss: 0.01489238254725933\n",
      "   Validation sindy_z Loss: 172.41510009765625\n",
      "   Validation sindy_x Loss: 13.618062973022461\n",
      "   Validation sindy_regularization Loss: 0.7520260214805603\n",
      "Decoder Loss Ratio: 0.076650, Decoder SINDy Loss Ratio: 0.948432\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "   Training Total Loss: 0.01011604256927967\n",
      "   Training decoder Loss: 0.009009978733956814\n",
      "   Training sindy_z Loss: 139.96290588378906\n",
      "   Training sindy_x Loss: 10.981939315795898\n",
      "   Training sindy_regularization Loss: 0.7870082259178162\n",
      "   Validation Total Loss: 0.012723882682621479\n",
      "   Validation decoder Loss: 0.01138310506939888\n",
      "   Validation sindy_z Loss: 161.90057373046875\n",
      "   Validation sindy_x Loss: 13.329081535339355\n",
      "   Validation sindy_regularization Loss: 0.7870082259178162\n",
      "Decoder Loss Ratio: 0.058588, Decoder SINDy Loss Ratio: 0.928306\n",
      "Epoch 4\n",
      "Epoch 4\n",
      "   Training Total Loss: 0.00921077560633421\n",
      "   Training decoder Loss: 0.008118903264403343\n",
      "   Training sindy_z Loss: 132.01979064941406\n",
      "   Training sindy_x Loss: 10.834282875061035\n",
      "   Training sindy_regularization Loss: 0.8444064259529114\n",
      "   Validation Total Loss: 0.011482435278594494\n",
      "   Validation decoder Loss: 0.010165589861571789\n",
      "   Validation sindy_z Loss: 151.2029571533203\n",
      "   Validation sindy_x Loss: 13.08401107788086\n",
      "   Validation sindy_regularization Loss: 0.8444064259529114\n",
      "Decoder Loss Ratio: 0.052321, Decoder SINDy Loss Ratio: 0.911238\n",
      "Epoch 5\n",
      "Epoch 5\n",
      "   Training Total Loss: 0.008439482189714909\n",
      "   Training decoder Loss: 0.007360758259892464\n",
      "   Training sindy_z Loss: 130.02154541015625\n",
      "   Training sindy_x Loss: 10.69747257232666\n",
      "   Training sindy_regularization Loss: 0.8976672291755676\n",
      "   Validation Total Loss: 0.01047228928655386\n",
      "   Validation decoder Loss: 0.009180505760014057\n",
      "   Validation sindy_z Loss: 147.31149291992188\n",
      "   Validation sindy_x Loss: 12.828069686889648\n",
      "   Validation sindy_regularization Loss: 0.8976672291755676\n",
      "Decoder Loss Ratio: 0.047251, Decoder SINDy Loss Ratio: 0.893413\n",
      "Epoch 6\n",
      "Epoch 6\n",
      "   Training Total Loss: 0.007796375080943108\n",
      "   Training decoder Loss: 0.006730943452566862\n",
      "   Training sindy_z Loss: 128.53807067871094\n",
      "   Training sindy_x Loss: 10.558684349060059\n",
      "   Training sindy_regularization Loss: 0.9563102722167969\n",
      "   Validation Total Loss: 0.00963059812784195\n",
      "   Validation decoder Loss: 0.008364749141037464\n",
      "   Validation sindy_z Loss: 144.63739013671875\n",
      "   Validation sindy_x Loss: 12.562862396240234\n",
      "   Validation sindy_regularization Loss: 0.9563102722167969\n",
      "Decoder Loss Ratio: 0.043053, Decoder SINDy Loss Ratio: 0.874942\n",
      "Epoch 7\n",
      "Epoch 7\n",
      "   Training Total Loss: 0.007221712730824947\n",
      "   Training decoder Loss: 0.006171511020511389\n",
      "   Training sindy_z Loss: 126.59188079833984\n",
      "   Training sindy_x Loss: 10.399940490722656\n",
      "   Training sindy_regularization Loss: 1.0207850933074951\n",
      "   Validation Total Loss: 0.008941331878304482\n",
      "   Validation decoder Loss: 0.007700893562287092\n",
      "   Validation sindy_z Loss: 142.53843688964844\n",
      "   Validation sindy_x Loss: 12.3023042678833\n",
      "   Validation sindy_regularization Loss: 1.0207850933074951\n",
      "Decoder Loss Ratio: 0.039636, Decoder SINDy Loss Ratio: 0.856796\n",
      "Epoch 8\n",
      "Epoch 8\n",
      "   Training Total Loss: 0.006665565073490143\n",
      "   Training decoder Loss: 0.005630229599773884\n",
      "   Training sindy_z Loss: 120.74822998046875\n",
      "   Training sindy_x Loss: 10.245512008666992\n",
      "   Training sindy_regularization Loss: 1.0784339904785156\n",
      "   Validation Total Loss: 0.008300431072711945\n",
      "   Validation decoder Loss: 0.007079225033521652\n",
      "   Validation sindy_z Loss: 137.0816192626953\n",
      "   Validation sindy_x Loss: 12.104208946228027\n",
      "   Validation sindy_regularization Loss: 1.0784339904785156\n",
      "Decoder Loss Ratio: 0.036436, Decoder SINDy Loss Ratio: 0.842999\n",
      "Epoch 9\n",
      "Epoch 9\n",
      "   Training Total Loss: 0.005188586190342903\n",
      "   Training decoder Loss: 0.00418432243168354\n",
      "   Training sindy_z Loss: 107.38500213623047\n",
      "   Training sindy_x Loss: 9.929637908935547\n",
      "   Training sindy_regularization Loss: 1.1299817562103271\n",
      "   Validation Total Loss: 0.006564246490597725\n",
      "   Validation decoder Loss: 0.0053748032078146935\n",
      "   Validation sindy_z Loss: 125.32730865478516\n",
      "   Validation sindy_x Loss: 11.7814359664917\n",
      "   Validation sindy_regularization Loss: 1.1299817562103271\n",
      "Decoder Loss Ratio: 0.027664, Decoder SINDy Loss Ratio: 0.820520\n",
      "Epoch 10\n",
      "Epoch 10\n",
      "   Training Total Loss: 0.0035279931034892797\n",
      "   Training decoder Loss: 0.0025442447513341904\n",
      "   Training sindy_z Loss: 88.14862060546875\n",
      "   Training sindy_x Loss: 9.719820022583008\n",
      "   Training sindy_regularization Loss: 1.176640272140503\n",
      "   Validation Total Loss: 0.004425074439495802\n",
      "   Validation decoder Loss: 0.0032651866786181927\n",
      "   Validation sindy_z Loss: 104.00607299804688\n",
      "   Validation sindy_x Loss: 11.481215476989746\n",
      "   Validation sindy_regularization Loss: 1.176640272140503\n",
      "Decoder Loss Ratio: 0.016806, Decoder SINDy Loss Ratio: 0.799611\n",
      "Epoch 11\n",
      "Epoch 11\n",
      "   Training Total Loss: 0.0027801969554275274\n",
      "   Training decoder Loss: 0.0018004344310611486\n",
      "   Training sindy_z Loss: 72.30461883544922\n",
      "   Training sindy_x Loss: 9.6749267578125\n",
      "   Training sindy_regularization Loss: 1.2269841432571411\n",
      "   Validation Total Loss: 0.00349582452327013\n",
      "   Validation decoder Loss: 0.0023459140211343765\n",
      "   Validation sindy_z Loss: 85.07691192626953\n",
      "   Validation sindy_x Loss: 11.376405715942383\n",
      "   Validation sindy_regularization Loss: 1.2269841432571411\n",
      "Decoder Loss Ratio: 0.012074, Decoder SINDy Loss Ratio: 0.792311\n",
      "Epoch 12\n",
      "Epoch 12\n",
      "   Training Total Loss: 0.00247446121647954\n",
      "   Training decoder Loss: 0.0015032074879854918\n",
      "   Training sindy_z Loss: 64.05672454833984\n",
      "   Training sindy_x Loss: 9.584700584411621\n",
      "   Training sindy_regularization Loss: 1.2783876657485962\n",
      "   Validation Total Loss: 0.003050271887332201\n",
      "   Validation decoder Loss: 0.0019170234445482492\n",
      "   Validation sindy_z Loss: 75.2284164428711\n",
      "   Validation sindy_x Loss: 11.204645156860352\n",
      "   Validation sindy_regularization Loss: 1.2783876657485962\n",
      "Decoder Loss Ratio: 0.009867, Decoder SINDy Loss Ratio: 0.780349\n",
      "Epoch 13\n",
      "Epoch 13\n",
      "   Training Total Loss: 0.0023478351067751646\n",
      "   Training decoder Loss: 0.0013915447052568197\n",
      "   Training sindy_z Loss: 60.721065521240234\n",
      "   Training sindy_x Loss: 9.430805206298828\n",
      "   Training sindy_regularization Loss: 1.3209834098815918\n",
      "   Validation Total Loss: 0.0028355377726256847\n",
      "   Validation decoder Loss: 0.001729302224703133\n",
      "   Validation sindy_z Loss: 71.12715148925781\n",
      "   Validation sindy_x Loss: 10.930257797241211\n",
      "   Validation sindy_regularization Loss: 1.3209834098815918\n",
      "Decoder Loss Ratio: 0.008901, Decoder SINDy Loss Ratio: 0.761239\n",
      "Epoch 14\n",
      "Epoch 14\n",
      "   Training Total Loss: 0.0021201292984187603\n",
      "   Training decoder Loss: 0.0011834684992209077\n",
      "   Training sindy_z Loss: 57.30961608886719\n",
      "   Training sindy_x Loss: 9.229843139648438\n",
      "   Training sindy_regularization Loss: 1.3676506280899048\n",
      "   Validation Total Loss: 0.0025605368427932262\n",
      "   Validation decoder Loss: 0.0014844315592199564\n",
      "   Validation sindy_z Loss: 67.18598175048828\n",
      "   Validation sindy_x Loss: 10.624287605285645\n",
      "   Validation sindy_regularization Loss: 1.3676506280899048\n",
      "Decoder Loss Ratio: 0.007640, Decoder SINDy Loss Ratio: 0.739930\n",
      "Epoch 15\n",
      "Epoch 15\n",
      "   Training Total Loss: 0.00201799557544291\n",
      "   Training decoder Loss: 0.001106842653825879\n",
      "   Training sindy_z Loss: 53.37417221069336\n",
      "   Training sindy_x Loss: 8.969807624816895\n",
      "   Training sindy_regularization Loss: 1.4172170162200928\n",
      "   Validation Total Loss: 0.0024250149726867676\n",
      "   Validation decoder Loss: 0.00138366362079978\n",
      "   Validation sindy_z Loss: 63.87752151489258\n",
      "   Validation sindy_x Loss: 10.2717924118042\n",
      "   Validation sindy_regularization Loss: 1.4172170162200928\n",
      "Decoder Loss Ratio: 0.007122, Decoder SINDy Loss Ratio: 0.715380\n",
      "Epoch 16\n",
      "Epoch 16\n",
      "   Training Total Loss: 0.0019221918191760778\n",
      "   Training decoder Loss: 0.0010418823221698403\n",
      "   Training sindy_z Loss: 48.83486557006836\n",
      "   Training sindy_x Loss: 8.656728744506836\n",
      "   Training sindy_regularization Loss: 1.4636662006378174\n",
      "   Validation Total Loss: 0.00230782525613904\n",
      "   Validation decoder Loss: 0.001302865450270474\n",
      "   Validation sindy_z Loss: 60.642818450927734\n",
      "   Validation sindy_x Loss: 9.903231620788574\n",
      "   Validation sindy_regularization Loss: 1.4636662006378174\n",
      "Decoder Loss Ratio: 0.006706, Decoder SINDy Loss Ratio: 0.689712\n",
      "Epoch 17\n",
      "Epoch 17\n",
      "   Training Total Loss: 0.0018402537098154426\n",
      "   Training decoder Loss: 0.0009929925436154008\n",
      "   Training sindy_z Loss: 44.07539367675781\n",
      "   Training sindy_x Loss: 8.321643829345703\n",
      "   Training sindy_regularization Loss: 1.509690761566162\n",
      "   Validation Total Loss: 0.0022113441955298185\n",
      "   Validation decoder Loss: 0.001242583035491407\n",
      "   Validation sindy_z Loss: 57.10682678222656\n",
      "   Validation sindy_x Loss: 9.536641120910645\n",
      "   Validation sindy_regularization Loss: 1.509690761566162\n",
      "Decoder Loss Ratio: 0.006395, Decoder SINDy Loss Ratio: 0.664181\n",
      "Epoch 18\n",
      "Epoch 18\n",
      "   Training Total Loss: 0.0018688165582716465\n",
      "   Training decoder Loss: 0.0010538824135437608\n",
      "   Training sindy_z Loss: 39.67294692993164\n",
      "   Training sindy_x Loss: 7.993867874145508\n",
      "   Training sindy_regularization Loss: 1.5547419786453247\n",
      "   Validation Total Loss: 0.0022290756460279226\n",
      "   Validation decoder Loss: 0.0012955166166648269\n",
      "   Validation sindy_z Loss: 53.40296936035156\n",
      "   Validation sindy_x Loss: 9.18011474609375\n",
      "   Validation sindy_regularization Loss: 1.5547419786453247\n",
      "Decoder Loss Ratio: 0.006668, Decoder SINDy Loss Ratio: 0.639350\n",
      "Epoch 19\n",
      "Epoch 19\n",
      "   Training Total Loss: 0.0017161761643365026\n",
      "   Training decoder Loss: 0.0009346594451926649\n",
      "   Training sindy_z Loss: 36.297359466552734\n",
      "   Training sindy_x Loss: 7.654541969299316\n",
      "   Training sindy_regularization Loss: 1.606256127357483\n",
      "   Validation Total Loss: 0.002068194327875972\n",
      "   Validation decoder Loss: 0.0011692190309986472\n",
      "   Validation sindy_z Loss: 51.234256744384766\n",
      "   Validation sindy_x Loss: 8.829127311706543\n",
      "   Validation sindy_regularization Loss: 1.606256127357483\n",
      "Decoder Loss Ratio: 0.006018, Decoder SINDy Loss Ratio: 0.614906\n",
      "Epoch 20\n",
      "Epoch 20\n",
      "   Training Total Loss: 0.0016174206975847483\n",
      "   Training decoder Loss: 0.0008664198685437441\n",
      "   Training sindy_z Loss: 34.030582427978516\n",
      "   Training sindy_x Loss: 7.344552993774414\n",
      "   Training sindy_regularization Loss: 1.6545488834381104\n",
      "   Validation Total Loss: 0.0019680920522660017\n",
      "   Validation decoder Loss: 0.0011000598315149546\n",
      "   Validation sindy_z Loss: 49.85186004638672\n",
      "   Validation sindy_x Loss: 8.51486873626709\n",
      "   Validation sindy_regularization Loss: 1.6545488834381104\n",
      "Decoder Loss Ratio: 0.005662, Decoder SINDy Loss Ratio: 0.593019\n",
      "Epoch 21\n",
      "Epoch 21\n",
      "   Training Total Loss: 0.0015370289329439402\n",
      "   Training decoder Loss: 0.0008150648791342974\n",
      "   Training sindy_z Loss: 32.64842224121094\n",
      "   Training sindy_x Loss: 7.04925012588501\n",
      "   Training sindy_regularization Loss: 1.7038962841033936\n",
      "   Validation Total Loss: 0.001889480510726571\n",
      "   Validation decoder Loss: 0.0010503589874133468\n",
      "   Validation sindy_z Loss: 49.290401458740234\n",
      "   Validation sindy_x Loss: 8.220826148986816\n",
      "   Validation sindy_regularization Loss: 1.7038962841033936\n",
      "Decoder Loss Ratio: 0.005406, Decoder SINDy Loss Ratio: 0.572541\n",
      "Epoch 22\n",
      "Epoch 22\n",
      "   Training Total Loss: 0.0015303989639505744\n",
      "   Training decoder Loss: 0.000836255494505167\n",
      "   Training sindy_z Loss: 31.497421264648438\n",
      "   Training sindy_x Loss: 6.766288757324219\n",
      "   Training sindy_regularization Loss: 1.7514547109603882\n",
      "   Validation Total Loss: 0.0018866158789023757\n",
      "   Validation decoder Loss: 0.001074141706340015\n",
      "   Validation sindy_z Loss: 48.045536041259766\n",
      "   Validation sindy_x Loss: 7.949596881866455\n",
      "   Validation sindy_regularization Loss: 1.7514547109603882\n",
      "Decoder Loss Ratio: 0.005529, Decoder SINDy Loss Ratio: 0.553651\n",
      "Epoch 23\n",
      "Epoch 23\n",
      "   Training Total Loss: 0.0014501750702038407\n",
      "   Training decoder Loss: 0.0007870651897974312\n",
      "   Training sindy_z Loss: 30.941232681274414\n",
      "   Training sindy_x Loss: 6.451390266418457\n",
      "   Training sindy_regularization Loss: 1.7970962524414062\n",
      "   Validation Total Loss: 0.0018113976111635566\n",
      "   Validation decoder Loss: 0.0010291625512763858\n",
      "   Validation sindy_z Loss: 48.041927337646484\n",
      "   Validation sindy_x Loss: 7.642642021179199\n",
      "   Validation sindy_regularization Loss: 1.7970962524414062\n",
      "Decoder Loss Ratio: 0.005297, Decoder SINDy Loss Ratio: 0.532273\n",
      "Epoch 24\n",
      "Epoch 24\n",
      "   Training Total Loss: 0.0013720907736569643\n",
      "   Training decoder Loss: 0.0007422093185596168\n",
      "   Training sindy_z Loss: 30.430694580078125\n",
      "   Training sindy_x Loss: 6.114880561828613\n",
      "   Training sindy_regularization Loss: 1.8393361568450928\n",
      "   Validation Total Loss: 0.0017389587592333555\n",
      "   Validation decoder Loss: 0.0009890656219795346\n",
      "   Validation sindy_z Loss: 47.740196228027344\n",
      "   Validation sindy_x Loss: 7.314997673034668\n",
      "   Validation sindy_regularization Loss: 1.8393361568450928\n",
      "Decoder Loss Ratio: 0.005091, Decoder SINDy Loss Ratio: 0.509454\n",
      "Epoch 25\n",
      "Epoch 25\n",
      "   Training Total Loss: 0.00138269760645926\n",
      "   Training decoder Loss: 0.0007885167142376304\n",
      "   Training sindy_z Loss: 29.924753189086914\n",
      "   Training sindy_x Loss: 5.753588676452637\n",
      "   Training sindy_regularization Loss: 1.8822065591812134\n",
      "   Validation Total Loss: 0.001755695790052414\n",
      "   Validation decoder Loss: 0.0010433808201923966\n",
      "   Validation sindy_z Loss: 47.30083084106445\n",
      "   Validation sindy_x Loss: 6.934929847717285\n",
      "   Validation sindy_regularization Loss: 1.8822065591812134\n",
      "Decoder Loss Ratio: 0.005370, Decoder SINDy Loss Ratio: 0.482984\n",
      "Epoch 26\n",
      "Epoch 26\n",
      "   Training Total Loss: 0.0011408469872549176\n",
      "   Training decoder Loss: 0.0005893527995795012\n",
      "   Training sindy_z Loss: 29.88437843322754\n",
      "   Training sindy_x Loss: 5.322632312774658\n",
      "   Training sindy_regularization Loss: 1.9230972528457642\n",
      "   Validation Total Loss: 0.001518537406809628\n",
      "   Validation decoder Loss: 0.0008454395574517548\n",
      "   Validation sindy_z Loss: 48.21401596069336\n",
      "   Validation sindy_x Loss: 6.538668632507324\n",
      "   Validation sindy_regularization Loss: 1.9230972528457642\n",
      "Decoder Loss Ratio: 0.004351, Decoder SINDy Loss Ratio: 0.455386\n",
      "Epoch 27\n",
      "Epoch 27\n",
      "   Training Total Loss: 0.0010685768211260438\n",
      "   Training decoder Loss: 0.0005636288551613688\n",
      "   Training sindy_z Loss: 30.06922149658203\n",
      "   Training sindy_x Loss: 4.853214740753174\n",
      "   Training sindy_regularization Loss: 1.9626535177230835\n",
      "   Validation Total Loss: 0.0014526323648169637\n",
      "   Validation decoder Loss: 0.0008225233177654445\n",
      "   Validation sindy_z Loss: 49.01561737060547\n",
      "   Validation sindy_x Loss: 6.104825496673584\n",
      "   Validation sindy_regularization Loss: 1.9626535177230835\n",
      "Decoder Loss Ratio: 0.004233, Decoder SINDy Loss Ratio: 0.425171\n",
      "Epoch 28\n",
      "Epoch 28\n",
      "   Training Total Loss: 0.0009398914407938719\n",
      "   Training decoder Loss: 0.000483485113363713\n",
      "   Training sindy_z Loss: 29.79248046875\n",
      "   Training sindy_x Loss: 4.364227771759033\n",
      "   Training sindy_regularization Loss: 1.9983584880828857\n",
      "   Validation Total Loss: 0.0013257934479042888\n",
      "   Validation decoder Loss: 0.000740133342333138\n",
      "   Validation sindy_z Loss: 48.374515533447266\n",
      "   Validation sindy_x Loss: 5.656764984130859\n",
      "   Validation sindy_regularization Loss: 1.9983584880828857\n",
      "Decoder Loss Ratio: 0.003809, Decoder SINDy Loss Ratio: 0.393966\n",
      "Epoch 29\n",
      "Epoch 29\n",
      "   Training Total Loss: 0.000852416327688843\n",
      "   Training decoder Loss: 0.00044297848944552243\n",
      "   Training sindy_z Loss: 30.325166702270508\n",
      "   Training sindy_x Loss: 3.89090633392334\n",
      "   Training sindy_regularization Loss: 2.034726858139038\n",
      "   Validation Total Loss: 0.0012362385168671608\n",
      "   Validation decoder Loss: 0.0006933507393114269\n",
      "   Validation sindy_z Loss: 48.94245529174805\n",
      "   Validation sindy_x Loss: 5.225404739379883\n",
      "   Validation sindy_regularization Loss: 2.034726858139038\n",
      "Decoder Loss Ratio: 0.003569, Decoder SINDy Loss Ratio: 0.363924\n",
      "Epoch 30\n",
      "Epoch 30\n",
      "   Training Total Loss: 0.0007477757171727717\n",
      "   Training decoder Loss: 0.00037687006988562644\n",
      "   Training sindy_z Loss: 31.114072799682617\n",
      "   Training sindy_x Loss: 3.5021512508392334\n",
      "   Training sindy_regularization Loss: 2.069056749343872\n",
      "   Validation Total Loss: 0.0011231073876842856\n",
      "   Validation decoder Loss: 0.0006150881526991725\n",
      "   Validation sindy_z Loss: 49.58509063720703\n",
      "   Validation sindy_x Loss: 4.87328577041626\n",
      "   Validation sindy_regularization Loss: 2.069056749343872\n",
      "Decoder Loss Ratio: 0.003166, Decoder SINDy Loss Ratio: 0.339401\n",
      "Epoch 31\n",
      "Epoch 31\n",
      "   Training Total Loss: 0.0008573248633183539\n",
      "   Training decoder Loss: 0.0005139334825798869\n",
      "   Training sindy_z Loss: 33.04255294799805\n",
      "   Training sindy_x Loss: 3.223968982696533\n",
      "   Training sindy_regularization Loss: 2.0994527339935303\n",
      "   Validation Total Loss: 0.0012153068091720343\n",
      "   Validation decoder Loss: 0.0007332517998293042\n",
      "   Validation sindy_z Loss: 52.507442474365234\n",
      "   Validation sindy_x Loss: 4.6106038093566895\n",
      "   Validation sindy_regularization Loss: 2.0994527339935303\n",
      "Decoder Loss Ratio: 0.003774, Decoder SINDy Loss Ratio: 0.321106\n",
      "Epoch 32\n",
      "Epoch 32\n",
      "   Training Total Loss: 0.000607321853749454\n",
      "   Training decoder Loss: 0.00028614848270080984\n",
      "   Training sindy_z Loss: 34.04048156738281\n",
      "   Training sindy_x Loss: 2.999601125717163\n",
      "   Training sindy_regularization Loss: 2.121323585510254\n",
      "   Validation Total Loss: 0.0009580664336681366\n",
      "   Validation decoder Loss: 0.0004979958175681531\n",
      "   Validation sindy_z Loss: 52.49662780761719\n",
      "   Validation sindy_x Loss: 4.38857364654541\n",
      "   Validation sindy_regularization Loss: 2.121323585510254\n",
      "Decoder Loss Ratio: 0.002563, Decoder SINDy Loss Ratio: 0.305643\n",
      "Epoch 33\n",
      "Epoch 33\n",
      "   Training Total Loss: 0.0005539029953069985\n",
      "   Training decoder Loss: 0.0002502631687093526\n",
      "   Training sindy_z Loss: 35.09177780151367\n",
      "   Training sindy_x Loss: 2.8218390941619873\n",
      "   Training sindy_regularization Loss: 2.1455953121185303\n",
      "   Validation Total Loss: 0.0008926903828978539\n",
      "   Validation decoder Loss: 0.00044996151700615883\n",
      "   Validation sindy_z Loss: 52.723690032958984\n",
      "   Validation sindy_x Loss: 4.212729454040527\n",
      "   Validation sindy_regularization Loss: 2.1455953121185303\n",
      "Decoder Loss Ratio: 0.002316, Decoder SINDy Loss Ratio: 0.293396\n",
      "Epoch 34\n",
      "Epoch 34\n",
      "   Training Total Loss: 0.0005085619632154703\n",
      "   Training decoder Loss: 0.00022039840405341238\n",
      "   Training sindy_z Loss: 36.09583282470703\n",
      "   Training sindy_x Loss: 2.6648635864257812\n",
      "   Training sindy_regularization Loss: 2.167725086212158\n",
      "   Validation Total Loss: 0.0008354991441592574\n",
      "   Validation decoder Loss: 0.00040927110239863396\n",
      "   Validation sindy_z Loss: 53.177223205566406\n",
      "   Validation sindy_x Loss: 4.045507907867432\n",
      "   Validation sindy_regularization Loss: 2.167725086212158\n",
      "Decoder Loss Ratio: 0.002106, Decoder SINDy Loss Ratio: 0.281750\n",
      "Epoch 35\n",
      "Epoch 35\n",
      "   Training Total Loss: 0.00047466190881095827\n",
      "   Training decoder Loss: 0.00019980901561211795\n",
      "   Training sindy_z Loss: 36.91604995727539\n",
      "   Training sindy_x Loss: 2.5296850204467773\n",
      "   Training sindy_regularization Loss: 2.1884427070617676\n",
      "   Validation Total Loss: 0.0007888776017352939\n",
      "   Validation decoder Loss: 0.0003767734451685101\n",
      "   Validation sindy_z Loss: 53.50004196166992\n",
      "   Validation sindy_x Loss: 3.9021968841552734\n",
      "   Validation sindy_regularization Loss: 2.1884427070617676\n",
      "Decoder Loss Ratio: 0.001939, Decoder SINDy Loss Ratio: 0.271769\n",
      "Epoch 36\n",
      "Epoch 36\n",
      "   Training Total Loss: 0.00043705260031856596\n",
      "   Training decoder Loss: 0.00017487831064499915\n",
      "   Training sindy_z Loss: 37.36007308959961\n",
      "   Training sindy_x Loss: 2.4010186195373535\n",
      "   Training sindy_regularization Loss: 2.207242012023926\n",
      "   Validation Total Loss: 0.0007402518531307578\n",
      "   Validation decoder Loss: 0.0003412068181205541\n",
      "   Validation sindy_z Loss: 53.76362228393555\n",
      "   Validation sindy_x Loss: 3.769726514816284\n",
      "   Validation sindy_regularization Loss: 2.207242012023926\n",
      "Decoder Loss Ratio: 0.001756, Decoder SINDy Loss Ratio: 0.262543\n",
      "Epoch 37\n",
      "Epoch 37\n",
      "   Training Total Loss: 0.00046046212082728744\n",
      "   Training decoder Loss: 0.00020859981304965913\n",
      "   Training sindy_z Loss: 37.39787673950195\n",
      "   Training sindy_x Loss: 2.296210289001465\n",
      "   Training sindy_regularization Loss: 2.2241251468658447\n",
      "   Validation Total Loss: 0.0007533200550824404\n",
      "   Validation decoder Loss: 0.00036542199086397886\n",
      "   Validation sindy_z Loss: 53.73447799682617\n",
      "   Validation sindy_x Loss: 3.6565680503845215\n",
      "   Validation sindy_regularization Loss: 2.2241251468658447\n",
      "Decoder Loss Ratio: 0.001881, Decoder SINDy Loss Ratio: 0.254662\n",
      "Epoch 38\n",
      "Epoch 38\n",
      "   Training Total Loss: 0.0005413072067312896\n",
      "   Training decoder Loss: 0.000301868945825845\n",
      "   Training sindy_z Loss: 37.45183181762695\n",
      "   Training sindy_x Loss: 2.170517683029175\n",
      "   Training sindy_regularization Loss: 2.2386474609375\n",
      "   Validation Total Loss: 0.0008291114936582744\n",
      "   Validation decoder Loss: 0.0004533943720161915\n",
      "   Validation sindy_z Loss: 54.32698440551758\n",
      "   Validation sindy_x Loss: 3.53330659866333\n",
      "   Validation sindy_regularization Loss: 2.2386474609375\n",
      "Decoder Loss Ratio: 0.002334, Decoder SINDy Loss Ratio: 0.246078\n",
      "Epoch 39\n",
      "Epoch 39\n",
      "   Training Total Loss: 0.0003626573598012328\n",
      "   Training decoder Loss: 0.00013096228940412402\n",
      "   Training sindy_z Loss: 37.06285095214844\n",
      "   Training sindy_x Loss: 2.0918781757354736\n",
      "   Training sindy_regularization Loss: 2.2507286071777344\n",
      "   Validation Total Loss: 0.0006357243983075023\n",
      "   Validation decoder Loss: 0.00027087455964647233\n",
      "   Validation sindy_z Loss: 52.82841491699219\n",
      "   Validation sindy_x Loss: 3.4234261512756348\n",
      "   Validation sindy_regularization Loss: 2.2507286071777344\n",
      "Decoder Loss Ratio: 0.001394, Decoder SINDy Loss Ratio: 0.238425\n",
      "Epoch 40\n",
      "Epoch 40\n",
      "   Training Total Loss: 0.00036152935354039073\n",
      "   Training decoder Loss: 0.0001387019146932289\n",
      "   Training sindy_z Loss: 36.41207504272461\n",
      "   Training sindy_x Loss: 2.002079486846924\n",
      "   Training sindy_regularization Loss: 2.261948585510254\n",
      "   Validation Total Loss: 0.0006259661167860031\n",
      "   Validation decoder Loss: 0.0002713030553422868\n",
      "   Validation sindy_z Loss: 52.045021057128906\n",
      "   Validation sindy_x Loss: 3.3204355239868164\n",
      "   Validation sindy_regularization Loss: 2.261948585510254\n",
      "Decoder Loss Ratio: 0.001396, Decoder SINDy Loss Ratio: 0.231252\n",
      "Epoch 41\n",
      "Epoch 41\n",
      "   Training Total Loss: 0.0003302789409644902\n",
      "   Training decoder Loss: 0.00011452765465946868\n",
      "   Training sindy_z Loss: 35.83845138549805\n",
      "   Training sindy_x Loss: 1.930342197418213\n",
      "   Training sindy_regularization Loss: 2.2717080116271973\n",
      "   Validation Total Loss: 0.0005852185422554612\n",
      "   Validation decoder Loss: 0.00023928818700369447\n",
      "   Validation sindy_z Loss: 50.92719268798828\n",
      "   Validation sindy_x Loss: 3.232132911682129\n",
      "   Validation sindy_regularization Loss: 2.2717080116271973\n",
      "Decoder Loss Ratio: 0.001232, Decoder SINDy Loss Ratio: 0.225102\n",
      "Epoch 42\n",
      "Epoch 42\n",
      "   Training Total Loss: 0.00031332974322140217\n",
      "   Training decoder Loss: 0.00010296668915543705\n",
      "   Training sindy_z Loss: 35.0830078125\n",
      "   Training sindy_x Loss: 1.8755667209625244\n",
      "   Training sindy_regularization Loss: 2.280639886856079\n",
      "   Validation Total Loss: 0.0005582916783168912\n",
      "   Validation decoder Loss: 0.00021942195598967373\n",
      "   Validation sindy_z Loss: 49.52142333984375\n",
      "   Validation sindy_x Loss: 3.1606333255767822\n",
      "   Validation sindy_regularization Loss: 2.280639886856079\n",
      "Decoder Loss Ratio: 0.001129, Decoder SINDy Loss Ratio: 0.220123\n",
      "Epoch 43\n",
      "Epoch 43\n",
      "   Training Total Loss: 0.00031309667974710464\n",
      "   Training decoder Loss: 0.00010917014151345938\n",
      "   Training sindy_z Loss: 34.4254264831543\n",
      "   Training sindy_x Loss: 1.810401439666748\n",
      "   Training sindy_regularization Loss: 2.2886388301849365\n",
      "   Validation Total Loss: 0.0005485602305270731\n",
      "   Validation decoder Loss: 0.00021700284560211003\n",
      "   Validation sindy_z Loss: 48.400596618652344\n",
      "   Validation sindy_x Loss: 3.086710214614868\n",
      "   Validation sindy_regularization Loss: 2.2886388301849365\n",
      "Decoder Loss Ratio: 0.001117, Decoder SINDy Loss Ratio: 0.214974\n",
      "Epoch 44\n",
      "Epoch 44\n",
      "   Training Total Loss: 0.0002930737682618201\n",
      "   Training decoder Loss: 9.468199277762324e-05\n",
      "   Training sindy_z Loss: 33.613399505615234\n",
      "   Training sindy_x Loss: 1.7543532848358154\n",
      "   Training sindy_regularization Loss: 2.2956466674804688\n",
      "   Validation Total Loss: 0.0005203738110139966\n",
      "   Validation decoder Loss: 0.00019686629821080714\n",
      "   Validation sindy_z Loss: 46.913795471191406\n",
      "   Validation sindy_x Loss: 3.0055103302001953\n",
      "   Validation sindy_regularization Loss: 2.2956466674804688\n",
      "Decoder Loss Ratio: 0.001013, Decoder SINDy Loss Ratio: 0.209319\n",
      "Epoch 45\n",
      "Epoch 45\n",
      "   Training Total Loss: 0.0002946246531791985\n",
      "   Training decoder Loss: 0.00010087240661960095\n",
      "   Training sindy_z Loss: 33.19222640991211\n",
      "   Training sindy_x Loss: 1.70743989944458\n",
      "   Training sindy_regularization Loss: 2.3008265495300293\n",
      "   Validation Total Loss: 0.000517739390488714\n",
      "   Validation decoder Loss: 0.00020293102716095746\n",
      "   Validation sindy_z Loss: 46.22196578979492\n",
      "   Validation sindy_x Loss: 2.918001413345337\n",
      "   Validation sindy_regularization Loss: 2.3008265495300293\n",
      "Decoder Loss Ratio: 0.001044, Decoder SINDy Loss Ratio: 0.203225\n",
      "Epoch 46\n",
      "Epoch 46\n",
      "   Training Total Loss: 0.0002641468890942633\n",
      "   Training decoder Loss: 7.467703835573047e-05\n",
      "   Training sindy_z Loss: 32.72603988647461\n",
      "   Training sindy_x Loss: 1.6643810272216797\n",
      "   Training sindy_regularization Loss: 2.3031766414642334\n",
      "   Validation Total Loss: 0.00047767278738319874\n",
      "   Validation decoder Loss: 0.0001673874503467232\n",
      "   Validation sindy_z Loss: 45.306827545166016\n",
      "   Validation sindy_x Loss: 2.8725359439849854\n",
      "   Validation sindy_regularization Loss: 2.3031766414642334\n",
      "Decoder Loss Ratio: 0.000862, Decoder SINDy Loss Ratio: 0.200058\n",
      "Epoch 47\n",
      "Epoch 47\n",
      "   Training Total Loss: 0.0002566731418482959\n",
      "   Training decoder Loss: 7.10402091499418e-05\n",
      "   Training sindy_z Loss: 31.84653663635254\n",
      "   Training sindy_x Loss: 1.6247104406356812\n",
      "   Training sindy_regularization Loss: 2.316188097000122\n",
      "   Validation Total Loss: 0.0004649914335459471\n",
      "   Validation decoder Loss: 0.00016033287101890892\n",
      "   Validation sindy_z Loss: 43.98308563232422\n",
      "   Validation sindy_x Loss: 2.8149666786193848\n",
      "   Validation sindy_regularization Loss: 2.316188097000122\n",
      "Decoder Loss Ratio: 0.000825, Decoder SINDy Loss Ratio: 0.196049\n",
      "Epoch 48\n",
      "Epoch 48\n",
      "   Training Total Loss: 0.0002517640823498368\n",
      "   Training decoder Loss: 6.930428935447708e-05\n",
      "   Training sindy_z Loss: 31.11786460876465\n",
      "   Training sindy_x Loss: 1.5916826725006104\n",
      "   Training sindy_regularization Loss: 2.329153537750244\n",
      "   Validation Total Loss: 0.00045306870015338063\n",
      "   Validation decoder Loss: 0.00015479771536774933\n",
      "   Validation sindy_z Loss: 42.63020706176758\n",
      "   Validation sindy_x Loss: 2.7497944831848145\n",
      "   Validation sindy_regularization Loss: 2.329153537750244\n",
      "Decoder Loss Ratio: 0.000797, Decoder SINDy Loss Ratio: 0.191510\n",
      "Epoch 49\n",
      "Epoch 49\n",
      "   Training Total Loss: 0.0002550543867982924\n",
      "   Training decoder Loss: 7.662494317628443e-05\n",
      "   Training sindy_z Loss: 30.39531707763672\n",
      "   Training sindy_x Loss: 1.5500779151916504\n",
      "   Training sindy_regularization Loss: 2.3421671390533447\n",
      "   Validation Total Loss: 0.00044974079355597496\n",
      "   Validation decoder Loss: 0.00015747823636047542\n",
      "   Validation sindy_z Loss: 41.486854553222656\n",
      "   Validation sindy_x Loss: 2.6884090900421143\n",
      "   Validation sindy_regularization Loss: 2.3421671390533447\n",
      "Decoder Loss Ratio: 0.000811, Decoder SINDy Loss Ratio: 0.187235\n",
      "Epoch 50\n",
      "Epoch 50\n",
      "   Training Total Loss: 0.00024270603898912668\n",
      "   Training decoder Loss: 6.723639671690762e-05\n",
      "   Training sindy_z Loss: 29.773942947387695\n",
      "   Training sindy_x Loss: 1.519254207611084\n",
      "   Training sindy_regularization Loss: 2.3544228076934814\n",
      "   Validation Total Loss: 0.00042887195013463497\n",
      "   Validation decoder Loss: 0.0001420202461304143\n",
      "   Validation sindy_z Loss: 40.47134017944336\n",
      "   Validation sindy_x Loss: 2.6330747604370117\n",
      "   Validation sindy_regularization Loss: 2.3544228076934814\n",
      "Decoder Loss Ratio: 0.000731, Decoder SINDy Loss Ratio: 0.183381\n",
      "Epoch 51\n"
     ]
    }
   ],
   "source": [
    "num_experiments = 1\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_experiments):\n",
    "    print('EXPERIMENT %d' % i)\n",
    "\n",
    "    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "\n",
    "    params['save_name'] = 'lorenz_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "    \n",
    "    results_dict = train_network(training_data, validation_data, params)\n",
    "    df = df.append({**results_dict, **params}, ignore_index=True)\n",
    "\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
