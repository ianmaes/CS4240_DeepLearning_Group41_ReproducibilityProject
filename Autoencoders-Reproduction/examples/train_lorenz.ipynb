{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_lorenz import get_lorenz_data\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate training, validation, testing data\n",
    "noise_strength = 1e-6\n",
    "training_data = get_lorenz_data(1024, noise_strength=noise_strength)\n",
    "validation_data = get_lorenz_data(20, noise_strength=noise_strength)\n",
    "training_data['x'] = torch.tensor(training_data['x']).float()\n",
    "training_data['dx'] = torch.tensor(training_data['dx']).float()\n",
    "training_data['t'] = torch.tensor(training_data['t']).float()\n",
    "training_data['z'] = torch.tensor(training_data['z']).float()\n",
    "training_data['dz'] = torch.tensor(training_data['dz']).float()\n",
    "\n",
    "\n",
    "validation_data['x'] = torch.tensor(validation_data['x']).float()\n",
    "validation_data['dx'] = torch.tensor(validation_data['dx']).float()\n",
    "validation_data['t'] = torch.tensor(validation_data['t']).float()\n",
    "validation_data['z'] = torch.tensor(validation_data['z']).float()\n",
    "validation_data['dz'] = torch.tensor(validation_data['dz']).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 64]\n",
      "256000\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "\n",
    "params['input_dim'] = 128\n",
    "params['latent_dim'] = 3\n",
    "params['model_order'] = 1\n",
    "params['poly_order'] = 3\n",
    "params['include_sine'] = False\n",
    "params['library_dim'] = library_size(params['latent_dim'], params['poly_order'], params['include_sine'], True)\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = True\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 500\n",
    "params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_z'] = 0.0\n",
    "params['loss_weight_sindy_x'] = 1e-4\n",
    "params['loss_weight_sindy_regularization'] = 1e-5\n",
    "\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [64,32]\n",
    "print(params['widths'][::-1])\n",
    "# training parameters\n",
    "params['epoch_size'] = training_data['x'].shape[0]\n",
    "print(training_data['x'].shape[0])\n",
    "params['batch_size'] = 1024\n",
    "params['learning_rate'] = 1e-3\n",
    "\n",
    "params['data_path'] = os.getcwd() + '/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 1\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 5001\n",
    "params['refinement_epochs'] = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:164: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'x': torch.tensor(data['x'][idxs], dtype=torch.float32),\n",
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:165: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'dx': torch.tensor(data['dx'][idxs], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_total_loss, train_losses, _ = network.define_loss( torch.tensor(train_dict['x'], dtype=torch.float32) , torch.tensor(train_dict['dx'], dtype=torch.float32), params=params)\n",
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_total_loss, val_losses, _ = network.define_loss( torch.tensor(validation_dict['x'], dtype=torch.float32), torch.tensor(validation_dict['dx'], dtype=torch.float32),  params=params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "   Training Total Loss: 0.021362144500017166\n",
      "   Training decoder Loss: 0.020088668912649155\n",
      "   Training sindy_z Loss: 200.16802978515625\n",
      "   Training sindy_x Loss: 12.66016960144043\n",
      "   Training sindy_regularization Loss: 0.745742917060852\n",
      "   Validation Total Loss: 0.0393601655960083\n",
      "   Validation decoder Loss: 0.03735923022031784\n",
      "   Validation sindy_z Loss: 299.16607666015625\n",
      "   Validation sindy_x Loss: 19.934772491455078\n",
      "   Validation sindy_regularization Loss: 0.745742917060852\n",
      "Decoder Loss Ratio: 0.205358, Decoder SINDy Loss Ratio: 1.807585\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "   Training Total Loss: 0.017148569226264954\n",
      "   Training decoder Loss: 0.016537891700863838\n",
      "   Training sindy_z Loss: 105.89168548583984\n",
      "   Training sindy_x Loss: 6.042863845825195\n",
      "   Training sindy_regularization Loss: 0.6391233205795288\n",
      "   Validation Total Loss: 0.032874997705221176\n",
      "   Validation decoder Loss: 0.03157685697078705\n",
      "   Validation sindy_z Loss: 259.64654541015625\n",
      "   Validation sindy_x Loss: 12.91746711730957\n",
      "   Validation sindy_regularization Loss: 0.6391233205795288\n",
      "Decoder Loss Ratio: 0.173573, Decoder SINDy Loss Ratio: 1.171291\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "   Training Total Loss: 0.005401352886110544\n",
      "   Training decoder Loss: 0.004938783124089241\n",
      "   Training sindy_z Loss: 617.7134399414062\n",
      "   Training sindy_x Loss: 4.568887710571289\n",
      "   Training sindy_regularization Loss: 0.5681142210960388\n",
      "   Validation Total Loss: 0.011289380490779877\n",
      "   Validation decoder Loss: 0.010198374278843403\n",
      "   Validation sindy_z Loss: 1696.89404296875\n",
      "   Validation sindy_x Loss: 10.853249549865723\n",
      "   Validation sindy_regularization Loss: 0.5681142210960388\n",
      "Decoder Loss Ratio: 0.056059, Decoder SINDy Loss Ratio: 0.984118\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "   Training Total Loss: 0.004096055869013071\n",
      "   Training decoder Loss: 0.0037058175075799227\n",
      "   Training sindy_z Loss: 719.7267456054688\n",
      "   Training sindy_x Loss: 3.84970760345459\n",
      "   Training sindy_regularization Loss: 0.5267621874809265\n",
      "   Validation Total Loss: 0.00889049656689167\n",
      "   Validation decoder Loss: 0.007905717939138412\n",
      "   Validation sindy_z Loss: 1956.201904296875\n",
      "   Validation sindy_x Loss: 9.795109748840332\n",
      "   Validation sindy_regularization Loss: 0.5267621874809265\n",
      "Decoder Loss Ratio: 0.043457, Decoder SINDy Loss Ratio: 0.888171\n",
      "Epoch 4\n",
      "Epoch 4\n",
      "   Training Total Loss: 0.003559483913704753\n",
      "   Training decoder Loss: 0.0031957486644387245\n",
      "   Training sindy_z Loss: 780.404541015625\n",
      "   Training sindy_x Loss: 3.587070941925049\n",
      "   Training sindy_regularization Loss: 0.5028117895126343\n",
      "   Validation Total Loss: 0.00789221003651619\n",
      "   Validation decoder Loss: 0.0069572944194078445\n",
      "   Validation sindy_z Loss: 2098.040771484375\n",
      "   Validation sindy_x Loss: 9.298871994018555\n",
      "   Validation sindy_regularization Loss: 0.5028117895126343\n",
      "Decoder Loss Ratio: 0.038243, Decoder SINDy Loss Ratio: 0.843175\n",
      "Epoch 5\n",
      "Epoch 5\n",
      "   Training Total Loss: 0.0031097077298909426\n",
      "   Training decoder Loss: 0.002757290843874216\n",
      "   Training sindy_z Loss: 839.7053833007812\n",
      "   Training sindy_x Loss: 3.475274085998535\n",
      "   Training sindy_regularization Loss: 0.4889398515224457\n",
      "   Validation Total Loss: 0.007089634425938129\n",
      "   Validation decoder Loss: 0.0061849565245211124\n",
      "   Validation sindy_z Loss: 2236.890380859375\n",
      "   Validation sindy_x Loss: 8.997885704040527\n",
      "   Validation sindy_regularization Loss: 0.4889398515224457\n",
      "Decoder Loss Ratio: 0.033998, Decoder SINDy Loss Ratio: 0.815883\n",
      "Epoch 6\n",
      "Epoch 6\n",
      "   Training Total Loss: 0.0027888729237020016\n",
      "   Training decoder Loss: 0.0024422076530754566\n",
      "   Training sindy_z Loss: 864.810302734375\n",
      "   Training sindy_x Loss: 3.4178647994995117\n",
      "   Training sindy_regularization Loss: 0.4878815710544586\n",
      "   Validation Total Loss: 0.00649277726188302\n",
      "   Validation decoder Loss: 0.005605014972388744\n",
      "   Validation sindy_z Loss: 2289.81982421875\n",
      "   Validation sindy_x Loss: 8.828834533691406\n",
      "   Validation sindy_regularization Loss: 0.4878815710544586\n",
      "Decoder Loss Ratio: 0.030810, Decoder SINDy Loss Ratio: 0.800554\n",
      "Epoch 7\n",
      "Epoch 7\n",
      "   Training Total Loss: 0.002554689534008503\n",
      "   Training decoder Loss: 0.0022153579629957676\n",
      "   Training sindy_z Loss: 853.0578002929688\n",
      "   Training sindy_x Loss: 3.3433420658111572\n",
      "   Training sindy_regularization Loss: 0.4997509717941284\n",
      "   Validation Total Loss: 0.006098807789385319\n",
      "   Validation decoder Loss: 0.005231821909546852\n",
      "   Validation sindy_z Loss: 2250.2314453125\n",
      "   Validation sindy_x Loss: 8.619881629943848\n",
      "   Validation sindy_regularization Loss: 0.4997509717941284\n",
      "Decoder Loss Ratio: 0.028759, Decoder SINDy Loss Ratio: 0.781608\n",
      "Epoch 8\n",
      "Epoch 8\n",
      "   Training Total Loss: 0.0024480910506099463\n",
      "   Training decoder Loss: 0.0021184354554861784\n",
      "   Training sindy_z Loss: 827.3128051757812\n",
      "   Training sindy_x Loss: 3.2446939945220947\n",
      "   Training sindy_regularization Loss: 0.5186386704444885\n",
      "   Validation Total Loss: 0.005862656515091658\n",
      "   Validation decoder Loss: 0.005022768396884203\n",
      "   Validation sindy_z Loss: 2174.578369140625\n",
      "   Validation sindy_x Loss: 8.347016334533691\n",
      "   Validation sindy_regularization Loss: 0.5186386704444885\n",
      "Decoder Loss Ratio: 0.027609, Decoder SINDy Loss Ratio: 0.756866\n",
      "Epoch 9\n",
      "Epoch 9\n",
      "   Training Total Loss: 0.002383953658863902\n",
      "   Training decoder Loss: 0.0020668846555054188\n",
      "   Training sindy_z Loss: 804.1157836914062\n",
      "   Training sindy_x Loss: 3.11630916595459\n",
      "   Training sindy_regularization Loss: 0.5438156127929688\n",
      "   Validation Total Loss: 0.005694145802408457\n",
      "   Validation decoder Loss: 0.004888096358627081\n",
      "   Validation sindy_z Loss: 2105.539794921875\n",
      "   Validation sindy_x Loss: 8.006114959716797\n",
      "   Validation sindy_regularization Loss: 0.5438156127929688\n",
      "Decoder Loss Ratio: 0.026869, Decoder SINDy Loss Ratio: 0.725954\n",
      "Epoch 10\n",
      "Epoch 10\n",
      "   Training Total Loss: 0.0023347637616097927\n",
      "   Training decoder Loss: 0.0020348657853901386\n",
      "   Training sindy_z Loss: 782.7272338867188\n",
      "   Training sindy_x Loss: 2.942167282104492\n",
      "   Training sindy_regularization Loss: 0.5681331157684326\n",
      "   Validation Total Loss: 0.005565239116549492\n",
      "   Validation decoder Loss: 0.004800856579095125\n",
      "   Validation sindy_z Loss: 2041.0003662109375\n",
      "   Validation sindy_x Loss: 7.587008476257324\n",
      "   Validation sindy_regularization Loss: 0.5681331157684326\n",
      "Decoder Loss Ratio: 0.026390, Decoder SINDy Loss Ratio: 0.687952\n",
      "Epoch 11\n",
      "Epoch 11\n",
      "   Training Total Loss: 0.0022782008163630962\n",
      "   Training decoder Loss: 0.001999898115172982\n",
      "   Training sindy_z Loss: 765.5198364257812\n",
      "   Training sindy_x Loss: 2.7236034870147705\n",
      "   Training sindy_regularization Loss: 0.5942288637161255\n",
      "   Validation Total Loss: 0.005452760495245457\n",
      "   Validation decoder Loss: 0.004737364128232002\n",
      "   Validation sindy_z Loss: 1986.60546875\n",
      "   Validation sindy_x Loss: 7.094542026519775\n",
      "   Validation sindy_regularization Loss: 0.5942288637161255\n",
      "Decoder Loss Ratio: 0.026041, Decoder SINDy Loss Ratio: 0.643297\n",
      "Epoch 12\n",
      "Epoch 12\n",
      "   Training Total Loss: 0.0022084021475166082\n",
      "   Training decoder Loss: 0.0019529670244082808\n",
      "   Training sindy_z Loss: 758.1578979492188\n",
      "   Training sindy_x Loss: 2.4931387901306152\n",
      "   Training sindy_regularization Loss: 0.6121305823326111\n",
      "   Validation Total Loss: 0.00533762201666832\n",
      "   Validation decoder Loss: 0.00467358622699976\n",
      "   Validation sindy_z Loss: 1956.1240234375\n",
      "   Validation sindy_x Loss: 6.579148292541504\n",
      "   Validation sindy_regularization Loss: 0.6121305823326111\n",
      "Decoder Loss Ratio: 0.025690, Decoder SINDy Loss Ratio: 0.596564\n",
      "Epoch 13\n",
      "Epoch 13\n",
      "   Training Total Loss: 0.002141979057341814\n",
      "   Training decoder Loss: 0.0019063209183514118\n",
      "   Training sindy_z Loss: 758.9144897460938\n",
      "   Training sindy_x Loss: 2.2944376468658447\n",
      "   Training sindy_regularization Loss: 0.6214390993118286\n",
      "   Validation Total Loss: 0.005221329629421234\n",
      "   Validation decoder Loss: 0.004600252490490675\n",
      "   Validation sindy_z Loss: 1946.4112548828125\n",
      "   Validation sindy_x Loss: 6.148629665374756\n",
      "   Validation sindy_regularization Loss: 0.6214390993118286\n",
      "Decoder Loss Ratio: 0.025287, Decoder SINDy Loss Ratio: 0.557527\n",
      "Epoch 14\n",
      "Epoch 14\n",
      "   Training Total Loss: 0.0020662948954850435\n",
      "   Training decoder Loss: 0.0018471411895006895\n",
      "   Training sindy_z Loss: 770.588623046875\n",
      "   Training sindy_x Loss: 2.1295053958892822\n",
      "   Training sindy_regularization Loss: 0.6203137040138245\n",
      "   Validation Total Loss: 0.005091689061373472\n",
      "   Validation decoder Loss: 0.004504213109612465\n",
      "   Validation sindy_z Loss: 1965.1895751953125\n",
      "   Validation sindy_x Loss: 5.812727451324463\n",
      "   Validation sindy_regularization Loss: 0.6203137040138245\n",
      "Decoder Loss Ratio: 0.024759, Decoder SINDy Loss Ratio: 0.527069\n",
      "Epoch 15\n",
      "Epoch 15\n",
      "   Training Total Loss: 0.001967316260561347\n",
      "   Training decoder Loss: 0.0017619648715481162\n",
      "   Training sindy_z Loss: 791.2506713867188\n",
      "   Training sindy_x Loss: 1.992614984512329\n",
      "   Training sindy_regularization Loss: 0.6089875102043152\n",
      "   Validation Total Loss: 0.004919851198792458\n",
      "   Validation decoder Loss: 0.004359250422567129\n",
      "   Validation sindy_z Loss: 2006.7205810546875\n",
      "   Validation sindy_x Loss: 5.545106410980225\n",
      "   Validation sindy_regularization Loss: 0.6089875102043152\n",
      "Decoder Loss Ratio: 0.023962, Decoder SINDy Loss Ratio: 0.502802\n",
      "Epoch 16\n",
      "Epoch 16\n",
      "   Training Total Loss: 0.0018492605304345489\n",
      "   Training decoder Loss: 0.0016555069014430046\n",
      "   Training sindy_z Loss: 821.7578125\n",
      "   Training sindy_x Loss: 1.8782985210418701\n",
      "   Training sindy_regularization Loss: 0.592373788356781\n",
      "   Validation Total Loss: 0.004707694984972477\n",
      "   Validation decoder Loss: 0.0041716089472174644\n",
      "   Validation sindy_z Loss: 2073.648681640625\n",
      "   Validation sindy_x Loss: 5.3016228675842285\n",
      "   Validation sindy_regularization Loss: 0.592373788356781\n",
      "Decoder Loss Ratio: 0.022931, Decoder SINDy Loss Ratio: 0.480725\n",
      "Epoch 17\n",
      "Epoch 17\n",
      "   Training Total Loss: 0.001744803856126964\n",
      "   Training decoder Loss: 0.0015608028043061495\n",
      "   Training sindy_z Loss: 859.612060546875\n",
      "   Training sindy_x Loss: 1.7823357582092285\n",
      "   Training sindy_regularization Loss: 0.5767450332641602\n",
      "   Validation Total Loss: 0.004495152737945318\n",
      "   Validation decoder Loss: 0.003982943017035723\n",
      "   Validation sindy_z Loss: 2161.04638671875\n",
      "   Validation sindy_x Loss: 5.0644211769104\n",
      "   Validation sindy_regularization Loss: 0.5767450332641602\n",
      "Decoder Loss Ratio: 0.021894, Decoder SINDy Loss Ratio: 0.459216\n",
      "Epoch 18\n",
      "Epoch 18\n",
      "   Training Total Loss: 0.0016876750160008669\n",
      "   Training decoder Loss: 0.0015108934603631496\n",
      "   Training sindy_z Loss: 894.0949096679688\n",
      "   Training sindy_x Loss: 1.7108639478683472\n",
      "   Training sindy_regularization Loss: 0.5695180296897888\n",
      "   Validation Total Loss: 0.004325087182223797\n",
      "   Validation decoder Loss: 0.0038335053250193596\n",
      "   Validation sindy_z Loss: 2242.73583984375\n",
      "   Validation sindy_x Loss: 4.858870506286621\n",
      "   Validation sindy_regularization Loss: 0.5695180296897888\n",
      "Decoder Loss Ratio: 0.021072, Decoder SINDy Loss Ratio: 0.440578\n",
      "Epoch 19\n",
      "Epoch 19\n",
      "   Training Total Loss: 0.0016556927002966404\n",
      "   Training decoder Loss: 0.0014841801021248102\n",
      "   Training sindy_z Loss: 914.9609985351562\n",
      "   Training sindy_x Loss: 1.6582602262496948\n",
      "   Training sindy_regularization Loss: 0.5686586499214172\n",
      "   Validation Total Loss: 0.004195000045001507\n",
      "   Validation decoder Loss: 0.0037192965392023325\n",
      "   Validation sindy_z Loss: 2293.523193359375\n",
      "   Validation sindy_x Loss: 4.700170516967773\n",
      "   Validation sindy_regularization Loss: 0.5686586499214172\n",
      "Decoder Loss Ratio: 0.020444, Decoder SINDy Loss Ratio: 0.426188\n",
      "Epoch 20\n",
      "Epoch 20\n",
      "   Training Total Loss: 0.0016376918647438288\n",
      "   Training decoder Loss: 0.0014706725487485528\n",
      "   Training sindy_z Loss: 928.1570434570312\n",
      "   Training sindy_x Loss: 1.61305832862854\n",
      "   Training sindy_regularization Loss: 0.5713414549827576\n",
      "   Validation Total Loss: 0.004099434241652489\n",
      "   Validation decoder Loss: 0.003637230722233653\n",
      "   Validation sindy_z Loss: 2329.186279296875\n",
      "   Validation sindy_x Loss: 4.564901828765869\n",
      "   Validation sindy_regularization Loss: 0.5713414549827576\n",
      "Decoder Loss Ratio: 0.019993, Decoder SINDy Loss Ratio: 0.413922\n",
      "Epoch 21\n",
      "Epoch 21\n",
      "   Training Total Loss: 0.0016206492437049747\n",
      "   Training decoder Loss: 0.001458607381209731\n",
      "   Training sindy_z Loss: 941.7704467773438\n",
      "   Training sindy_x Loss: 1.5626360177993774\n",
      "   Training sindy_regularization Loss: 0.5778267979621887\n",
      "   Validation Total Loss: 0.004019156098365784\n",
      "   Validation decoder Loss: 0.003570414846763015\n",
      "   Validation sindy_z Loss: 2368.9462890625\n",
      "   Validation sindy_x Loss: 4.429630279541016\n",
      "   Validation sindy_regularization Loss: 0.5778267979621887\n",
      "Decoder Loss Ratio: 0.019626, Decoder SINDy Loss Ratio: 0.401657\n",
      "Epoch 22\n",
      "Epoch 22\n",
      "   Training Total Loss: 0.0016029530670493841\n",
      "   Training decoder Loss: 0.0014458494260907173\n",
      "   Training sindy_z Loss: 953.1951293945312\n",
      "   Training sindy_x Loss: 1.5121634006500244\n",
      "   Training sindy_regularization Loss: 0.5887314081192017\n",
      "   Validation Total Loss: 0.003946809563785791\n",
      "   Validation decoder Loss: 0.0035101829562336206\n",
      "   Validation sindy_z Loss: 2404.061767578125\n",
      "   Validation sindy_x Loss: 4.307390213012695\n",
      "   Validation sindy_regularization Loss: 0.5887314081192017\n",
      "Decoder Loss Ratio: 0.019295, Decoder SINDy Loss Ratio: 0.390573\n",
      "Epoch 23\n",
      "Epoch 23\n",
      "   Training Total Loss: 0.0015801116824150085\n",
      "   Training decoder Loss: 0.0014278211165219545\n",
      "   Training sindy_z Loss: 960.9799194335938\n",
      "   Training sindy_x Loss: 1.462730884552002\n",
      "   Training sindy_regularization Loss: 0.6017482280731201\n",
      "   Validation Total Loss: 0.0038733105175197124\n",
      "   Validation decoder Loss: 0.003447872819378972\n",
      "   Validation sindy_z Loss: 2430.034912109375\n",
      "   Validation sindy_x Loss: 4.194202899932861\n",
      "   Validation sindy_regularization Loss: 0.6017482280731201\n",
      "Decoder Loss Ratio: 0.018952, Decoder SINDy Loss Ratio: 0.380309\n",
      "Epoch 24\n",
      "Epoch 24\n",
      "   Training Total Loss: 0.001545689650811255\n",
      "   Training decoder Loss: 0.0013984921388328075\n",
      "   Training sindy_z Loss: 964.1845092773438\n",
      "   Training sindy_x Loss: 1.4104984998703003\n",
      "   Training sindy_regularization Loss: 0.6147626042366028\n",
      "   Validation Total Loss: 0.003788457717746496\n",
      "   Validation decoder Loss: 0.003375424537807703\n",
      "   Validation sindy_z Loss: 2444.084716796875\n",
      "   Validation sindy_x Loss: 4.068854808807373\n",
      "   Validation sindy_regularization Loss: 0.6147626042366028\n",
      "Decoder Loss Ratio: 0.018554, Decoder SINDy Loss Ratio: 0.368943\n",
      "Epoch 25\n",
      "Epoch 25\n",
      "   Training Total Loss: 0.001491245231591165\n",
      "   Training decoder Loss: 0.0013504308881238103\n",
      "   Training sindy_z Loss: 954.4924926757812\n",
      "   Training sindy_x Loss: 1.3452129364013672\n",
      "   Training sindy_regularization Loss: 0.6293061971664429\n",
      "   Validation Total Loss: 0.0036747201811522245\n",
      "   Validation decoder Loss: 0.003277221694588661\n",
      "   Validation sindy_z Loss: 2424.794677734375\n",
      "   Validation sindy_x Loss: 3.912055492401123\n",
      "   Validation sindy_regularization Loss: 0.6293061971664429\n",
      "Decoder Loss Ratio: 0.018014, Decoder SINDy Loss Ratio: 0.354726\n",
      "Epoch 26\n",
      "Epoch 26\n",
      "   Training Total Loss: 0.001359274028800428\n",
      "   Training decoder Loss: 0.0012288488214835525\n",
      "   Training sindy_z Loss: 909.9536743164062\n",
      "   Training sindy_x Loss: 1.239332914352417\n",
      "   Training sindy_regularization Loss: 0.6491860151290894\n",
      "   Validation Total Loss: 0.0034329923801124096\n",
      "   Validation decoder Loss: 0.003056631423532963\n",
      "   Validation sindy_z Loss: 2316.84765625\n",
      "   Validation sindy_x Loss: 3.69869065284729\n",
      "   Validation sindy_regularization Loss: 0.6491860151290894\n",
      "Decoder Loss Ratio: 0.016802, Decoder SINDy Loss Ratio: 0.335379\n",
      "Epoch 27\n",
      "Epoch 27\n",
      "   Training Total Loss: 0.0008992255898192525\n",
      "   Training decoder Loss: 0.0007816735887899995\n",
      "   Training sindy_z Loss: 763.89453125\n",
      "   Training sindy_x Loss: 1.1080608367919922\n",
      "   Training sindy_regularization Loss: 0.6745903491973877\n",
      "   Validation Total Loss: 0.0026065241545438766\n",
      "   Validation decoder Loss: 0.0022504942025989294\n",
      "   Validation sindy_z Loss: 1948.770751953125\n",
      "   Validation sindy_x Loss: 3.4928410053253174\n",
      "   Validation sindy_regularization Loss: 0.6745903491973877\n",
      "Decoder Loss Ratio: 0.012371, Decoder SINDy Loss Ratio: 0.316713\n",
      "Epoch 28\n",
      "Epoch 28\n",
      "   Training Total Loss: 0.0005048540770076215\n",
      "   Training decoder Loss: 0.0003789158654399216\n",
      "   Training sindy_z Loss: 576.0907592773438\n",
      "   Training sindy_x Loss: 1.1886030435562134\n",
      "   Training sindy_regularization Loss: 0.7077928781509399\n",
      "   Validation Total Loss: 0.0017218698048964143\n",
      "   Validation decoder Loss: 0.0013592285104095936\n",
      "   Validation sindy_z Loss: 1476.7069091796875\n",
      "   Validation sindy_x Loss: 3.555634021759033\n",
      "   Validation sindy_regularization Loss: 0.7077928781509399\n",
      "Decoder Loss Ratio: 0.007471, Decoder SINDy Loss Ratio: 0.322407\n",
      "Epoch 29\n",
      "Epoch 29\n",
      "   Training Total Loss: 0.00038532292819581926\n",
      "   Training decoder Loss: 0.00026587332831695676\n",
      "   Training sindy_z Loss: 533.2429809570312\n",
      "   Training sindy_x Loss: 1.1206943988800049\n",
      "   Training sindy_regularization Loss: 0.7380181550979614\n",
      "   Validation Total Loss: 0.0013085603713989258\n",
      "   Validation decoder Loss: 0.0009664343087933958\n",
      "   Validation sindy_z Loss: 1360.53564453125\n",
      "   Validation sindy_x Loss: 3.347459077835083\n",
      "   Validation sindy_regularization Loss: 0.7380181550979614\n",
      "Decoder Loss Ratio: 0.005312, Decoder SINDy Loss Ratio: 0.303531\n",
      "Epoch 30\n",
      "Epoch 30\n",
      "   Training Total Loss: 0.0003392678627278656\n",
      "   Training decoder Loss: 0.00023093572235666215\n",
      "   Training sindy_z Loss: 531.8451538085938\n",
      "   Training sindy_x Loss: 1.0064988136291504\n",
      "   Training sindy_regularization Loss: 0.7682279348373413\n",
      "   Validation Total Loss: 0.0011072237975895405\n",
      "   Validation decoder Loss: 0.0007942192023620009\n",
      "   Validation sindy_z Loss: 1352.482177734375\n",
      "   Validation sindy_x Loss: 3.053223133087158\n",
      "   Validation sindy_regularization Loss: 0.7682279348373413\n",
      "Decoder Loss Ratio: 0.004366, Decoder SINDy Loss Ratio: 0.276851\n",
      "Epoch 31\n",
      "Epoch 31\n",
      "   Training Total Loss: 0.0003085169300902635\n",
      "   Training decoder Loss: 0.00021089689107611775\n",
      "   Training sindy_z Loss: 537.9337158203125\n",
      "   Training sindy_x Loss: 0.8970116972923279\n",
      "   Training sindy_regularization Loss: 0.7918874621391296\n",
      "   Validation Total Loss: 0.0009610487031750381\n",
      "   Validation decoder Loss: 0.000673735688906163\n",
      "   Validation sindy_z Loss: 1364.0838623046875\n",
      "   Validation sindy_x Loss: 2.7939414978027344\n",
      "   Validation sindy_regularization Loss: 0.7918874621391296\n",
      "Decoder Loss Ratio: 0.003703, Decoder SINDy Loss Ratio: 0.253341\n",
      "Epoch 32\n",
      "Epoch 32\n",
      "   Training Total Loss: 0.00027621741173788905\n",
      "   Training decoder Loss: 0.00018678067135624588\n",
      "   Training sindy_z Loss: 543.3765258789062\n",
      "   Training sindy_x Loss: 0.8135385513305664\n",
      "   Training sindy_regularization Loss: 0.8082898259162903\n",
      "   Validation Total Loss: 0.0008348913979716599\n",
      "   Validation decoder Loss: 0.0005720568005926907\n",
      "   Validation sindy_z Loss: 1374.4239501953125\n",
      "   Validation sindy_x Loss: 2.5475168228149414\n",
      "   Validation sindy_regularization Loss: 0.8082898259162903\n",
      "Decoder Loss Ratio: 0.003145, Decoder SINDy Loss Ratio: 0.230996\n",
      "Epoch 33\n",
      "Epoch 33\n",
      "   Training Total Loss: 0.0002669804380275309\n",
      "   Training decoder Loss: 0.0001819684257498011\n",
      "   Training sindy_z Loss: 543.3916015625\n",
      "   Training sindy_x Loss: 0.768206775188446\n",
      "   Training sindy_regularization Loss: 0.8191317915916443\n",
      "   Validation Total Loss: 0.0007611507899127901\n",
      "   Validation decoder Loss: 0.0005186099442653358\n",
      "   Validation sindy_z Loss: 1371.1773681640625\n",
      "   Validation sindy_x Loss: 2.3434953689575195\n",
      "   Validation sindy_regularization Loss: 0.8191317915916443\n",
      "Decoder Loss Ratio: 0.002851, Decoder SINDy Loss Ratio: 0.212496\n",
      "Epoch 34\n",
      "Epoch 34\n",
      "   Training Total Loss: 0.00024004020087886602\n",
      "   Training decoder Loss: 0.00015868876653257757\n",
      "   Training sindy_z Loss: 539.1045532226562\n",
      "   Training sindy_x Loss: 0.7308158874511719\n",
      "   Training sindy_regularization Loss: 0.8269837498664856\n",
      "   Validation Total Loss: 0.0006809478509239852\n",
      "   Validation decoder Loss: 0.00045521254651248455\n",
      "   Validation sindy_z Loss: 1358.088623046875\n",
      "   Validation sindy_x Loss: 2.174654483795166\n",
      "   Validation sindy_regularization Loss: 0.8269837498664856\n",
      "Decoder Loss Ratio: 0.002502, Decoder SINDy Loss Ratio: 0.197187\n",
      "Epoch 35\n",
      "Epoch 35\n",
      "   Training Total Loss: 0.00022261508274823427\n",
      "   Training decoder Loss: 0.00014400159125216305\n",
      "   Training sindy_z Loss: 531.5752563476562\n",
      "   Training sindy_x Loss: 0.702960193157196\n",
      "   Training sindy_regularization Loss: 0.8317461609840393\n",
      "   Validation Total Loss: 0.0006271678139455616\n",
      "   Validation decoder Loss: 0.00041440920904278755\n",
      "   Validation sindy_z Loss: 1337.759765625\n",
      "   Validation sindy_x Loss: 2.0444111824035645\n",
      "   Validation sindy_regularization Loss: 0.8317461609840393\n",
      "Decoder Loss Ratio: 0.002278, Decoder SINDy Loss Ratio: 0.185377\n",
      "Epoch 36\n",
      "Epoch 36\n",
      "   Training Total Loss: 0.00020876686903648078\n",
      "   Training decoder Loss: 0.00013190323079470545\n",
      "   Training sindy_z Loss: 522.31787109375\n",
      "   Training sindy_x Loss: 0.6851129531860352\n",
      "   Training sindy_regularization Loss: 0.8352348208427429\n",
      "   Validation Total Loss: 0.0005854607443325222\n",
      "   Validation decoder Loss: 0.00038260853034444153\n",
      "   Validation sindy_z Loss: 1313.87841796875\n",
      "   Validation sindy_x Loss: 1.944998860359192\n",
      "   Validation sindy_regularization Loss: 0.8352348208427429\n",
      "Decoder Loss Ratio: 0.002103, Decoder SINDy Loss Ratio: 0.176363\n",
      "Epoch 37\n",
      "Epoch 37\n",
      "   Training Total Loss: 0.00019794305262621492\n",
      "   Training decoder Loss: 0.00012216053437441587\n",
      "   Training sindy_z Loss: 513.0321655273438\n",
      "   Training sindy_x Loss: 0.6742144823074341\n",
      "   Training sindy_regularization Loss: 0.8361080884933472\n",
      "   Validation Total Loss: 0.0005532316281460226\n",
      "   Validation decoder Loss: 0.0003579130279831588\n",
      "   Validation sindy_z Loss: 1290.3782958984375\n",
      "   Validation sindy_x Loss: 1.8695753812789917\n",
      "   Validation sindy_regularization Loss: 0.8361080884933472\n",
      "Decoder Loss Ratio: 0.001967, Decoder SINDy Loss Ratio: 0.169524\n",
      "Epoch 38\n",
      "Epoch 38\n",
      "   Training Total Loss: 0.00018856031238101423\n",
      "   Training decoder Loss: 0.00011346144310664386\n",
      "   Training sindy_z Loss: 504.3069763183594\n",
      "   Training sindy_x Loss: 0.6674882173538208\n",
      "   Training sindy_regularization Loss: 0.8350048065185547\n",
      "   Validation Total Loss: 0.0005254886928014457\n",
      "   Validation decoder Loss: 0.00033623084891587496\n",
      "   Validation sindy_z Loss: 1268.662109375\n",
      "   Validation sindy_x Loss: 1.809077501296997\n",
      "   Validation sindy_regularization Loss: 0.8350048065185547\n",
      "Decoder Loss Ratio: 0.001848, Decoder SINDy Loss Ratio: 0.164038\n",
      "Epoch 39\n",
      "Epoch 39\n",
      "   Training Total Loss: 0.00017924420535564423\n",
      "   Training decoder Loss: 0.00010480177297722548\n",
      "   Training sindy_z Loss: 495.2216796875\n",
      "   Training sindy_x Loss: 0.6611419916152954\n",
      "   Training sindy_regularization Loss: 0.8328239321708679\n",
      "   Validation Total Loss: 0.0004998943768441677\n",
      "   Validation decoder Loss: 0.00031598014174960554\n",
      "   Validation sindy_z Loss: 1246.0341796875\n",
      "   Validation sindy_x Loss: 1.7558599710464478\n",
      "   Validation sindy_regularization Loss: 0.8328239321708679\n",
      "Decoder Loss Ratio: 0.001737, Decoder SINDy Loss Ratio: 0.159213\n",
      "Epoch 40\n",
      "Epoch 40\n",
      "   Training Total Loss: 0.00017208467761520296\n",
      "   Training decoder Loss: 9.812570351641625e-05\n",
      "   Training sindy_z Loss: 485.5077209472656\n",
      "   Training sindy_x Loss: 0.6564922332763672\n",
      "   Training sindy_regularization Loss: 0.830974817276001\n",
      "   Validation Total Loss: 0.0004772147221956402\n",
      "   Validation decoder Loss: 0.0002981139696203172\n",
      "   Validation sindy_z Loss: 1221.8970947265625\n",
      "   Validation sindy_x Loss: 1.707910180091858\n",
      "   Validation sindy_regularization Loss: 0.830974817276001\n",
      "Decoder Loss Ratio: 0.001639, Decoder SINDy Loss Ratio: 0.154865\n",
      "Epoch 41\n",
      "Epoch 41\n",
      "   Training Total Loss: 0.0001633732463233173\n",
      "   Training decoder Loss: 9.013144881464541e-05\n",
      "   Training sindy_z Loss: 475.9571228027344\n",
      "   Training sindy_x Loss: 0.6493467688560486\n",
      "   Training sindy_regularization Loss: 0.8307119011878967\n",
      "   Validation Total Loss: 0.0004539873043540865\n",
      "   Validation decoder Loss: 0.0002794377796817571\n",
      "   Validation sindy_z Loss: 1198.1021728515625\n",
      "   Validation sindy_x Loss: 1.6624242067337036\n",
      "   Validation sindy_regularization Loss: 0.8307119011878967\n",
      "Decoder Loss Ratio: 0.001536, Decoder SINDy Loss Ratio: 0.150740\n",
      "Epoch 42\n"
     ]
    }
   ],
   "source": [
    "num_experiments = 1\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_experiments):\n",
    "    print('EXPERIMENT %d' % i)\n",
    "\n",
    "    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "\n",
    "    params['save_name'] = 'lorenz_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "    \n",
    "    results_dict = train_network(training_data, validation_data, params)\n",
    "    df = df.append({**results_dict, **params}, ignore_index=True)\n",
    "\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
