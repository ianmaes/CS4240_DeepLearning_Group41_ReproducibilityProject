{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_lorenz import get_lorenz_data\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate training, validation, testing data\n",
    "noise_strength = 1e-6\n",
    "training_data = get_lorenz_data(1024, noise_strength=noise_strength)\n",
    "validation_data = get_lorenz_data(20, noise_strength=noise_strength)\n",
    "training_data['x'] = torch.tensor(training_data['x']).float().to('cuda')\n",
    "training_data['dx'] = torch.tensor(training_data['dx']).float().to('cuda')\n",
    "training_data['t'] = torch.tensor(training_data['t']).float().to('cuda')\n",
    "training_data['z'] = torch.tensor(training_data['z']).float().to('cuda')\n",
    "training_data['dz'] = torch.tensor(training_data['dz']).float().to('cuda')\n",
    "training_data['ddx'] = None\n",
    "\n",
    "validation_data['x'] = torch.tensor(validation_data['x']).float().to('cuda')\n",
    "validation_data['dx'] = torch.tensor(validation_data['dx']).float().to('cuda')\n",
    "validation_data['t'] = torch.tensor(validation_data['t']).float().to('cuda')\n",
    "validation_data['z'] = torch.tensor(validation_data['z']).float().to('cuda')\n",
    "validation_data['dz'] = torch.tensor(validation_data['dz']).float().to('cuda')\n",
    "validation_data['ddx'] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 64]\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "\n",
    "params['input_dim'] = 128\n",
    "params['latent_dim'] = 3\n",
    "params['model_order'] = 1\n",
    "params['poly_order'] = 3\n",
    "params['include_sine'] = False\n",
    "params['library_dim'] = library_size(params['latent_dim'], params['poly_order'], params['include_sine'], True)\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = True\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 3\n",
    "params['coefficient_mask'] = torch.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_z'] = 0\n",
    "params['loss_weight_sindy_x'] = 1e-4\n",
    "params['loss_weight_sindy_regularization'] = 1e-5\n",
    "\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [64,32]\n",
    "print(params['widths'][::-1])\n",
    "# training parameters\n",
    "params['epoch_size'] = training_data['x'].shape[0]\n",
    "params['batch_size'] = 1024\n",
    "params['learning_rate'] = 1e-3\n",
    "\n",
    "params['data_path'] = os.getcwd() + '/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 1\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 5\n",
    "params['refinement_epochs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def to_numpy(obj):\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.cpu().numpy()  # Convert tensor to numpy array\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: to_numpy(v) for k, v in obj.items()}  # Apply recursively to dictionaries\n",
    "    elif isinstance(obj, list):\n",
    "        return [to_numpy(v) for v in obj]  # Apply recursively to lists\n",
    "    else:\n",
    "        return obj  # Return the object as is if it's neither a tensor, list, nor dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n",
      "Device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:180: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'x': torch.tensor(data['x'][idxs], dtype=torch.float32).to(params['device']),\n",
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'dx': torch.tensor(data['dx'][idxs], dtype=torch.float32).to(params['device']),\n",
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:187: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  feed_dict['coefficient_mask'] = torch.tensor(params['coefficient_mask'], dtype=torch.float32).to(params['device'])\n",
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sindy_model_terms = [torch.sum(torch.tensor(params['coefficient_mask']))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch 0\n",
      "Epoch 0\n",
      "   Training Total Loss: 0.03906350955367088\n",
      "   Training decoder Loss: 0.0372636578977108\n",
      "   Training sindy_z Loss: 1208.0028076171875\n",
      "   Training sindy_x Loss: 17.92543601989746\n",
      "   Training sindy_regularization Loss: 0.7309862375259399\n",
      "   Validation Total Loss: 0.03904091939330101\n",
      "   Validation decoder Loss: 0.03726543113589287\n",
      "   Validation sindy_z Loss: 1243.0517578125\n",
      "   Validation sindy_x Loss: 17.68178367614746\n",
      "   Validation sindy_regularization Loss: 0.7309862375259399\n",
      "Decoder Loss Ratio: 0.197669, Decoder SINDy Loss Ratio: 1.383683\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "   Training Total Loss: 0.0328662283718586\n",
      "   Training decoder Loss: 0.031461019068956375\n",
      "   Training sindy_z Loss: 231.83126831054688\n",
      "   Training sindy_x Loss: 13.987504959106445\n",
      "   Training sindy_regularization Loss: 0.646133542060852\n",
      "   Validation Total Loss: 0.032850027084350586\n",
      "   Validation decoder Loss: 0.03147069737315178\n",
      "   Validation sindy_z Loss: 241.75306701660156\n",
      "   Validation sindy_x Loss: 13.728693008422852\n",
      "   Validation sindy_regularization Loss: 0.646133542060852\n",
      "Decoder Loss Ratio: 0.166931, Decoder SINDy Loss Ratio: 1.074335\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "   Training Total Loss: 0.014534614980220795\n",
      "   Training decoder Loss: 0.013193009421229362\n",
      "   Training sindy_z Loss: 145.2196807861328\n",
      "   Training sindy_x Loss: 13.360994338989258\n",
      "   Training sindy_regularization Loss: 0.5505563020706177\n",
      "   Validation Total Loss: 0.01504069846123457\n",
      "   Validation decoder Loss: 0.013721990399062634\n",
      "   Validation sindy_z Loss: 148.7256317138672\n",
      "   Validation sindy_x Loss: 13.132024765014648\n",
      "   Validation sindy_regularization Loss: 0.5505563020706177\n",
      "Decoder Loss Ratio: 0.072786, Decoder SINDy Loss Ratio: 1.027643\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "   Training Total Loss: 0.010946863330900669\n",
      "   Training decoder Loss: 0.00970462802797556\n",
      "   Training sindy_z Loss: 95.31137084960938\n",
      "   Training sindy_x Loss: 12.370027542114258\n",
      "   Training sindy_regularization Loss: 0.5233244299888611\n",
      "   Validation Total Loss: 0.01171445194631815\n",
      "   Validation decoder Loss: 0.010509498417377472\n",
      "   Validation sindy_z Loss: 101.3756332397461\n",
      "   Validation sindy_x Loss: 11.99720287322998\n",
      "   Validation sindy_regularization Loss: 0.5233244299888611\n",
      "Decoder Loss Ratio: 0.055746, Decoder SINDy Loss Ratio: 0.938838\n",
      "THRESHOLDING: 54 active coefficients\n",
      "Epoch 4\n",
      "Epoch 4\n",
      "   Training Total Loss: 0.009747207164764404\n",
      "   Training decoder Loss: 0.008563458919525146\n",
      "   Training sindy_z Loss: 75.12506103515625\n",
      "   Training sindy_x Loss: 11.785529136657715\n",
      "   Training sindy_regularization Loss: 0.5195114016532898\n",
      "   Validation Total Loss: 0.010596838779747486\n",
      "   Validation decoder Loss: 0.009451840072870255\n",
      "   Validation sindy_z Loss: 72.44461059570312\n",
      "   Validation sindy_x Loss: 11.398041725158691\n",
      "   Validation sindy_regularization Loss: 0.5195114016532898\n",
      "Decoder Loss Ratio: 0.050136, Decoder SINDy Loss Ratio: 0.891951\n",
      "REFINEMENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss_val, _, _ = autoencoder_network.define_loss(torch.tensor(train_dict['x'], dtype=torch.float32), torch.tensor(train_dict['dx'], dtype=torch.float32), params=params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "   Training Total Loss: 0.0064505282789468765\n",
      "   Training decoder Loss: 0.0057275001890957355\n",
      "   Training sindy_z Loss: 46.7758903503418\n",
      "   Training sindy_x Loss: 7.177398204803467\n",
      "   Training sindy_regularization Loss: 0.5287944078445435\n",
      "   Validation Total Loss: 0.009726793505251408\n",
      "   Validation decoder Loss: 0.008626635186374187\n",
      "   Validation sindy_z Loss: 60.284358978271484\n",
      "   Validation sindy_x Loss: 10.948705673217773\n",
      "   Validation sindy_regularization Loss: 0.5287944078445435\n",
      "Decoder Loss Ratio: 0.045759, Decoder SINDy Loss Ratio: 0.856788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss_val, final_losses, _ = autoencoder_network.define_loss(torch.tensor(validation_dict['x'], dtype=torch.float32), torch.tensor(validation_dict['dx'], dtype=torch.float32), params=params)\n",
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  _, _, _, _, _, _, _, sindy_predict = autoencoder_network(torch.tensor(validation_dict['x'], dtype=torch.float32), torch.tensor(validation_dict['dx'], dtype=torch.float32))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoefficient_mask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibrary_dim\u001b[39m\u001b[38;5;124m'\u001b[39m], params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatent_dim\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m      8\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlorenz_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS_\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m results_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m results_dict \u001b[38;5;241m=\u001b[39m to_numpy(results_dict)\n\u001b[0;32m     12\u001b[0m params \u001b[38;5;241m=\u001b[39m to_numpy(params)\n",
      "File \u001b[1;32mc:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:91\u001b[0m, in \u001b[0;36mtrain_network\u001b[1;34m(training_data, val_data, params)\u001b[0m\n\u001b[0;32m     89\u001b[0m     results_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_sindy_regularization\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m final_losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msindy_regularization\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     90\u001b[0m     results_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_losses\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(validation_losses)\n\u001b[1;32m---> 91\u001b[0m     results_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msindy_model_terms\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43msindy_model_terms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results_dict\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\envs\\deep_learning\\Lib\\site-packages\\torch\\_tensor.py:1062\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1062\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "num_experiments = 1\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_experiments):\n",
    "    print('EXPERIMENT %d' % i)\n",
    "\n",
    "    params['coefficient_mask'] = torch.ones((params['library_dim'], params['latent_dim']))\n",
    "\n",
    "    params['save_name'] = 'lorenz_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "    \n",
    "    results_dict = train_network(training_data, validation_data, params)\n",
    "    results_dict = to_numpy(results_dict)\n",
    "    params = to_numpy(params)\n",
    "    print(results_dict['validation_losses'][1]['decoder'])\n",
    "    print(params)\n",
    "    df = df._append({**results_dict, **params}, ignore_index=True)\n",
    "\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
