{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_lorenz import get_lorenz_data\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate training, validation, testing data\n",
    "noise_strength = 1e-6\n",
    "training_data = get_lorenz_data(1024, noise_strength=noise_strength)\n",
    "validation_data = get_lorenz_data(20, noise_strength=noise_strength)\n",
    "training_data['x'] = torch.tensor(training_data['x']).float()\n",
    "training_data['dx'] = torch.tensor(training_data['dx']).float()\n",
    "training_data['t'] = torch.tensor(training_data['t']).float()\n",
    "training_data['z'] = torch.tensor(training_data['z']).float()\n",
    "training_data['dz'] = torch.tensor(training_data['dz']).float()\n",
    "\n",
    "\n",
    "validation_data['x'] = torch.tensor(validation_data['x']).float()\n",
    "validation_data['dx'] = torch.tensor(validation_data['dx']).float()\n",
    "validation_data['t'] = torch.tensor(validation_data['t']).float()\n",
    "validation_data['z'] = torch.tensor(validation_data['z']).float()\n",
    "validation_data['dz'] = torch.tensor(validation_data['dz']).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 64]\n",
      "256000\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "\n",
    "params['input_dim'] = 128\n",
    "params['latent_dim'] = 3\n",
    "params['model_order'] = 1\n",
    "params['poly_order'] = 3\n",
    "params['include_sine'] = False\n",
    "params['library_dim'] = library_size(params['latent_dim'], params['poly_order'], params['include_sine'], True)\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = True\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 500\n",
    "params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_z'] = 1e-6\n",
    "params['loss_weight_sindy_x'] = 1e-4\n",
    "params['loss_weight_sindy_regularization'] = 1e-5\n",
    "\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [64,32]\n",
    "print(params['widths'][::-1])\n",
    "# training parameters\n",
    "params['epoch_size'] = training_data['x'].shape[0]\n",
    "print(training_data['x'].shape[0])\n",
    "params['batch_size'] = 1024\n",
    "params['learning_rate'] = 1e-3\n",
    "\n",
    "params['data_path'] = os.getcwd() + '/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 1\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 5001\n",
    "params['refinement_epochs'] = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:164: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'x': torch.tensor(data['x'][idxs], dtype=torch.float32),\n",
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:165: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'dx': torch.tensor(data['dx'][idxs], dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_total_loss, train_losses, _ = network.define_loss( torch.tensor(train_dict['x'], dtype=torch.float32) , torch.tensor(train_dict['dx'], dtype=torch.float32), params=params)\n",
      "c:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_total_loss, val_losses, _ = network.define_loss( torch.tensor(validation_dict['x'], dtype=torch.float32), torch.tensor(validation_dict['dx'], dtype=torch.float32),  params=params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "   Training Total Loss: 0.04026878625154495\n",
      "   Training decoder Loss: 0.03915810585021973\n",
      "   Training sindy_z Loss: 414.460693359375\n",
      "   Training sindy_x Loss: 11.021198272705078\n",
      "   Training sindy_regularization Loss: 0.8560728430747986\n",
      "   Validation Total Loss: 0.03221606835722923\n",
      "   Validation decoder Loss: 0.031160986050963402\n",
      "   Validation sindy_z Loss: 370.8631896972656\n",
      "   Validation sindy_x Loss: 10.465227127075195\n",
      "   Validation sindy_regularization Loss: 0.8560728430747986\n",
      "Decoder Loss Ratio: 0.167842, Decoder SINDy Loss Ratio: 0.999455\n",
      "Epoch 1\n",
      "Epoch 1\n",
      "   Training Total Loss: 0.030928656458854675\n",
      "   Training decoder Loss: 0.02990357205271721\n",
      "   Training sindy_z Loss: 713.27783203125\n",
      "   Training sindy_x Loss: 10.167985916137695\n",
      "   Training sindy_regularization Loss: 0.828544020652771\n",
      "   Validation Total Loss: 0.025548966601490974\n",
      "   Validation decoder Loss: 0.02455822378396988\n",
      "   Validation sindy_z Loss: 660.7398681640625\n",
      "   Validation sindy_x Loss: 9.824577331542969\n",
      "   Validation sindy_regularization Loss: 0.828544020652771\n",
      "Decoder Loss Ratio: 0.132277, Decoder SINDy Loss Ratio: 0.938271\n",
      "Epoch 2\n",
      "Epoch 2\n",
      "   Training Total Loss: 0.012037663720548153\n",
      "   Training decoder Loss: 0.01113663986325264\n",
      "   Training sindy_z Loss: 648.8126831054688\n",
      "   Training sindy_x Loss: 8.930341720581055\n",
      "   Training sindy_regularization Loss: 0.7989957332611084\n",
      "   Validation Total Loss: 0.011364209465682507\n",
      "   Validation decoder Loss: 0.010433594696223736\n",
      "   Validation sindy_z Loss: 689.2206420898438\n",
      "   Validation sindy_x Loss: 9.226253509521484\n",
      "   Validation sindy_regularization Loss: 0.7989957332611084\n",
      "Decoder Loss Ratio: 0.056198, Decoder SINDy Loss Ratio: 0.881130\n",
      "Epoch 3\n",
      "Epoch 3\n",
      "   Training Total Loss: 0.008936566300690174\n",
      "   Training decoder Loss: 0.008176238276064396\n",
      "   Training sindy_z Loss: 590.1362915039062\n",
      "   Training sindy_x Loss: 7.524225234985352\n",
      "   Training sindy_regularization Loss: 0.790565550327301\n",
      "   Validation Total Loss: 0.008668520487844944\n",
      "   Validation decoder Loss: 0.007861250080168247\n",
      "   Validation sindy_z Loss: 597.6947631835938\n",
      "   Validation sindy_x Loss: 7.993639945983887\n",
      "   Validation sindy_regularization Loss: 0.790565550327301\n",
      "Decoder Loss Ratio: 0.042343, Decoder SINDy Loss Ratio: 0.763412\n",
      "Epoch 4\n",
      "Epoch 4\n",
      "   Training Total Loss: 0.007748214993625879\n",
      "   Training decoder Loss: 0.007056715898215771\n",
      "   Training sindy_z Loss: 625.6351318359375\n",
      "   Training sindy_x Loss: 6.832955360412598\n",
      "   Training sindy_regularization Loss: 0.8203617930412292\n",
      "   Validation Total Loss: 0.007623190525919199\n",
      "   Validation decoder Loss: 0.006902668159455061\n",
      "   Validation sindy_z Loss: 624.5155029296875\n",
      "   Validation sindy_x Loss: 7.12318754196167\n",
      "   Validation sindy_regularization Loss: 0.8203617930412292\n",
      "Decoder Loss Ratio: 0.037180, Decoder SINDy Loss Ratio: 0.680282\n",
      "Epoch 5\n",
      "Epoch 5\n",
      "   Training Total Loss: 0.006774228531867266\n",
      "   Training decoder Loss: 0.0061106630600988865\n",
      "   Training sindy_z Loss: 670.9540405273438\n",
      "   Training sindy_x Loss: 6.5501861572265625\n",
      "   Training sindy_regularization Loss: 0.8546581268310547\n",
      "   Validation Total Loss: 0.006810673512518406\n",
      "   Validation decoder Loss: 0.006147429812699556\n",
      "   Validation sindy_z Loss: 657.8892822265625\n",
      "   Validation sindy_x Loss: 6.546971321105957\n",
      "   Validation sindy_regularization Loss: 0.8546581268310547\n",
      "Decoder Loss Ratio: 0.033112, Decoder SINDy Loss Ratio: 0.625252\n",
      "Epoch 6\n",
      "Epoch 6\n",
      "   Training Total Loss: 0.00590737909078598\n",
      "   Training decoder Loss: 0.00527718011289835\n",
      "   Training sindy_z Loss: 696.0498046875\n",
      "   Training sindy_x Loss: 6.21446418762207\n",
      "   Training sindy_regularization Loss: 0.8752782344818115\n",
      "   Validation Total Loss: 0.006100705359131098\n",
      "   Validation decoder Loss: 0.005489837843924761\n",
      "   Validation sindy_z Loss: 670.0662841796875\n",
      "   Validation sindy_x Loss: 6.021150588989258\n",
      "   Validation sindy_regularization Loss: 0.8752782344818115\n",
      "Decoder Loss Ratio: 0.029570, Decoder SINDy Loss Ratio: 0.575035\n",
      "Epoch 7\n",
      "Epoch 7\n",
      "   Training Total Loss: 0.005321417935192585\n",
      "   Training decoder Loss: 0.00474184425547719\n",
      "   Training sindy_z Loss: 688.85498046875\n",
      "   Training sindy_x Loss: 5.706038475036621\n",
      "   Training sindy_regularization Loss: 0.8969829678535461\n",
      "   Validation Total Loss: 0.005608494859188795\n",
      "   Validation decoder Loss: 0.005050852429121733\n",
      "   Validation sindy_z Loss: 652.4920654296875\n",
      "   Validation sindy_x Loss: 5.486725330352783\n",
      "   Validation sindy_regularization Loss: 0.8969829678535461\n",
      "Decoder Loss Ratio: 0.027205, Decoder SINDy Loss Ratio: 0.523996\n",
      "Epoch 8\n",
      "Epoch 8\n",
      "   Training Total Loss: 0.004946417640894651\n",
      "   Training decoder Loss: 0.004414740018546581\n",
      "   Training sindy_z Loss: 664.2900390625\n",
      "   Training sindy_x Loss: 5.224945545196533\n",
      "   Training sindy_regularization Loss: 0.918343722820282\n",
      "   Validation Total Loss: 0.005287045147269964\n",
      "   Validation decoder Loss: 0.004769172519445419\n",
      "   Validation sindy_z Loss: 622.1077270507812\n",
      "   Validation sindy_x Loss: 5.08689546585083\n",
      "   Validation sindy_regularization Loss: 0.918343722820282\n",
      "Decoder Loss Ratio: 0.025688, Decoder SINDy Loss Ratio: 0.485811\n",
      "Epoch 9\n",
      "Epoch 9\n",
      "   Training Total Loss: 0.004707942251116037\n",
      "   Training decoder Loss: 0.004210182931274176\n",
      "   Training sindy_z Loss: 646.0228881835938\n",
      "   Training sindy_x Loss: 4.884738922119141\n",
      "   Training sindy_regularization Loss: 0.9285094738006592\n",
      "   Validation Total Loss: 0.005059256684035063\n",
      "   Validation decoder Loss: 0.004564679227769375\n",
      "   Validation sindy_z Loss: 601.539306640625\n",
      "   Validation sindy_x Loss: 4.85292387008667\n",
      "   Validation sindy_regularization Loss: 0.9285094738006592\n",
      "Decoder Loss Ratio: 0.024587, Decoder SINDy Loss Ratio: 0.463466\n",
      "Epoch 10\n",
      "Epoch 10\n",
      "   Training Total Loss: 0.004552156198769808\n",
      "   Training decoder Loss: 0.004067963920533657\n",
      "   Training sindy_z Loss: 608.7850341796875\n",
      "   Training sindy_x Loss: 4.748897075653076\n",
      "   Training sindy_regularization Loss: 0.9302319884300232\n",
      "   Validation Total Loss: 0.004910958465188742\n",
      "   Validation decoder Loss: 0.004426120780408382\n",
      "   Validation sindy_z Loss: 564.771484375\n",
      "   Validation sindy_x Loss: 4.755350589752197\n",
      "   Validation sindy_regularization Loss: 0.9302319884300232\n",
      "Decoder Loss Ratio: 0.023840, Decoder SINDy Loss Ratio: 0.454148\n",
      "Epoch 11\n",
      "Epoch 11\n",
      "   Training Total Loss: 0.0044875917956233025\n",
      "   Training decoder Loss: 0.004017014987766743\n",
      "   Training sindy_z Loss: 588.1607055664062\n",
      "   Training sindy_x Loss: 4.6129469871521\n",
      "   Training sindy_regularization Loss: 0.9282000064849854\n",
      "   Validation Total Loss: 0.0048299916088581085\n",
      "   Validation decoder Loss: 0.004357624799013138\n",
      "   Validation sindy_z Loss: 544.2205810546875\n",
      "   Validation sindy_x Loss: 4.630847930908203\n",
      "   Validation sindy_regularization Loss: 0.9282000064849854\n",
      "Decoder Loss Ratio: 0.023471, Decoder SINDy Loss Ratio: 0.442257\n",
      "Epoch 12\n",
      "Epoch 12\n",
      "   Training Total Loss: 0.004336133133620024\n",
      "   Training decoder Loss: 0.0038800607435405254\n",
      "   Training sindy_z Loss: 562.3134155273438\n",
      "   Training sindy_x Loss: 4.468592643737793\n",
      "   Training sindy_regularization Loss: 0.921295702457428\n",
      "   Validation Total Loss: 0.0046517993323504925\n",
      "   Validation decoder Loss: 0.004190612118691206\n",
      "   Validation sindy_z Loss: 517.2506103515625\n",
      "   Validation sindy_x Loss: 4.5197434425354\n",
      "   Validation sindy_regularization Loss: 0.921295702457428\n",
      "Decoder Loss Ratio: 0.022572, Decoder SINDy Loss Ratio: 0.431647\n",
      "Epoch 13\n",
      "Epoch 13\n",
      "   Training Total Loss: 0.004235618282109499\n",
      "   Training decoder Loss: 0.003795536234974861\n",
      "   Training sindy_z Loss: 543.9780883789062\n",
      "   Training sindy_x Loss: 4.309688091278076\n",
      "   Training sindy_regularization Loss: 0.9113448262214661\n",
      "   Validation Total Loss: 0.004516676068305969\n",
      "   Validation decoder Loss: 0.004069012589752674\n",
      "   Validation sindy_z Loss: 497.1039123535156\n",
      "   Validation sindy_x Loss: 4.385499000549316\n",
      "   Validation sindy_regularization Loss: 0.9113448262214661\n",
      "Decoder Loss Ratio: 0.021917, Decoder SINDy Loss Ratio: 0.418826\n",
      "Epoch 14\n",
      "Epoch 14\n",
      "   Training Total Loss: 0.00412118062376976\n",
      "   Training decoder Loss: 0.0036988642532378435\n",
      "   Training sindy_z Loss: 528.5068969726562\n",
      "   Training sindy_x Loss: 4.13340425491333\n",
      "   Training sindy_regularization Loss: 0.8976169228553772\n",
      "   Validation Total Loss: 0.004360452760010958\n",
      "   Validation decoder Loss: 0.003927289042621851\n",
      "   Validation sindy_z Loss: 478.82354736328125\n",
      "   Validation sindy_x Loss: 4.241877555847168\n",
      "   Validation sindy_regularization Loss: 0.8976169228553772\n",
      "Decoder Loss Ratio: 0.021153, Decoder SINDy Loss Ratio: 0.405110\n",
      "Epoch 15\n",
      "Epoch 15\n",
      "   Training Total Loss: 0.003980881068855524\n",
      "   Training decoder Loss: 0.0035789543762803078\n",
      "   Training sindy_z Loss: 516.851806640625\n",
      "   Training sindy_x Loss: 3.9311912059783936\n",
      "   Training sindy_regularization Loss: 0.8807547092437744\n",
      "   Validation Total Loss: 0.004177072551101446\n",
      "   Validation decoder Loss: 0.0037612731102854013\n",
      "   Validation sindy_z Loss: 463.27880859375\n",
      "   Validation sindy_x Loss: 4.069920539855957\n",
      "   Validation sindy_regularization Loss: 0.8807547092437744\n",
      "Decoder Loss Ratio: 0.020259, Decoder SINDy Loss Ratio: 0.388687\n",
      "Epoch 16\n",
      "Epoch 16\n",
      "   Training Total Loss: 0.00383620522916317\n",
      "   Training decoder Loss: 0.0034561348147690296\n",
      "   Training sindy_z Loss: 508.8053283691406\n",
      "   Training sindy_x Loss: 3.714341402053833\n",
      "   Training sindy_regularization Loss: 0.8636099100112915\n",
      "   Validation Total Loss: 0.003998898901045322\n",
      "   Validation decoder Loss: 0.0036022556014358997\n",
      "   Validation sindy_z Loss: 451.0335693359375\n",
      "   Validation sindy_x Loss: 3.8800723552703857\n",
      "   Validation sindy_regularization Loss: 0.8636099100112915\n",
      "Decoder Loss Ratio: 0.019403, Decoder SINDy Loss Ratio: 0.370557\n",
      "Epoch 17\n",
      "Epoch 17\n",
      "   Training Total Loss: 0.00371684436686337\n",
      "   Training decoder Loss: 0.003356924979016185\n",
      "   Training sindy_z Loss: 504.4110412597656\n",
      "   Training sindy_x Loss: 3.5140318870544434\n",
      "   Training sindy_regularization Loss: 0.8516271114349365\n",
      "   Validation Total Loss: 0.0038507776334881783\n",
      "   Validation decoder Loss: 0.003471920732408762\n",
      "   Validation sindy_z Loss: 443.1015319824219\n",
      "   Validation sindy_x Loss: 3.7034075260162354\n",
      "   Validation sindy_regularization Loss: 0.8516271114349365\n",
      "Decoder Loss Ratio: 0.018701, Decoder SINDy Loss Ratio: 0.353685\n",
      "Epoch 18\n",
      "Epoch 18\n",
      "   Training Total Loss: 0.0036307035479694605\n",
      "   Training decoder Loss: 0.0032861032523214817\n",
      "   Training sindy_z Loss: 499.6033020019531\n",
      "   Training sindy_x Loss: 3.361664295196533\n",
      "   Training sindy_regularization Loss: 0.8433739542961121\n",
      "   Validation Total Loss: 0.0037303222343325615\n",
      "   Validation decoder Loss: 0.0033682319335639477\n",
      "   Validation sindy_z Loss: 437.13134765625\n",
      "   Validation sindy_x Loss: 3.5365655422210693\n",
      "   Validation sindy_regularization Loss: 0.8433739542961121\n",
      "Decoder Loss Ratio: 0.018142, Decoder SINDy Loss Ratio: 0.337751\n",
      "Epoch 19\n",
      "Epoch 19\n",
      "   Training Total Loss: 0.003574011381715536\n",
      "   Training decoder Loss: 0.0032410703133791685\n",
      "   Training sindy_z Loss: 494.3135681152344\n",
      "   Training sindy_x Loss: 3.2456791400909424\n",
      "   Training sindy_regularization Loss: 0.8373167514801025\n",
      "   Validation Total Loss: 0.0036397019866853952\n",
      "   Validation decoder Loss: 0.003292185952886939\n",
      "   Validation sindy_z Loss: 431.94781494140625\n",
      "   Validation sindy_x Loss: 3.3914296627044678\n",
      "   Validation sindy_regularization Loss: 0.8373167514801025\n",
      "Decoder Loss Ratio: 0.017733, Decoder SINDy Loss Ratio: 0.323890\n",
      "Epoch 20\n",
      "Epoch 20\n",
      "   Training Total Loss: 0.003519866382703185\n",
      "   Training decoder Loss: 0.0031952345743775368\n",
      "   Training sindy_z Loss: 490.1427307128906\n",
      "   Training sindy_x Loss: 3.1630775928497314\n",
      "   Training sindy_regularization Loss: 0.8323928713798523\n",
      "   Validation Total Loss: 0.0035709566436707973\n",
      "   Validation decoder Loss: 0.003235062351450324\n",
      "   Validation sindy_z Loss: 427.83251953125\n",
      "   Validation sindy_x Loss: 3.2757034301757812\n",
      "   Validation sindy_regularization Loss: 0.8323928713798523\n",
      "Decoder Loss Ratio: 0.017425, Decoder SINDy Loss Ratio: 0.312838\n",
      "Epoch 21\n",
      "Epoch 21\n",
      "   Training Total Loss: 0.003466176800429821\n",
      "   Training decoder Loss: 0.0031481089536100626\n",
      "   Training sindy_z Loss: 488.9388732910156\n",
      "   Training sindy_x Loss: 3.097628116607666\n",
      "   Training sindy_regularization Loss: 0.8305095434188843\n",
      "   Validation Total Loss: 0.003510345472022891\n",
      "   Validation decoder Loss: 0.0031842126045376062\n",
      "   Validation sindy_z Loss: 426.736328125\n",
      "   Validation sindy_x Loss: 3.1782772541046143\n",
      "   Validation sindy_regularization Loss: 0.8305095434188843\n",
      "Decoder Loss Ratio: 0.017151, Decoder SINDy Loss Ratio: 0.303533\n",
      "Epoch 22\n",
      "Epoch 22\n",
      "   Training Total Loss: 0.0034138131886720657\n",
      "   Training decoder Loss: 0.003104011993855238\n",
      "   Training sindy_z Loss: 490.9923095703125\n",
      "   Training sindy_x Loss: 3.0150279998779297\n",
      "   Training sindy_regularization Loss: 0.8298383951187134\n",
      "   Validation Total Loss: 0.0034479701425880194\n",
      "   Validation decoder Loss: 0.003131292760372162\n",
      "   Validation sindy_z Loss: 428.8955383300781\n",
      "   Validation sindy_x Loss: 3.0837903022766113\n",
      "   Validation sindy_regularization Loss: 0.8298383951187134\n",
      "Decoder Loss Ratio: 0.016866, Decoder SINDy Loss Ratio: 0.294510\n",
      "Epoch 23\n",
      "Epoch 23\n",
      "   Training Total Loss: 0.00335689727216959\n",
      "   Training decoder Loss: 0.0030509866774082184\n",
      "   Training sindy_z Loss: 489.3401184082031\n",
      "   Training sindy_x Loss: 2.976104736328125\n",
      "   Training sindy_regularization Loss: 0.830007791519165\n",
      "   Validation Total Loss: 0.0033930144272744656\n",
      "   Validation decoder Loss: 0.0030830807518213987\n",
      "   Validation sindy_z Loss: 427.0058898925781\n",
      "   Validation sindy_x Loss: 3.0163352489471436\n",
      "   Validation sindy_regularization Loss: 0.830007791519165\n",
      "Decoder Loss Ratio: 0.016606, Decoder SINDy Loss Ratio: 0.288067\n",
      "Epoch 24\n",
      "Epoch 24\n",
      "   Training Total Loss: 0.0033006155863404274\n",
      "   Training decoder Loss: 0.0029988521710038185\n",
      "   Training sindy_z Loss: 491.5921936035156\n",
      "   Training sindy_x Loss: 2.934626579284668\n",
      "   Training sindy_regularization Loss: 0.8300955891609192\n",
      "   Validation Total Loss: 0.0033362354151904583\n",
      "   Validation decoder Loss: 0.003033272922039032\n",
      "   Validation sindy_z Loss: 428.6203918457031\n",
      "   Validation sindy_x Loss: 2.9466171264648438\n",
      "   Validation sindy_regularization Loss: 0.8300955891609192\n",
      "Decoder Loss Ratio: 0.016338, Decoder SINDy Loss Ratio: 0.281409\n",
      "Epoch 25\n",
      "Epoch 25\n",
      "   Training Total Loss: 0.0032461180817335844\n",
      "   Training decoder Loss: 0.002947523258626461\n",
      "   Training sindy_z Loss: 495.3200378417969\n",
      "   Training sindy_x Loss: 2.902952194213867\n",
      "   Training sindy_regularization Loss: 0.8299633264541626\n",
      "   Validation Total Loss: 0.0032816946040838957\n",
      "   Validation decoder Loss: 0.0029854425229132175\n",
      "   Validation sindy_z Loss: 431.4111022949219\n",
      "   Validation sindy_x Loss: 2.8795247077941895\n",
      "   Validation sindy_regularization Loss: 0.8299633264541626\n",
      "Decoder Loss Ratio: 0.016080, Decoder SINDy Loss Ratio: 0.275002\n",
      "Epoch 26\n",
      "Epoch 26\n",
      "   Training Total Loss: 0.003186955349519849\n",
      "   Training decoder Loss: 0.002892118878662586\n",
      "   Training sindy_z Loss: 502.121826171875\n",
      "   Training sindy_x Loss: 2.8654117584228516\n",
      "   Training sindy_regularization Loss: 0.8295358419418335\n",
      "   Validation Total Loss: 0.0032219248823821545\n",
      "   Validation decoder Loss: 0.0029327895026654005\n",
      "   Validation sindy_z Loss: 437.05474853515625\n",
      "   Validation sindy_x Loss: 2.8083996772766113\n",
      "   Validation sindy_regularization Loss: 0.8295358419418335\n",
      "Decoder Loss Ratio: 0.015797, Decoder SINDy Loss Ratio: 0.268209\n",
      "Epoch 27\n",
      "Epoch 27\n",
      "   Training Total Loss: 0.0031282827258110046\n",
      "   Training decoder Loss: 0.0028365314938127995\n",
      "   Training sindy_z Loss: 509.1443786621094\n",
      "   Training sindy_x Loss: 2.834623336791992\n",
      "   Training sindy_regularization Loss: 0.8288944363594055\n",
      "   Validation Total Loss: 0.003163215471431613\n",
      "   Validation decoder Loss: 0.0028808482456952333\n",
      "   Validation sindy_z Loss: 443.0364074707031\n",
      "   Validation sindy_x Loss: 2.74078106880188\n",
      "   Validation sindy_regularization Loss: 0.8288944363594055\n",
      "Decoder Loss Ratio: 0.015517, Decoder SINDy Loss Ratio: 0.261751\n",
      "Epoch 28\n",
      "Epoch 28\n",
      "   Training Total Loss: 0.003062732517719269\n",
      "   Training decoder Loss: 0.0027739540673792362\n",
      "   Training sindy_z Loss: 516.17626953125\n",
      "   Training sindy_x Loss: 2.8049705028533936\n",
      "   Training sindy_regularization Loss: 0.8281400203704834\n",
      "   Validation Total Loss: 0.0030986247584223747\n",
      "   Validation decoder Loss: 0.002822883427143097\n",
      "   Validation sindy_z Loss: 449.3484802246094\n",
      "   Validation sindy_x Loss: 2.6746010780334473\n",
      "   Validation sindy_regularization Loss: 0.8281400203704834\n",
      "Decoder Loss Ratio: 0.015205, Decoder SINDy Loss Ratio: 0.255431\n",
      "Epoch 29\n",
      "Epoch 29\n",
      "   Training Total Loss: 0.0029856860637664795\n",
      "   Training decoder Loss: 0.0026992252096533775\n",
      "   Training sindy_z Loss: 520.6638793945312\n",
      "   Training sindy_x Loss: 2.781938076019287\n",
      "   Training sindy_regularization Loss: 0.8267157673835754\n",
      "   Validation Total Loss: 0.003024894744157791\n",
      "   Validation decoder Loss: 0.0027555394917726517\n",
      "   Validation sindy_z Loss: 453.8057556152344\n",
      "   Validation sindy_x Loss: 2.6108813285827637\n",
      "   Validation sindy_regularization Loss: 0.8267157673835754\n",
      "Decoder Loss Ratio: 0.014842, Decoder SINDy Loss Ratio: 0.249346\n",
      "Epoch 30\n",
      "Epoch 30\n",
      "   Training Total Loss: 0.002883442211896181\n",
      "   Training decoder Loss: 0.0025974917225539684\n",
      "   Training sindy_z Loss: 519.3681030273438\n",
      "   Training sindy_x Loss: 2.77693247795105\n",
      "   Training sindy_regularization Loss: 0.8257297873497009\n",
      "   Validation Total Loss: 0.0029300472233444452\n",
      "   Validation decoder Loss: 0.0026667078491300344\n",
      "   Validation sindy_z Loss: 453.7204895019531\n",
      "   Validation sindy_x Loss: 2.5508203506469727\n",
      "   Validation sindy_regularization Loss: 0.8257297873497009\n",
      "Decoder Loss Ratio: 0.014364, Decoder SINDy Loss Ratio: 0.243610\n",
      "Epoch 31\n",
      "Epoch 31\n",
      "   Training Total Loss: 0.002715881448239088\n",
      "   Training decoder Loss: 0.002425379352644086\n",
      "   Training sindy_z Loss: 506.3448486328125\n",
      "   Training sindy_x Loss: 2.8225977420806885\n",
      "   Training sindy_regularization Loss: 0.8242167234420776\n",
      "   Validation Total Loss: 0.0027783026453107595\n",
      "   Validation decoder Loss: 0.0025192061439156532\n",
      "   Validation sindy_z Loss: 444.2934875488281\n",
      "   Validation sindy_x Loss: 2.508543014526367\n",
      "   Validation sindy_regularization Loss: 0.8242167234420776\n",
      "Decoder Loss Ratio: 0.013569, Decoder SINDy Loss Ratio: 0.239572\n",
      "Epoch 32\n",
      "Epoch 32\n",
      "   Training Total Loss: 0.0023654731921851635\n",
      "   Training decoder Loss: 0.0020531911868602037\n",
      "   Training sindy_z Loss: 478.8428955078125\n",
      "   Training sindy_x Loss: 3.040764093399048\n",
      "   Training sindy_regularization Loss: 0.8205562829971313\n",
      "   Validation Total Loss: 0.0024560773745179176\n",
      "   Validation decoder Loss: 0.002189416904002428\n",
      "   Validation sindy_z Loss: 425.05169677734375\n",
      "   Validation sindy_x Loss: 2.584547281265259\n",
      "   Validation sindy_regularization Loss: 0.8205562829971313\n",
      "Decoder Loss Ratio: 0.011793, Decoder SINDy Loss Ratio: 0.246831\n",
      "Epoch 33\n",
      "Epoch 33\n",
      "   Training Total Loss: 0.0017918432131409645\n",
      "   Training decoder Loss: 0.0014312872663140297\n",
      "   Training sindy_z Loss: 442.2829895019531\n",
      "   Training sindy_x Loss: 3.524142265319824\n",
      "   Training sindy_regularization Loss: 0.814177930355072\n",
      "   Validation Total Loss: 0.0018634601728990674\n",
      "   Validation decoder Loss: 0.0015696854097768664\n",
      "   Validation sindy_z Loss: 401.094970703125\n",
      "   Validation sindy_x Loss: 2.856330156326294\n",
      "   Validation sindy_regularization Loss: 0.814177930355072\n",
      "Decoder Loss Ratio: 0.008455, Decoder SINDy Loss Ratio: 0.272787\n",
      "Epoch 34\n",
      "Epoch 34\n",
      "   Training Total Loss: 0.0015261461958289146\n",
      "   Training decoder Loss: 0.001140098087489605\n",
      "   Training sindy_z Loss: 428.2806701660156\n",
      "   Training sindy_x Loss: 3.7794442176818848\n",
      "   Training sindy_regularization Loss: 0.8103711605072021\n",
      "   Validation Total Loss: 0.0015361306723207235\n",
      "   Validation decoder Loss: 0.001228011678904295\n",
      "   Validation sindy_z Loss: 399.8558349609375\n",
      "   Validation sindy_x Loss: 3.0001540184020996\n",
      "   Validation sindy_regularization Loss: 0.8103711605072021\n",
      "Decoder Loss Ratio: 0.006614, Decoder SINDy Loss Ratio: 0.286522\n",
      "Epoch 35\n",
      "Epoch 35\n",
      "   Training Total Loss: 0.0013072581496089697\n",
      "   Training decoder Loss: 0.0009246914414688945\n",
      "   Training sindy_z Loss: 422.6449279785156\n",
      "   Training sindy_x Loss: 3.744070291519165\n",
      "   Training sindy_regularization Loss: 0.8159658312797546\n",
      "   Validation Total Loss: 0.0012482964666560292\n",
      "   Validation decoder Loss: 0.0009464582544751465\n",
      "   Validation sindy_z Loss: 402.7874450683594\n",
      "   Validation sindy_x Loss: 2.9367856979370117\n",
      "   Validation sindy_regularization Loss: 0.8159658312797546\n",
      "Decoder Loss Ratio: 0.005098, Decoder SINDy Loss Ratio: 0.280470\n",
      "Epoch 36\n",
      "Epoch 36\n",
      "   Training Total Loss: 0.001113507547415793\n",
      "   Training decoder Loss: 0.0007495068712159991\n",
      "   Training sindy_z Loss: 418.2540283203125\n",
      "   Training sindy_x Loss: 3.5577552318573\n",
      "   Training sindy_regularization Loss: 0.8225132822990417\n",
      "   Validation Total Loss: 0.0010099748615175486\n",
      "   Validation decoder Loss: 0.0007243587751872838\n",
      "   Validation sindy_z Loss: 405.1874694824219\n",
      "   Validation sindy_x Loss: 2.7739098072052\n",
      "   Validation sindy_regularization Loss: 0.8225132822990417\n",
      "Decoder Loss Ratio: 0.003902, Decoder SINDy Loss Ratio: 0.264915\n",
      "Epoch 37\n",
      "Epoch 37\n",
      "   Training Total Loss: 0.0009927315404638648\n",
      "   Training decoder Loss: 0.0006547822849825025\n",
      "   Training sindy_z Loss: 413.0374755859375\n",
      "   Training sindy_x Loss: 3.2958626747131348\n",
      "   Training sindy_regularization Loss: 0.8362976312637329\n",
      "   Validation Total Loss: 0.0008617262938059866\n",
      "   Validation decoder Loss: 0.0005951408529654145\n",
      "   Validation sindy_z Loss: 405.1874694824219\n",
      "   Validation sindy_x Loss: 2.5822243690490723\n",
      "   Validation sindy_regularization Loss: 0.8362976312637329\n",
      "Decoder Loss Ratio: 0.003206, Decoder SINDy Loss Ratio: 0.246609\n",
      "Epoch 38\n",
      "Epoch 38\n",
      "   Training Total Loss: 0.0008909991593100131\n",
      "   Training decoder Loss: 0.0005844688275828958\n",
      "   Training sindy_z Loss: 403.36376953125\n",
      "   Training sindy_x Loss: 2.9799411296844482\n",
      "   Training sindy_regularization Loss: 0.8536239266395569\n",
      "   Validation Total Loss: 0.0007549030124209821\n",
      "   Validation decoder Loss: 0.0005100618582218885\n",
      "   Validation sindy_z Loss: 399.25677490234375\n",
      "   Validation sindy_x Loss: 2.3630495071411133\n",
      "   Validation sindy_regularization Loss: 0.8536239266395569\n",
      "Decoder Loss Ratio: 0.002747, Decoder SINDy Loss Ratio: 0.225677\n",
      "Epoch 39\n",
      "Epoch 39\n",
      "   Training Total Loss: 0.0007580615347251296\n",
      "   Training decoder Loss: 0.00047921514487825334\n",
      "   Training sindy_z Loss: 387.4290466308594\n",
      "   Training sindy_x Loss: 2.7013778686523438\n",
      "   Training sindy_regularization Loss: 0.8708624243736267\n",
      "   Validation Total Loss: 0.0006372060743160546\n",
      "   Validation decoder Loss: 0.00041096119093708694\n",
      "   Validation sindy_z Loss: 386.8187255859375\n",
      "   Validation sindy_x Loss: 2.1753623485565186\n",
      "   Validation sindy_regularization Loss: 0.8708624243736267\n",
      "Decoder Loss Ratio: 0.002214, Decoder SINDy Loss Ratio: 0.207752\n",
      "Epoch 40\n",
      "Epoch 40\n",
      "   Training Total Loss: 0.000708918203599751\n",
      "   Training decoder Loss: 0.00045489525655284524\n",
      "   Training sindy_z Loss: 369.1305847167969\n",
      "   Training sindy_x Loss: 2.451555013656616\n",
      "   Training sindy_regularization Loss: 0.8867464661598206\n",
      "   Validation Total Loss: 0.0005897039663977921\n",
      "   Validation decoder Loss: 0.00037939214962534606\n",
      "   Validation sindy_z Loss: 370.69482421875\n",
      "   Validation sindy_x Loss: 2.0144433975219727\n",
      "   Validation sindy_regularization Loss: 0.8867464661598206\n",
      "Decoder Loss Ratio: 0.002044, Decoder SINDy Loss Ratio: 0.192384\n",
      "Epoch 41\n",
      "Epoch 41\n",
      "   Training Total Loss: 0.0006049598450772464\n",
      "   Training decoder Loss: 0.0003683494287542999\n",
      "   Training sindy_z Loss: 352.4831848144531\n",
      "   Training sindy_x Loss: 2.276305675506592\n",
      "   Training sindy_regularization Loss: 0.897988498210907\n",
      "   Validation Total Loss: 0.000508850091136992\n",
      "   Validation decoder Loss: 0.000308910763124004\n",
      "   Validation sindy_z Loss: 355.2188720703125\n",
      "   Validation sindy_x Loss: 1.9095947742462158\n",
      "   Validation sindy_regularization Loss: 0.897988498210907\n",
      "Decoder Loss Ratio: 0.001664, Decoder SINDy Loss Ratio: 0.182371\n",
      "Epoch 42\n",
      "Epoch 42\n",
      "   Training Total Loss: 0.0005632338579744101\n",
      "   Training decoder Loss: 0.0003428693162277341\n",
      "   Training sindy_z Loss: 336.3265686035156\n",
      "   Training sindy_x Loss: 2.1127431392669678\n",
      "   Training sindy_regularization Loss: 0.9090254306793213\n",
      "   Validation Total Loss: 0.00047941270167939365\n",
      "   Validation decoder Loss: 0.0002903851855080575\n",
      "   Validation sindy_z Loss: 339.5378723144531\n",
      "   Validation sindy_x Loss: 1.7993724346160889\n",
      "   Validation sindy_regularization Loss: 0.9090254306793213\n",
      "Decoder Loss Ratio: 0.001564, Decoder SINDy Loss Ratio: 0.171845\n",
      "Epoch 43\n",
      "Epoch 43\n",
      "   Training Total Loss: 0.0004958650097250938\n",
      "   Training decoder Loss: 0.000289101735688746\n",
      "   Training sindy_z Loss: 322.2652893066406\n",
      "   Training sindy_x Loss: 1.9754503965377808\n",
      "   Training sindy_regularization Loss: 0.9218252897262573\n",
      "   Validation Total Loss: 0.00042030037730000913\n",
      "   Validation decoder Loss: 0.00024010741617530584\n",
      "   Validation sindy_z Loss: 325.0053405761719\n",
      "   Validation sindy_x Loss: 1.7097468376159668\n",
      "   Validation sindy_regularization Loss: 0.9218252897262573\n",
      "Decoder Loss Ratio: 0.001293, Decoder SINDy Loss Ratio: 0.163285\n",
      "Epoch 44\n",
      "Epoch 44\n",
      "   Training Total Loss: 0.00045637862058356404\n",
      "   Training decoder Loss: 0.0002612004755064845\n",
      "   Training sindy_z Loss: 310.5327453613281\n",
      "   Training sindy_x Loss: 1.858689546585083\n",
      "   Training sindy_regularization Loss: 0.9309194684028625\n",
      "   Validation Total Loss: 0.00039090373320505023\n",
      "   Validation decoder Loss: 0.00021926012414041907\n",
      "   Validation sindy_z Loss: 312.8111877441406\n",
      "   Validation sindy_x Loss: 1.6233443021774292\n",
      "   Validation sindy_regularization Loss: 0.9309194684028625\n",
      "Decoder Loss Ratio: 0.001181, Decoder SINDy Loss Ratio: 0.155033\n",
      "Epoch 45\n",
      "Epoch 45\n",
      "   Training Total Loss: 0.0004593714256770909\n",
      "   Training decoder Loss: 0.0002747186226770282\n",
      "   Training sindy_z Loss: 305.257568359375\n",
      "   Training sindy_x Loss: 1.7528926134109497\n",
      "   Training sindy_regularization Loss: 0.936355710029602\n",
      "   Validation Total Loss: 0.00038866684189997613\n",
      "   Validation decoder Loss: 0.00022574636386707425\n",
      "   Validation sindy_z Loss: 306.7511901855469\n",
      "   Validation sindy_x Loss: 1.535569429397583\n",
      "   Validation sindy_regularization Loss: 0.936355710029602\n",
      "Decoder Loss Ratio: 0.001216, Decoder SINDy Loss Ratio: 0.146651\n",
      "Epoch 46\n",
      "Epoch 46\n",
      "   Training Total Loss: 0.0004024818481411785\n",
      "   Training decoder Loss: 0.00022661710681859404\n",
      "   Training sindy_z Loss: 297.3741760253906\n",
      "   Training sindy_x Loss: 1.6644575595855713\n",
      "   Training sindy_regularization Loss: 0.9419000148773193\n",
      "   Validation Total Loss: 0.0003531438414938748\n",
      "   Validation decoder Loss: 0.00019607676949817687\n",
      "   Validation sindy_z Loss: 297.9439392089844\n",
      "   Validation sindy_x Loss: 1.4764807224273682\n",
      "   Validation sindy_regularization Loss: 0.9419000148773193\n",
      "Decoder Loss Ratio: 0.001056, Decoder SINDy Loss Ratio: 0.141008\n",
      "Epoch 47\n",
      "Epoch 47\n",
      "   Training Total Loss: 0.00039458912215195596\n",
      "   Training decoder Loss: 0.0002254019636893645\n",
      "   Training sindy_z Loss: 290.1164855957031\n",
      "   Training sindy_x Loss: 1.5968809127807617\n",
      "   Training sindy_regularization Loss: 0.9499044418334961\n",
      "   Validation Total Loss: 0.0003503411717247218\n",
      "   Validation decoder Loss: 0.00019933546718675643\n",
      "   Validation sindy_z Loss: 290.0054016113281\n",
      "   Validation sindy_x Loss: 1.4150663614273071\n",
      "   Validation sindy_regularization Loss: 0.9499044418334961\n",
      "Decoder Loss Ratio: 0.001074, Decoder SINDy Loss Ratio: 0.135142\n",
      "Epoch 48\n",
      "Epoch 48\n",
      "   Training Total Loss: 0.0003638734051492065\n",
      "   Training decoder Loss: 0.00020171914366073906\n",
      "   Training sindy_z Loss: 285.0842590332031\n",
      "   Training sindy_x Loss: 1.52566659450531\n",
      "   Training sindy_regularization Loss: 0.9587580561637878\n",
      "   Validation Total Loss: 0.00032070736051537097\n",
      "   Validation decoder Loss: 0.00017543772992212325\n",
      "   Validation sindy_z Loss: 284.42242431640625\n",
      "   Validation sindy_x Loss: 1.3568203449249268\n",
      "   Validation sindy_regularization Loss: 0.9587580561637878\n",
      "Decoder Loss Ratio: 0.000945, Decoder SINDy Loss Ratio: 0.129580\n",
      "Epoch 49\n",
      "Epoch 49\n",
      "   Training Total Loss: 0.00034668867010623217\n",
      "   Training decoder Loss: 0.0001901653886307031\n",
      "   Training sindy_z Loss: 280.3159484863281\n",
      "   Training sindy_x Loss: 1.4685697555541992\n",
      "   Training sindy_regularization Loss: 0.9666327834129333\n",
      "   Validation Total Loss: 0.00030752818565815687\n",
      "   Validation decoder Loss: 0.00016736281395424157\n",
      "   Validation sindy_z Loss: 279.11932373046875\n",
      "   Validation sindy_x Loss: 1.304990291595459\n",
      "   Validation sindy_regularization Loss: 0.9666327834129333\n",
      "Decoder Loss Ratio: 0.000901, Decoder SINDy Loss Ratio: 0.124630\n",
      "Epoch 50\n",
      "Epoch 50\n",
      "   Training Total Loss: 0.000327632122207433\n",
      "   Training decoder Loss: 0.00017573742661625147\n",
      "   Training sindy_z Loss: 276.04510498046875\n",
      "   Training sindy_x Loss: 1.421716570854187\n",
      "   Training sindy_regularization Loss: 0.9723042249679565\n",
      "   Validation Total Loss: 0.0002917048695962876\n",
      "   Validation decoder Loss: 0.000155753135913983\n",
      "   Validation sindy_z Loss: 274.33087158203125\n",
      "   Validation sindy_x Loss: 1.2622870206832886\n",
      "   Validation sindy_regularization Loss: 0.9723042249679565\n",
      "Decoder Loss Ratio: 0.000839, Decoder SINDy Loss Ratio: 0.120552\n",
      "Epoch 51\n",
      "Epoch 51\n",
      "   Training Total Loss: 0.0003189545532222837\n",
      "   Training decoder Loss: 0.00017108506290242076\n",
      "   Training sindy_z Loss: 272.97027587890625\n",
      "   Training sindy_x Loss: 1.3809442520141602\n",
      "   Training sindy_regularization Loss: 0.977508008480072\n",
      "   Validation Total Loss: 0.00028445557109080255\n",
      "   Validation decoder Loss: 0.0001524289109511301\n",
      "   Validation sindy_z Loss: 270.87432861328125\n",
      "   Validation sindy_x Loss: 1.2225160598754883\n",
      "   Validation sindy_regularization Loss: 0.977508008480072\n",
      "Decoder Loss Ratio: 0.000821, Decoder SINDy Loss Ratio: 0.116753\n",
      "Epoch 52\n",
      "Epoch 52\n",
      "   Training Total Loss: 0.00030222570057958364\n",
      "   Training decoder Loss: 0.00015743475523777306\n",
      "   Training sindy_z Loss: 269.0464172363281\n",
      "   Training sindy_x Loss: 1.34978187084198\n",
      "   Training sindy_regularization Loss: 0.9812751412391663\n",
      "   Validation Total Loss: 0.0002695628209039569\n",
      "   Validation decoder Loss: 0.00014018523506820202\n",
      "   Validation sindy_z Loss: 266.6180419921875\n",
      "   Validation sindy_x Loss: 1.1956480741500854\n",
      "   Validation sindy_regularization Loss: 0.9812751412391663\n",
      "Decoder Loss Ratio: 0.000755, Decoder SINDy Loss Ratio: 0.114187\n",
      "Epoch 53\n",
      "Epoch 53\n",
      "   Training Total Loss: 0.00038907595444470644\n",
      "   Training decoder Loss: 0.0002448514278512448\n",
      "   Training sindy_z Loss: 267.56439208984375\n",
      "   Training sindy_x Loss: 1.3438752889633179\n",
      "   Training sindy_regularization Loss: 0.9837022423744202\n",
      "   Validation Total Loss: 0.00035055179614573717\n",
      "   Validation decoder Loss: 0.00022397434804588556\n",
      "   Validation sindy_z Loss: 265.206787109375\n",
      "   Validation sindy_x Loss: 1.167404055595398\n",
      "   Validation sindy_regularization Loss: 0.9837022423744202\n",
      "Decoder Loss Ratio: 0.001206, Decoder SINDy Loss Ratio: 0.111490\n",
      "Epoch 54\n",
      "Epoch 54\n",
      "   Training Total Loss: 0.0002855728380382061\n",
      "   Training decoder Loss: 0.00014645460760220885\n",
      "   Training sindy_z Loss: 263.6381530761719\n",
      "   Training sindy_x Loss: 1.2928531169891357\n",
      "   Training sindy_regularization Loss: 0.9832902550697327\n",
      "   Validation Total Loss: 0.0002539163106121123\n",
      "   Validation decoder Loss: 0.00013021416089031845\n",
      "   Validation sindy_z Loss: 260.755126953125\n",
      "   Validation sindy_x Loss: 1.1386926174163818\n",
      "   Validation sindy_regularization Loss: 0.9832902550697327\n",
      "Decoder Loss Ratio: 0.000701, Decoder SINDy Loss Ratio: 0.108748\n",
      "Epoch 55\n",
      "Epoch 55\n",
      "   Training Total Loss: 0.0002746702521108091\n",
      "   Training decoder Loss: 0.0001369506644550711\n",
      "   Training sindy_z Loss: 260.3371276855469\n",
      "   Training sindy_x Loss: 1.2788480520248413\n",
      "   Training sindy_regularization Loss: 0.9834759831428528\n",
      "   Validation Total Loss: 0.0002450218016747385\n",
      "   Validation decoder Loss: 0.00012278642680030316\n",
      "   Validation sindy_z Loss: 257.1878356933594\n",
      "   Validation sindy_x Loss: 1.1240060329437256\n",
      "   Validation sindy_regularization Loss: 0.9834759831428528\n",
      "Decoder Loss Ratio: 0.000661, Decoder SINDy Loss Ratio: 0.107345\n",
      "Epoch 56\n",
      "Epoch 56\n",
      "   Training Total Loss: 0.0002985285536851734\n",
      "   Training decoder Loss: 0.00016190673341043293\n",
      "   Training sindy_z Loss: 258.8708801269531\n",
      "   Training sindy_x Loss: 1.2680656909942627\n",
      "   Training sindy_regularization Loss: 0.9815225601196289\n",
      "   Validation Total Loss: 0.00026529093156568706\n",
      "   Validation decoder Loss: 0.0001459649356547743\n",
      "   Validation sindy_z Loss: 256.0707702636719\n",
      "   Validation sindy_x Loss: 1.0951076745986938\n",
      "   Validation sindy_regularization Loss: 0.9815225601196289\n",
      "Decoder Loss Ratio: 0.000786, Decoder SINDy Loss Ratio: 0.104585\n",
      "Epoch 57\n",
      "Epoch 57\n",
      "   Training Total Loss: 0.0002637594297993928\n",
      "   Training decoder Loss: 0.00012951101234648377\n",
      "   Training sindy_z Loss: 256.1994323730469\n",
      "   Training sindy_x Loss: 1.2443883419036865\n",
      "   Training sindy_regularization Loss: 0.9809587597846985\n",
      "   Validation Total Loss: 0.00023383150983136147\n",
      "   Validation decoder Loss: 0.00011529723269632086\n",
      "   Validation sindy_z Loss: 252.76451110839844\n",
      "   Validation sindy_x Loss: 1.0872468948364258\n",
      "   Validation sindy_regularization Loss: 0.9809587597846985\n",
      "Decoder Loss Ratio: 0.000621, Decoder SINDy Loss Ratio: 0.103835\n",
      "Epoch 58\n",
      "Epoch 58\n",
      "   Training Total Loss: 0.0002561044238973409\n",
      "   Training decoder Loss: 0.00012293373583815992\n",
      "   Training sindy_z Loss: 253.494140625\n",
      "   Training sindy_x Loss: 1.2335243225097656\n",
      "   Training sindy_regularization Loss: 0.9818270206451416\n",
      "   Validation Total Loss: 0.00022774285753257573\n",
      "   Validation decoder Loss: 0.00011048154556192458\n",
      "   Validation sindy_z Loss: 249.8881072998047\n",
      "   Validation sindy_x Loss: 1.0744304656982422\n",
      "   Validation sindy_regularization Loss: 0.9818270206451416\n",
      "Decoder Loss Ratio: 0.000595, Decoder SINDy Loss Ratio: 0.102611\n",
      "Epoch 59\n",
      "Epoch 59\n",
      "   Training Total Loss: 0.00024866050807759166\n",
      "   Training decoder Loss: 0.00011663239274639636\n",
      "   Training sindy_z Loss: 251.60279846191406\n",
      "   Training sindy_x Loss: 1.222129464149475\n",
      "   Training sindy_regularization Loss: 0.9815166592597961\n",
      "   Validation Total Loss: 0.0002214330161223188\n",
      "   Validation decoder Loss: 0.0001054709282470867\n",
      "   Validation sindy_z Loss: 248.0108184814453\n",
      "   Validation sindy_x Loss: 1.061469316482544\n",
      "   Validation sindy_regularization Loss: 0.9815166592597961\n",
      "Decoder Loss Ratio: 0.000568, Decoder SINDy Loss Ratio: 0.101373\n",
      "Epoch 60\n",
      "Epoch 60\n",
      "   Training Total Loss: 0.0002553628000896424\n",
      "   Training decoder Loss: 0.00012490502558648586\n",
      "   Training sindy_z Loss: 250.40687561035156\n",
      "   Training sindy_x Loss: 1.2065391540527344\n",
      "   Training sindy_regularization Loss: 0.9803868532180786\n",
      "   Validation Total Loss: 0.00022505999368149787\n",
      "   Validation decoder Loss: 0.00011130970960948616\n",
      "   Validation sindy_z Loss: 246.79335021972656\n",
      "   Validation sindy_x Loss: 1.0394641160964966\n",
      "   Validation sindy_regularization Loss: 0.9803868532180786\n",
      "Decoder Loss Ratio: 0.000600, Decoder SINDy Loss Ratio: 0.099271\n",
      "Epoch 61\n",
      "Epoch 61\n",
      "   Training Total Loss: 0.00024043978191912174\n",
      "   Training decoder Loss: 0.00011064767750212923\n",
      "   Training sindy_z Loss: 247.81048583984375\n",
      "   Training sindy_x Loss: 1.2000820636749268\n",
      "   Training sindy_regularization Loss: 0.9783891439437866\n",
      "   Validation Total Loss: 0.00021179724717512727\n",
      "   Validation decoder Loss: 9.847530600382015e-05\n",
      "   Validation sindy_z Loss: 244.0424346923828\n",
      "   Validation sindy_x Loss: 1.0353806018829346\n",
      "   Validation sindy_regularization Loss: 0.9783891439437866\n",
      "Decoder Loss Ratio: 0.000530, Decoder SINDy Loss Ratio: 0.098881\n",
      "Epoch 62\n",
      "Epoch 62\n",
      "   Training Total Loss: 0.00022718461696058512\n",
      "   Training decoder Loss: 9.876390686258674e-05\n",
      "   Training sindy_z Loss: 246.64405822753906\n",
      "   Training sindy_x Loss: 1.1864981651306152\n",
      "   Training sindy_regularization Loss: 0.9770897030830383\n",
      "   Validation Total Loss: 0.00019962684018537402\n",
      "   Validation decoder Loss: 8.783827070146799e-05\n",
      "   Validation sindy_z Loss: 242.8771514892578\n",
      "   Validation sindy_x Loss: 1.0201767683029175\n",
      "   Validation sindy_regularization Loss: 0.9770897030830383\n",
      "Decoder Loss Ratio: 0.000473, Decoder SINDy Loss Ratio: 0.097429\n",
      "Epoch 63\n",
      "Epoch 63\n",
      "   Training Total Loss: 0.00023837653861846775\n",
      "   Training decoder Loss: 0.00010967359412461519\n",
      "   Training sindy_z Loss: 245.57032775878906\n",
      "   Training sindy_x Loss: 1.1894268989562988\n",
      "   Training sindy_regularization Loss: 0.9760259389877319\n",
      "   Validation Total Loss: 0.00021214704611338675\n",
      "   Validation decoder Loss: 0.00010097265476360917\n",
      "   Validation sindy_z Loss: 241.58270263671875\n",
      "   Validation sindy_x Loss: 1.0141414403915405\n",
      "   Validation sindy_regularization Loss: 0.9760259389877319\n",
      "Decoder Loss Ratio: 0.000544, Decoder SINDy Loss Ratio: 0.096853\n",
      "Epoch 64\n",
      "Epoch 64\n",
      "   Training Total Loss: 0.00022208542213775218\n",
      "   Training decoder Loss: 9.52335904003121e-05\n",
      "   Training sindy_z Loss: 245.56138610839844\n",
      "   Training sindy_x Loss: 1.171108365058899\n",
      "   Training sindy_regularization Loss: 0.9740990400314331\n",
      "   Validation Total Loss: 0.0001940832589752972\n",
      "   Validation decoder Loss: 8.459931268589571e-05\n",
      "   Validation sindy_z Loss: 241.73056030273438\n",
      "   Validation sindy_x Loss: 0.997429609298706\n",
      "   Validation sindy_regularization Loss: 0.9740990400314331\n",
      "Decoder Loss Ratio: 0.000456, Decoder SINDy Loss Ratio: 0.095257\n",
      "Epoch 65\n",
      "Epoch 65\n",
      "   Training Total Loss: 0.0002593702229205519\n",
      "   Training decoder Loss: 0.00013241669512353837\n",
      "   Training sindy_z Loss: 245.4879608154297\n",
      "   Training sindy_x Loss: 1.1723618507385254\n",
      "   Training sindy_regularization Loss: 0.9717339277267456\n",
      "   Validation Total Loss: 0.00023228951613418758\n",
      "   Validation decoder Loss: 0.00012224404781591147\n",
      "   Validation sindy_z Loss: 241.1610107421875\n",
      "   Validation sindy_x Loss: 1.0032814741134644\n",
      "   Validation sindy_regularization Loss: 0.9717339277267456\n",
      "Decoder Loss Ratio: 0.000658, Decoder SINDy Loss Ratio: 0.095816\n",
      "Epoch 66\n",
      "Epoch 66\n",
      "   Training Total Loss: 0.0002043895365204662\n",
      "   Training decoder Loss: 7.871580601204187e-05\n",
      "   Training sindy_z Loss: 241.5941619873047\n",
      "   Training sindy_x Loss: 1.1597245931625366\n",
      "   Training sindy_regularization Loss: 0.9701268076896667\n",
      "   Validation Total Loss: 0.00017897257930599153\n",
      "   Validation decoder Loss: 7.059497875161469e-05\n",
      "   Validation sindy_z Loss: 237.43878173828125\n",
      "   Validation sindy_x Loss: 0.9867633581161499\n",
      "   Validation sindy_regularization Loss: 0.9701268076896667\n",
      "Decoder Loss Ratio: 0.000380, Decoder SINDy Loss Ratio: 0.094238\n",
      "Epoch 67\n",
      "Epoch 67\n",
      "   Training Total Loss: 0.00020121436682529747\n",
      "   Training decoder Loss: 7.615139475092292e-05\n",
      "   Training sindy_z Loss: 240.77980041503906\n",
      "   Training sindy_x Loss: 1.1536953449249268\n",
      "   Training sindy_regularization Loss: 0.9693441390991211\n",
      "   Validation Total Loss: 0.0001752568205120042\n",
      "   Validation decoder Loss: 6.793326610932127e-05\n",
      "   Validation sindy_z Loss: 236.5897979736328\n",
      "   Validation sindy_x Loss: 0.9763011932373047\n",
      "   Validation sindy_regularization Loss: 0.9693441390991211\n",
      "Decoder Loss Ratio: 0.000366, Decoder SINDy Loss Ratio: 0.093239\n",
      "Epoch 68\n",
      "Epoch 68\n",
      "   Training Total Loss: 0.0001996197970584035\n",
      "   Training decoder Loss: 7.539818034274504e-05\n",
      "   Training sindy_z Loss: 238.315673828125\n",
      "   Training sindy_x Loss: 1.1452782154083252\n",
      "   Training sindy_regularization Loss: 0.9693794846534729\n",
      "   Validation Total Loss: 0.00017609188216738403\n",
      "   Validation decoder Loss: 6.928864604560658e-05\n",
      "   Validation sindy_z Loss: 233.82290649414062\n",
      "   Validation sindy_x Loss: 0.97109454870224\n",
      "   Validation sindy_regularization Loss: 0.9693794846534729\n",
      "Decoder Loss Ratio: 0.000373, Decoder SINDy Loss Ratio: 0.092742\n",
      "Epoch 69\n",
      "Epoch 69\n",
      "   Training Total Loss: 0.00022051206906326115\n",
      "   Training decoder Loss: 9.597236930858344e-05\n",
      "   Training sindy_z Loss: 236.6988067626953\n",
      "   Training sindy_x Loss: 1.1483737230300903\n",
      "   Training sindy_regularization Loss: 0.9702323079109192\n",
      "   Validation Total Loss: 0.00019609968876466155\n",
      "   Validation decoder Loss: 9.013238013722003e-05\n",
      "   Validation sindy_z Loss: 232.27903747558594\n",
      "   Validation sindy_x Loss: 0.9626498222351074\n",
      "   Validation sindy_regularization Loss: 0.9702323079109192\n",
      "Decoder Loss Ratio: 0.000485, Decoder SINDy Loss Ratio: 0.091935\n",
      "Epoch 70\n",
      "Epoch 70\n",
      "   Training Total Loss: 0.00019767261983361095\n",
      "   Training decoder Loss: 7.469957927241921e-05\n",
      "   Training sindy_z Loss: 238.9232635498047\n",
      "   Training sindy_x Loss: 1.1329090595245361\n",
      "   Training sindy_regularization Loss: 0.9682137370109558\n",
      "   Validation Total Loss: 0.00017580573330633342\n",
      "   Validation decoder Loss: 7.109928992576897e-05\n",
      "   Validation sindy_z Loss: 234.05003356933594\n",
      "   Validation sindy_x Loss: 0.9502431750297546\n",
      "   Validation sindy_regularization Loss: 0.9682137370109558\n",
      "Decoder Loss Ratio: 0.000383, Decoder SINDy Loss Ratio: 0.090751\n",
      "Epoch 71\n",
      "Epoch 71\n",
      "   Training Total Loss: 0.00018541680765338242\n",
      "   Training decoder Loss: 6.287904398050159e-05\n",
      "   Training sindy_z Loss: 234.9739532470703\n",
      "   Training sindy_x Loss: 1.1285161972045898\n",
      "   Training sindy_regularization Loss: 0.9686144590377808\n",
      "   Validation Total Loss: 0.00016254426736850291\n",
      "   Validation decoder Loss: 5.7703000493347645e-05\n",
      "   Validation sindy_z Loss: 230.092529296875\n",
      "   Validation sindy_x Loss: 0.9515511989593506\n",
      "   Validation sindy_regularization Loss: 0.9686144590377808\n",
      "Decoder Loss Ratio: 0.000311, Decoder SINDy Loss Ratio: 0.090875\n",
      "Epoch 72\n",
      "Epoch 72\n",
      "   Training Total Loss: 0.00022399777662940323\n",
      "   Training decoder Loss: 0.00010155357449548319\n",
      "   Training sindy_z Loss: 237.46473693847656\n",
      "   Training sindy_x Loss: 1.127661108970642\n",
      "   Training sindy_regularization Loss: 0.9678105711936951\n",
      "   Validation Total Loss: 0.0002039028040599078\n",
      "   Validation decoder Loss: 9.929609223036095e-05\n",
      "   Validation sindy_z Loss: 232.15621948242188\n",
      "   Validation sindy_x Loss: 0.9492860436439514\n",
      "   Validation sindy_regularization Loss: 0.9678105711936951\n",
      "Decoder Loss Ratio: 0.000535, Decoder SINDy Loss Ratio: 0.090659\n",
      "Epoch 73\n",
      "Epoch 73\n",
      "   Training Total Loss: 0.00017784615920390934\n",
      "   Training decoder Loss: 5.669302845490165e-05\n",
      "   Training sindy_z Loss: 233.95660400390625\n",
      "   Training sindy_x Loss: 1.114715576171875\n",
      "   Training sindy_regularization Loss: 0.9681578278541565\n",
      "   Validation Total Loss: 0.00015623414947185665\n",
      "   Validation decoder Loss: 5.277472882880829e-05\n",
      "   Validation sindy_z Loss: 228.8405303955078\n",
      "   Validation sindy_x Loss: 0.9377784132957458\n",
      "   Validation sindy_regularization Loss: 0.9681578278541565\n",
      "Decoder Loss Ratio: 0.000284, Decoder SINDy Loss Ratio: 0.089560\n",
      "Epoch 74\n",
      "Epoch 74\n",
      "   Training Total Loss: 0.00017673283582553267\n",
      "   Training decoder Loss: 5.612985114566982e-05\n",
      "   Training sindy_z Loss: 234.6526641845703\n",
      "   Training sindy_x Loss: 1.1091758012771606\n",
      "   Training sindy_regularization Loss: 0.9685400724411011\n",
      "   Validation Total Loss: 0.00015459519636351615\n",
      "   Validation decoder Loss: 5.2131526899756864e-05\n",
      "   Validation sindy_z Loss: 229.37355041503906\n",
      "   Validation sindy_x Loss: 0.9277827143669128\n",
      "   Validation sindy_regularization Loss: 0.9685400724411011\n",
      "Decoder Loss Ratio: 0.000281, Decoder SINDy Loss Ratio: 0.088606\n",
      "Epoch 75\n",
      "Epoch 75\n",
      "   Training Total Loss: 0.00017420435324311256\n",
      "   Training decoder Loss: 5.4042451665736735e-05\n",
      "   Training sindy_z Loss: 231.79737854003906\n",
      "   Training sindy_x Loss: 1.1047141551971436\n",
      "   Training sindy_regularization Loss: 0.9690501093864441\n",
      "   Validation Total Loss: 0.00015272996097337455\n",
      "   Validation decoder Loss: 5.034878267906606e-05\n",
      "   Validation sindy_z Loss: 226.472900390625\n",
      "   Validation sindy_x Loss: 0.9269068241119385\n",
      "   Validation sindy_regularization Loss: 0.9690501093864441\n",
      "Decoder Loss Ratio: 0.000271, Decoder SINDy Loss Ratio: 0.088522\n",
      "Epoch 76\n",
      "Epoch 76\n",
      "   Training Total Loss: 0.00017072052287403494\n",
      "   Training decoder Loss: 5.1233564590802416e-05\n",
      "   Training sindy_z Loss: 229.1598663330078\n",
      "   Training sindy_x Loss: 1.0978472232818604\n",
      "   Training sindy_regularization Loss: 0.9702240824699402\n",
      "   Validation Total Loss: 0.00015017291298136115\n",
      "   Validation decoder Loss: 4.836993321077898e-05\n",
      "   Validation sindy_z Loss: 223.86669921875\n",
      "   Validation sindy_x Loss: 0.9210073947906494\n",
      "   Validation sindy_regularization Loss: 0.9702240824699402\n",
      "Decoder Loss Ratio: 0.000261, Decoder SINDy Loss Ratio: 0.087958\n",
      "Epoch 77\n",
      "Epoch 77\n",
      "   Training Total Loss: 0.00017355201998725533\n",
      "   Training decoder Loss: 5.467252049129456e-05\n",
      "   Training sindy_z Loss: 229.642822265625\n",
      "   Training sindy_x Loss: 1.0917026996612549\n",
      "   Training sindy_regularization Loss: 0.9709234237670898\n",
      "   Validation Total Loss: 0.00015144801000133157\n",
      "   Validation decoder Loss: 5.0575279601616785e-05\n",
      "   Validation sindy_z Loss: 224.3546600341797\n",
      "   Validation sindy_x Loss: 0.9116350412368774\n",
      "   Validation sindy_regularization Loss: 0.9709234237670898\n",
      "Decoder Loss Ratio: 0.000272, Decoder SINDy Loss Ratio: 0.087063\n",
      "Epoch 78\n",
      "Epoch 78\n",
      "   Training Total Loss: 0.00017438046052120626\n",
      "   Training decoder Loss: 5.602113378699869e-05\n",
      "   Training sindy_z Loss: 228.04217529296875\n",
      "   Training sindy_x Loss: 1.086488127708435\n",
      "   Training sindy_regularization Loss: 0.9710527062416077\n",
      "   Validation Total Loss: 0.00015501631423830986\n",
      "   Validation decoder Loss: 5.409201548900455e-05\n",
      "   Validation sindy_z Loss: 222.49256896972656\n",
      "   Validation sindy_x Loss: 0.9121378064155579\n",
      "   Validation sindy_regularization Loss: 0.9710527062416077\n",
      "Decoder Loss Ratio: 0.000291, Decoder SINDy Loss Ratio: 0.087111\n",
      "Epoch 79\n",
      "Epoch 79\n",
      "   Training Total Loss: 0.0001902788208099082\n",
      "   Training decoder Loss: 7.208283932413906e-05\n",
      "   Training sindy_z Loss: 235.1417694091797\n",
      "   Training sindy_x Loss: 1.084998369216919\n",
      "   Training sindy_regularization Loss: 0.9696142673492432\n",
      "   Validation Total Loss: 0.00017278021550737321\n",
      "   Validation decoder Loss: 7.248356996569782e-05\n",
      "   Validation sindy_z Loss: 229.03244018554688\n",
      "   Validation sindy_x Loss: 0.9060050845146179\n",
      "   Validation sindy_regularization Loss: 0.9696142673492432\n",
      "Decoder Loss Ratio: 0.000390, Decoder SINDy Loss Ratio: 0.086526\n",
      "Epoch 80\n",
      "Epoch 80\n",
      "   Training Total Loss: 0.00016216062067542225\n",
      "   Training decoder Loss: 4.464509038371034e-05\n",
      "   Training sindy_z Loss: 230.11558532714844\n",
      "   Training sindy_x Loss: 1.0781774520874023\n",
      "   Training sindy_regularization Loss: 0.9697791337966919\n",
      "   Validation Total Loss: 0.00014228603686206043\n",
      "   Validation decoder Loss: 4.2485604353714734e-05\n",
      "   Validation sindy_z Loss: 224.26300048828125\n",
      "   Validation sindy_x Loss: 0.9010264873504639\n",
      "   Validation sindy_regularization Loss: 0.9697791337966919\n",
      "Decoder Loss Ratio: 0.000229, Decoder SINDy Loss Ratio: 0.086050\n",
      "Epoch 81\n",
      "Epoch 81\n",
      "   Training Total Loss: 0.0001644384756218642\n",
      "   Training decoder Loss: 4.7402420022990555e-05\n",
      "   Training sindy_z Loss: 227.93896484375\n",
      "   Training sindy_x Loss: 1.0732643604278564\n",
      "   Training sindy_regularization Loss: 0.9709616303443909\n",
      "   Validation Total Loss: 0.00014475436182692647\n",
      "   Validation decoder Loss: 4.5483451685868204e-05\n",
      "   Validation sindy_z Loss: 222.0438995361328\n",
      "   Validation sindy_x Loss: 0.895612895488739\n",
      "   Validation sindy_regularization Loss: 0.9709616303443909\n",
      "Decoder Loss Ratio: 0.000245, Decoder SINDy Loss Ratio: 0.085533\n",
      "Epoch 82\n",
      "Epoch 82\n",
      "   Training Total Loss: 0.00015910978254396468\n",
      "   Training decoder Loss: 4.278808046365157e-05\n",
      "   Training sindy_z Loss: 225.8864288330078\n",
      "   Training sindy_x Loss: 1.0660274028778076\n",
      "   Training sindy_regularization Loss: 0.9718956351280212\n",
      "   Validation Total Loss: 0.00014018212095834315\n",
      "   Validation decoder Loss: 4.135963899898343e-05\n",
      "   Validation sindy_z Loss: 220.03213500976562\n",
      "   Validation sindy_x Loss: 0.891035258769989\n",
      "   Validation sindy_regularization Loss: 0.9718956351280212\n",
      "Decoder Loss Ratio: 0.000223, Decoder SINDy Loss Ratio: 0.085096\n",
      "Epoch 83\n",
      "Epoch 83\n",
      "   Training Total Loss: 0.00015743380936328322\n",
      "   Training decoder Loss: 4.1419611079618335e-05\n",
      "   Training sindy_z Loss: 223.9442138671875\n",
      "   Training sindy_x Loss: 1.0628206729888916\n",
      "   Training sindy_regularization Loss: 0.9732137322425842\n",
      "   Validation Total Loss: 0.00013836853031534702\n",
      "   Validation decoder Loss: 4.0034461562754586e-05\n",
      "   Validation sindy_z Loss: 218.15631103515625\n",
      "   Validation sindy_x Loss: 0.8860193490982056\n",
      "   Validation sindy_regularization Loss: 0.9732137322425842\n",
      "Decoder Loss Ratio: 0.000216, Decoder SINDy Loss Ratio: 0.084617\n",
      "Epoch 84\n",
      "Epoch 84\n",
      "   Training Total Loss: 0.00016272430366370827\n",
      "   Training decoder Loss: 4.723634629044682e-05\n",
      "   Training sindy_z Loss: 230.43316650390625\n",
      "   Training sindy_x Loss: 1.0577977895736694\n",
      "   Training sindy_regularization Loss: 0.9708173871040344\n",
      "   Validation Total Loss: 0.00014328304678201675\n",
      "   Validation decoder Loss: 4.6054850827204064e-05\n",
      "   Validation sindy_z Loss: 223.9240264892578\n",
      "   Validation sindy_x Loss: 0.8752002120018005\n",
      "   Validation sindy_regularization Loss: 0.9708173871040344\n",
      "Decoder Loss Ratio: 0.000248, Decoder SINDy Loss Ratio: 0.083584\n",
      "Epoch 85\n",
      "Epoch 85\n",
      "   Training Total Loss: 0.0001559114025440067\n",
      "   Training decoder Loss: 4.057017940795049e-05\n",
      "   Training sindy_z Loss: 226.419921875\n",
      "   Training sindy_x Loss: 1.0562719106674194\n",
      "   Training sindy_regularization Loss: 0.9714044332504272\n",
      "   Validation Total Loss: 0.00013661995762959123\n",
      "   Validation decoder Loss: 3.915038541890681e-05\n",
      "   Validation sindy_z Loss: 220.03570556640625\n",
      "   Validation sindy_x Loss: 0.877555251121521\n",
      "   Validation sindy_regularization Loss: 0.9714044332504272\n",
      "Decoder Loss Ratio: 0.000211, Decoder SINDy Loss Ratio: 0.083809\n",
      "Epoch 86\n",
      "Epoch 86\n",
      "   Training Total Loss: 0.00015671418805141002\n",
      "   Training decoder Loss: 4.175937283434905e-05\n",
      "   Training sindy_z Loss: 224.0181427001953\n",
      "   Training sindy_x Loss: 1.0523098707199097\n",
      "   Training sindy_regularization Loss: 0.9723840951919556\n",
      "   Validation Total Loss: 0.00013768095232080668\n",
      "   Validation decoder Loss: 4.0648017602507025e-05\n",
      "   Validation sindy_z Loss: 217.6741180419922\n",
      "   Validation sindy_x Loss: 0.8730910420417786\n",
      "   Validation sindy_regularization Loss: 0.9723840951919556\n",
      "Decoder Loss Ratio: 0.000219, Decoder SINDy Loss Ratio: 0.083382\n",
      "Epoch 87\n",
      "Epoch 87\n",
      "   Training Total Loss: 0.00016213308845181018\n",
      "   Training decoder Loss: 4.7873807488940656e-05\n",
      "   Training sindy_z Loss: 224.9145050048828\n",
      "   Training sindy_x Loss: 1.0453472137451172\n",
      "   Training sindy_regularization Loss: 0.9724569916725159\n",
      "   Validation Total Loss: 0.0001443643996026367\n",
      "   Validation decoder Loss: 4.756576527142897e-05\n",
      "   Validation sindy_z Loss: 218.61892700195312\n",
      "   Validation sindy_x Loss: 0.8707407116889954\n",
      "   Validation sindy_regularization Loss: 0.9724569916725159\n",
      "Decoder Loss Ratio: 0.000256, Decoder SINDy Loss Ratio: 0.083158\n",
      "Epoch 88\n",
      "Epoch 88\n",
      "   Training Total Loss: 0.00015325710410252213\n",
      "   Training decoder Loss: 3.913690670742653e-05\n",
      "   Training sindy_z Loss: 222.6502685546875\n",
      "   Training sindy_x Loss: 1.0438863039016724\n",
      "   Training sindy_regularization Loss: 0.9731571078300476\n",
      "   Validation Total Loss: 0.0001348639343632385\n",
      "   Validation decoder Loss: 3.854738315567374e-05\n",
      "   Validation sindy_z Loss: 216.21778869628906\n",
      "   Validation sindy_x Loss: 0.8658499121665955\n",
      "   Validation sindy_regularization Loss: 0.9731571078300476\n",
      "Decoder Loss Ratio: 0.000208, Decoder SINDy Loss Ratio: 0.082691\n",
      "Epoch 89\n",
      "Epoch 89\n",
      "   Training Total Loss: 0.000160228053573519\n",
      "   Training decoder Loss: 4.5306685933610424e-05\n",
      "   Training sindy_z Loss: 238.50364685058594\n",
      "   Training sindy_x Loss: 1.0522971153259277\n",
      "   Training sindy_regularization Loss: 0.96916663646698\n",
      "   Validation Total Loss: 0.00014405095134861767\n",
      "   Validation decoder Loss: 4.7517940402030945e-05\n",
      "   Validation sindy_z Loss: 230.91812133789062\n",
      "   Validation sindy_x Loss: 0.8684134483337402\n",
      "   Validation sindy_regularization Loss: 0.96916663646698\n",
      "Decoder Loss Ratio: 0.000256, Decoder SINDy Loss Ratio: 0.082936\n",
      "Epoch 90\n",
      "Epoch 90\n",
      "   Training Total Loss: 0.00015005913155619055\n",
      "   Training decoder Loss: 3.6760757211595774e-05\n",
      "   Training sindy_z Loss: 232.7833251953125\n",
      "   Training sindy_x Loss: 1.0361387729644775\n",
      "   Training sindy_regularization Loss: 0.9684494733810425\n",
      "   Validation Total Loss: 0.00013193508493714035\n",
      "   Validation decoder Loss: 3.650548023870215e-05\n",
      "   Validation sindy_z Loss: 225.3444366455078\n",
      "   Validation sindy_x Loss: 0.8574512004852295\n",
      "   Validation sindy_regularization Loss: 0.9684494733810425\n",
      "Decoder Loss Ratio: 0.000197, Decoder SINDy Loss Ratio: 0.081889\n",
      "Epoch 91\n",
      "Epoch 91\n",
      "   Training Total Loss: 0.0001483815285610035\n",
      "   Training decoder Loss: 3.5244676837464795e-05\n",
      "   Training sindy_z Loss: 229.85435485839844\n",
      "   Training sindy_x Loss: 1.034454584121704\n",
      "   Training sindy_regularization Loss: 0.9691395163536072\n",
      "   Validation Total Loss: 0.0001295885449508205\n",
      "   Validation decoder Loss: 3.457032289588824e-05\n",
      "   Validation sindy_z Loss: 222.61509704589844\n",
      "   Validation sindy_x Loss: 0.8532682657241821\n",
      "   Validation sindy_regularization Loss: 0.9691395163536072\n",
      "Decoder Loss Ratio: 0.000186, Decoder SINDy Loss Ratio: 0.081489\n",
      "Epoch 92\n",
      "Epoch 92\n",
      "   Training Total Loss: 0.0001517335040261969\n",
      "   Training decoder Loss: 3.8606784073635936e-05\n",
      "   Training sindy_z Loss: 227.5917510986328\n",
      "   Training sindy_x Loss: 1.034265398979187\n",
      "   Training sindy_regularization Loss: 0.9700170159339905\n",
      "   Validation Total Loss: 0.0001334203698206693\n",
      "   Validation decoder Loss: 3.8590736949117854e-05\n",
      "   Validation sindy_z Loss: 220.54385375976562\n",
      "   Validation sindy_x Loss: 0.8512946367263794\n",
      "   Validation sindy_regularization Loss: 0.9700170159339905\n",
      "Decoder Loss Ratio: 0.000208, Decoder SINDy Loss Ratio: 0.081301\n",
      "Epoch 93\n",
      "Epoch 93\n",
      "   Training Total Loss: 0.00014673981058876961\n",
      "   Training decoder Loss: 3.429558273637667e-05\n",
      "   Training sindy_z Loss: 226.00616455078125\n",
      "   Training sindy_x Loss: 1.027364730834961\n",
      "   Training sindy_regularization Loss: 0.9707763195037842\n",
      "   Validation Total Loss: 0.00012833660002797842\n",
      "   Validation decoder Loss: 3.4036493161693215e-05\n",
      "   Validation sindy_z Loss: 219.00454711914062\n",
      "   Validation sindy_x Loss: 0.8459234237670898\n",
      "   Validation sindy_regularization Loss: 0.9707763195037842\n",
      "Decoder Loss Ratio: 0.000183, Decoder SINDy Loss Ratio: 0.080788\n",
      "Epoch 94\n",
      "Epoch 94\n",
      "   Training Total Loss: 0.00015680531214457005\n",
      "   Training decoder Loss: 4.415684816194698e-05\n",
      "   Training sindy_z Loss: 226.33534240722656\n",
      "   Training sindy_x Loss: 1.0293498039245605\n",
      "   Training sindy_regularization Loss: 0.971347451210022\n",
      "   Validation Total Loss: 0.00013794050028081983\n",
      "   Validation decoder Loss: 4.368229929241352e-05\n",
      "   Validation sindy_z Loss: 219.17523193359375\n",
      "   Validation sindy_x Loss: 0.8454472422599792\n",
      "   Validation sindy_regularization Loss: 0.971347451210022\n",
      "Decoder Loss Ratio: 0.000235, Decoder SINDy Loss Ratio: 0.080742\n",
      "Epoch 95\n",
      "Epoch 95\n",
      "   Training Total Loss: 0.0001815775322029367\n",
      "   Training decoder Loss: 6.855773244751617e-05\n",
      "   Training sindy_z Loss: 227.43968200683594\n",
      "   Training sindy_x Loss: 1.0330841541290283\n",
      "   Training sindy_regularization Loss: 0.9711387753486633\n",
      "   Validation Total Loss: 0.00016119029896799475\n",
      "   Validation decoder Loss: 6.726113497279584e-05\n",
      "   Validation sindy_z Loss: 220.09848022460938\n",
      "   Validation sindy_x Loss: 0.8421779274940491\n",
      "   Validation sindy_regularization Loss: 0.9711387753486633\n",
      "Decoder Loss Ratio: 0.000362, Decoder SINDy Loss Ratio: 0.080430\n",
      "Epoch 96\n",
      "Epoch 96\n",
      "   Training Total Loss: 0.0001786644570529461\n",
      "   Training decoder Loss: 6.659405335085467e-05\n",
      "   Training sindy_z Loss: 227.95172119140625\n",
      "   Training sindy_x Loss: 1.023660659790039\n",
      "   Training sindy_regularization Loss: 0.9704341292381287\n",
      "   Validation Total Loss: 0.0001617074740352109\n",
      "   Validation decoder Loss: 6.812059291405603e-05\n",
      "   Validation sindy_z Loss: 220.64736938476562\n",
      "   Validation sindy_x Loss: 0.8388254046440125\n",
      "   Validation sindy_regularization Loss: 0.9704341292381287\n",
      "Decoder Loss Ratio: 0.000367, Decoder SINDy Loss Ratio: 0.080110\n",
      "Epoch 97\n",
      "Epoch 97\n",
      "   Training Total Loss: 0.00014322980132419616\n",
      "   Training decoder Loss: 3.1567065889248624e-05\n",
      "   Training sindy_z Loss: 226.1540069580078\n",
      "   Training sindy_x Loss: 1.0196170806884766\n",
      "   Training sindy_regularization Loss: 0.9701035618782043\n",
      "   Validation Total Loss: 0.00012436303950380534\n",
      "   Validation decoder Loss: 3.1497638701694086e-05\n",
      "   Validation sindy_z Loss: 218.83795166015625\n",
      "   Validation sindy_x Loss: 0.8316436409950256\n",
      "   Validation sindy_regularization Loss: 0.9701035618782043\n",
      "Decoder Loss Ratio: 0.000170, Decoder SINDy Loss Ratio: 0.079424\n",
      "Epoch 98\n",
      "Epoch 98\n",
      "   Training Total Loss: 0.00014363911759573966\n",
      "   Training decoder Loss: 3.220116559532471e-05\n",
      "   Training sindy_z Loss: 225.3646697998047\n",
      "   Training sindy_x Loss: 1.0173476934432983\n",
      "   Training sindy_regularization Loss: 0.9703189730644226\n",
      "   Validation Total Loss: 0.00012437319674063474\n",
      "   Validation decoder Loss: 3.1792114896234125e-05\n",
      "   Validation sindy_z Loss: 218.0581817626953\n",
      "   Validation sindy_x Loss: 0.8287789821624756\n",
      "   Validation sindy_regularization Loss: 0.9703189730644226\n",
      "Decoder Loss Ratio: 0.000171, Decoder SINDy Loss Ratio: 0.079150\n",
      "Epoch 99\n",
      "Epoch 99\n",
      "   Training Total Loss: 0.00014674526755698025\n",
      "   Training decoder Loss: 3.526610817061737e-05\n",
      "   Training sindy_z Loss: 224.7377471923828\n",
      "   Training sindy_x Loss: 1.0177795886993408\n",
      "   Training sindy_regularization Loss: 0.9701208472251892\n",
      "   Validation Total Loss: 0.00012788960884790868\n",
      "   Validation decoder Loss: 3.582529097911902e-05\n",
      "   Validation sindy_z Loss: 217.46588134765625\n",
      "   Validation sindy_x Loss: 0.8236311674118042\n",
      "   Validation sindy_regularization Loss: 0.9701208472251892\n",
      "Decoder Loss Ratio: 0.000193, Decoder SINDy Loss Ratio: 0.078659\n",
      "Epoch 100\n",
      "Epoch 100\n",
      "   Training Total Loss: 0.00014279484457802027\n",
      "   Training decoder Loss: 3.191095311194658e-05\n",
      "   Training sindy_z Loss: 229.7595672607422\n",
      "   Training sindy_x Loss: 1.0119423866271973\n",
      "   Training sindy_regularization Loss: 0.9689656496047974\n",
      "   Validation Total Loss: 0.00012484172475524247\n",
      "   Validation decoder Loss: 3.3179188903886825e-05\n",
      "   Validation sindy_z Loss: 222.25942993164062\n",
      "   Validation sindy_x Loss: 0.8197287917137146\n",
      "   Validation sindy_regularization Loss: 0.9689656496047974\n",
      "Decoder Loss Ratio: 0.000179, Decoder SINDy Loss Ratio: 0.078286\n",
      "Epoch 101\n",
      "Epoch 101\n",
      "   Training Total Loss: 0.00014029051817487925\n",
      "   Training decoder Loss: 2.9357170205912553e-05\n",
      "   Training sindy_z Loss: 227.5205078125\n",
      "   Training sindy_x Loss: 1.0124233961105347\n",
      "   Training sindy_regularization Loss: 0.9691007137298584\n",
      "   Validation Total Loss: 0.00012087582581443712\n",
      "   Validation decoder Loss: 2.9487100619007833e-05\n",
      "   Validation sindy_z Loss: 219.89349365234375\n",
      "   Validation sindy_x Loss: 0.8169772028923035\n",
      "   Validation sindy_regularization Loss: 0.9691007137298584\n",
      "Decoder Loss Ratio: 0.000159, Decoder SINDy Loss Ratio: 0.078023\n",
      "Epoch 102\n",
      "Epoch 102\n",
      "   Training Total Loss: 0.00018110740347765386\n",
      "   Training decoder Loss: 6.994233990553766e-05\n",
      "   Training sindy_z Loss: 231.0065155029297\n",
      "   Training sindy_x Loss: 1.0148241519927979\n",
      "   Training sindy_regularization Loss: 0.9682646989822388\n",
      "   Validation Total Loss: 0.00016163301188498735\n",
      "   Validation decoder Loss: 7.023657963145524e-05\n",
      "   Validation sindy_z Loss: 222.8325958251953\n",
      "   Validation sindy_x Loss: 0.8171379566192627\n",
      "   Validation sindy_regularization Loss: 0.9682646989822388\n",
      "Decoder Loss Ratio: 0.000378, Decoder SINDy Loss Ratio: 0.078039\n",
      "Epoch 103\n",
      "Epoch 103\n",
      "   Training Total Loss: 0.0001387805095873773\n",
      "   Training decoder Loss: 2.8358057534205727e-05\n",
      "   Training sindy_z Loss: 229.21470642089844\n",
      "   Training sindy_x Loss: 1.0074636936187744\n",
      "   Training sindy_regularization Loss: 0.9676092863082886\n",
      "   Validation Total Loss: 0.0001193366915686056\n",
      "   Validation decoder Loss: 2.8646465580095537e-05\n",
      "   Validation sindy_z Loss: 221.2161102294922\n",
      "   Validation sindy_x Loss: 0.810141384601593\n",
      "   Validation sindy_regularization Loss: 0.9676092863082886\n",
      "Decoder Loss Ratio: 0.000154, Decoder SINDy Loss Ratio: 0.077371\n",
      "Epoch 104\n",
      "Epoch 104\n",
      "   Training Total Loss: 0.0001640880072955042\n",
      "   Training decoder Loss: 5.401991802500561e-05\n",
      "   Training sindy_z Loss: 230.35740661621094\n",
      "   Training sindy_x Loss: 1.0039736032485962\n",
      "   Training sindy_regularization Loss: 0.9670736193656921\n",
      "   Validation Total Loss: 0.00014596286928281188\n",
      "   Validation decoder Loss: 5.507117384695448e-05\n",
      "   Validation sindy_z Loss: 222.4432830810547\n",
      "   Validation sindy_x Loss: 0.8122096657752991\n",
      "   Validation sindy_regularization Loss: 0.9670736193656921\n",
      "Decoder Loss Ratio: 0.000297, Decoder SINDy Loss Ratio: 0.077568\n",
      "Epoch 105\n",
      "Epoch 105\n",
      "   Training Total Loss: 0.00015374980284832418\n",
      "   Training decoder Loss: 4.3834210373461246e-05\n",
      "   Training sindy_z Loss: 231.2273406982422\n",
      "   Training sindy_x Loss: 1.0025126934051514\n",
      "   Training sindy_regularization Loss: 0.9664328098297119\n",
      "   Validation Total Loss: 0.0001353431143797934\n",
      "   Validation decoder Loss: 4.503460513660684e-05\n",
      "   Validation sindy_z Loss: 223.21231079101562\n",
      "   Validation sindy_x Loss: 0.8064417243003845\n",
      "   Validation sindy_regularization Loss: 0.9664328098297119\n",
      "Decoder Loss Ratio: 0.000243, Decoder SINDy Loss Ratio: 0.077017\n",
      "Epoch 106\n",
      "Epoch 106\n",
      "   Training Total Loss: 0.00018233017181046307\n",
      "   Training decoder Loss: 7.2696348070167e-05\n",
      "   Training sindy_z Loss: 231.30516052246094\n",
      "   Training sindy_x Loss: 0.9997576475143433\n",
      "   Training sindy_regularization Loss: 0.9658069610595703\n",
      "   Validation Total Loss: 0.00016458967002108693\n",
      "   Validation decoder Loss: 7.420606561936438e-05\n",
      "   Validation sindy_z Loss: 223.13597106933594\n",
      "   Validation sindy_x Loss: 0.8072554469108582\n",
      "   Validation sindy_regularization Loss: 0.9658069610595703\n",
      "Decoder Loss Ratio: 0.000400, Decoder SINDy Loss Ratio: 0.077095\n",
      "Epoch 107\n",
      "Epoch 107\n",
      "   Training Total Loss: 0.00013827373913954943\n",
      "   Training decoder Loss: 2.8655524147325195e-05\n",
      "   Training sindy_z Loss: 232.80311584472656\n",
      "   Training sindy_x Loss: 0.9996882081031799\n",
      "   Training sindy_regularization Loss: 0.9649384617805481\n",
      "   Validation Total Loss: 0.00011831631854875013\n",
      "   Validation decoder Loss: 2.9133707357686944e-05\n",
      "   Validation sindy_z Loss: 224.44039916992188\n",
      "   Validation sindy_x Loss: 0.7953323125839233\n",
      "   Validation sindy_regularization Loss: 0.9649384617805481\n",
      "Decoder Loss Ratio: 0.000157, Decoder SINDy Loss Ratio: 0.075956\n",
      "Epoch 108\n",
      "Epoch 108\n",
      "   Training Total Loss: 0.00013742280134465545\n",
      "   Training decoder Loss: 2.7677770049194805e-05\n",
      "   Training sindy_z Loss: 232.36070251464844\n",
      "   Training sindy_x Loss: 1.0010004043579102\n",
      "   Training sindy_regularization Loss: 0.9644991159439087\n",
      "   Validation Total Loss: 0.0001173899945570156\n",
      "   Validation decoder Loss: 2.8336047762422822e-05\n",
      "   Validation sindy_z Loss: 224.00868225097656\n",
      "   Validation sindy_x Loss: 0.7940895557403564\n",
      "   Validation sindy_regularization Loss: 0.9644991159439087\n",
      "Decoder Loss Ratio: 0.000153, Decoder SINDy Loss Ratio: 0.075838\n",
      "Epoch 109\n",
      "Epoch 109\n",
      "   Training Total Loss: 0.0002002267719944939\n",
      "   Training decoder Loss: 9.066124766832218e-05\n",
      "   Training sindy_z Loss: 234.0448455810547\n",
      "   Training sindy_x Loss: 0.9992637634277344\n",
      "   Training sindy_regularization Loss: 0.9639151096343994\n",
      "   Validation Total Loss: 0.00018154610006604344\n",
      "   Validation decoder Loss: 9.194797894451767e-05\n",
      "   Validation sindy_z Loss: 225.53790283203125\n",
      "   Validation sindy_x Loss: 0.7995897531509399\n",
      "   Validation sindy_regularization Loss: 0.9639151096343994\n",
      "Decoder Loss Ratio: 0.000495, Decoder SINDy Loss Ratio: 0.076363\n",
      "Epoch 110\n",
      "Epoch 110\n",
      "   Training Total Loss: 0.00013496432802639902\n",
      "   Training decoder Loss: 2.625780507514719e-05\n",
      "   Training sindy_z Loss: 232.4249267578125\n",
      "   Training sindy_x Loss: 0.9907572269439697\n",
      "   Training sindy_regularization Loss: 0.9630802273750305\n",
      "   Validation Total Loss: 0.00011513245408423245\n",
      "   Validation decoder Loss: 2.682770718820393e-05\n",
      "   Validation sindy_z Loss: 223.85704040527344\n",
      "   Validation sindy_x Loss: 0.7867395281791687\n",
      "   Validation sindy_regularization Loss: 0.9630802273750305\n",
      "Decoder Loss Ratio: 0.000145, Decoder SINDy Loss Ratio: 0.075136\n",
      "Epoch 111\n",
      "Epoch 111\n",
      "   Training Total Loss: 0.0001457537291571498\n",
      "   Training decoder Loss: 3.690567973535508e-05\n",
      "   Training sindy_z Loss: 232.41209411621094\n",
      "   Training sindy_x Loss: 0.9922138452529907\n",
      "   Training sindy_regularization Loss: 0.9626676440238953\n",
      "   Validation Total Loss: 0.0001256630348507315\n",
      "   Validation decoder Loss: 3.756903242901899e-05\n",
      "   Validation sindy_z Loss: 223.93496704101562\n",
      "   Validation sindy_x Loss: 0.7846733331680298\n",
      "   Validation sindy_regularization Loss: 0.9626676440238953\n",
      "Decoder Loss Ratio: 0.000202, Decoder SINDy Loss Ratio: 0.074938\n",
      "Epoch 112\n",
      "Epoch 112\n",
      "   Training Total Loss: 0.00013588608999270946\n",
      "   Training decoder Loss: 2.7404234060668387e-05\n",
      "   Training sindy_z Loss: 233.6249237060547\n",
      "   Training sindy_x Loss: 0.9886202216148376\n",
      "   Training sindy_regularization Loss: 0.9619833827018738\n",
      "   Validation Total Loss: 0.00011585813626879826\n",
      "   Validation decoder Loss: 2.81377142528072e-05\n",
      "   Validation sindy_z Loss: 225.08865356445312\n",
      "   Validation sindy_x Loss: 0.781005859375\n",
      "   Validation sindy_regularization Loss: 0.9619833827018738\n",
      "Decoder Loss Ratio: 0.000152, Decoder SINDy Loss Ratio: 0.074588\n",
      "Epoch 113\n",
      "Epoch 113\n",
      "   Training Total Loss: 0.00014045802527107298\n",
      "   Training decoder Loss: 3.1932904676068574e-05\n",
      "   Training sindy_z Loss: 240.13037109375\n",
      "   Training sindy_x Loss: 0.9892489910125732\n",
      "   Training sindy_regularization Loss: 0.960021436214447\n",
      "   Validation Total Loss: 0.0001196788070956245\n",
      "   Validation decoder Loss: 3.23630592902191e-05\n",
      "   Validation sindy_z Loss: 230.95936584472656\n",
      "   Validation sindy_x Loss: 0.7771553993225098\n",
      "   Validation sindy_regularization Loss: 0.960021436214447\n",
      "Decoder Loss Ratio: 0.000174, Decoder SINDy Loss Ratio: 0.074220\n",
      "Epoch 114\n",
      "Epoch 114\n",
      "   Training Total Loss: 0.00013318871788214892\n",
      "   Training decoder Loss: 2.5437962904106826e-05\n",
      "   Training sindy_z Loss: 237.89576721191406\n",
      "   Training sindy_x Loss: 0.9815890789031982\n",
      "   Training sindy_regularization Loss: 0.9591848254203796\n",
      "   Validation Total Loss: 0.00011297223682049662\n",
      "   Validation decoder Loss: 2.6082212571054697e-05\n",
      "   Validation sindy_z Loss: 228.95770263671875\n",
      "   Validation sindy_x Loss: 0.7729818224906921\n",
      "   Validation sindy_regularization Loss: 0.9591848254203796\n",
      "Decoder Loss Ratio: 0.000140, Decoder SINDy Loss Ratio: 0.073822\n",
      "Epoch 115\n",
      "Epoch 115\n",
      "   Training Total Loss: 0.00015597302990499884\n",
      "   Training decoder Loss: 4.813775740331039e-05\n",
      "   Training sindy_z Loss: 237.96604919433594\n",
      "   Training sindy_x Loss: 0.9825088977813721\n",
      "   Training sindy_regularization Loss: 0.9584389925003052\n",
      "   Validation Total Loss: 0.00013486410898622125\n",
      "   Validation decoder Loss: 4.782541873282753e-05\n",
      "   Validation sindy_z Loss: 228.8705596923828\n",
      "   Validation sindy_x Loss: 0.7745431065559387\n",
      "   Validation sindy_regularization Loss: 0.9584389925003052\n",
      "Decoder Loss Ratio: 0.000258, Decoder SINDy Loss Ratio: 0.073971\n",
      "Epoch 116\n",
      "Epoch 116\n",
      "   Training Total Loss: 0.00013987618149258196\n",
      "   Training decoder Loss: 3.287658910267055e-05\n",
      "   Training sindy_z Loss: 238.5904998779297\n",
      "   Training sindy_x Loss: 0.974250853061676\n",
      "   Training sindy_regularization Loss: 0.9574516415596008\n",
      "   Validation Total Loss: 0.00011874620395246893\n",
      "   Validation decoder Loss: 3.234820542274974e-05\n",
      "   Validation sindy_z Loss: 229.65133666992188\n",
      "   Validation sindy_x Loss: 0.7682347893714905\n",
      "   Validation sindy_regularization Loss: 0.9574516415596008\n",
      "Decoder Loss Ratio: 0.000174, Decoder SINDy Loss Ratio: 0.073368\n",
      "Epoch 117\n",
      "Epoch 117\n",
      "   Training Total Loss: 0.00014952736091800034\n",
      "   Training decoder Loss: 4.196712325210683e-05\n",
      "   Training sindy_z Loss: 242.0585479736328\n",
      "   Training sindy_x Loss: 0.9799786806106567\n",
      "   Training sindy_regularization Loss: 0.9562361836433411\n",
      "   Validation Total Loss: 0.0001296026457566768\n",
      "   Validation decoder Loss: 4.29441497544758e-05\n",
      "   Validation sindy_z Loss: 232.84042358398438\n",
      "   Validation sindy_x Loss: 0.7709614634513855\n",
      "   Validation sindy_regularization Loss: 0.9562361836433411\n",
      "Decoder Loss Ratio: 0.000231, Decoder SINDy Loss Ratio: 0.073629\n",
      "Epoch 118\n",
      "Epoch 118\n",
      "   Training Total Loss: 0.00013120545190759003\n",
      "   Training decoder Loss: 2.449238127155695e-05\n",
      "   Training sindy_z Loss: 241.49290466308594\n",
      "   Training sindy_x Loss: 0.9716453552246094\n",
      "   Training sindy_regularization Loss: 0.9548537135124207\n",
      "   Validation Total Loss: 0.00011085134610766545\n",
      "   Validation decoder Loss: 2.5227232981706038e-05\n",
      "   Validation sindy_z Loss: 232.26699829101562\n",
      "   Validation sindy_x Loss: 0.7607558369636536\n",
      "   Validation sindy_regularization Loss: 0.9548537135124207\n",
      "Decoder Loss Ratio: 0.000136, Decoder SINDy Loss Ratio: 0.072654\n",
      "Epoch 119\n",
      "Epoch 119\n",
      "   Training Total Loss: 0.00015790757606737316\n",
      "   Training decoder Loss: 5.0715847464744e-05\n",
      "   Training sindy_z Loss: 241.63531494140625\n",
      "   Training sindy_x Loss: 0.9765126705169678\n",
      "   Training sindy_regularization Loss: 0.9540465474128723\n",
      "   Validation Total Loss: 0.0001365653588436544\n",
      "   Validation decoder Loss: 5.076984234619886e-05\n",
      "   Validation sindy_z Loss: 232.37046813964844\n",
      "   Validation sindy_x Loss: 0.7625505328178406\n",
      "   Validation sindy_regularization Loss: 0.9540465474128723\n",
      "Decoder Loss Ratio: 0.000273, Decoder SINDy Loss Ratio: 0.072825\n",
      "Epoch 120\n",
      "Epoch 120\n",
      "   Training Total Loss: 0.00012924426118843257\n",
      "   Training decoder Loss: 2.2677675588056445e-05\n",
      "   Training sindy_z Loss: 242.09339904785156\n",
      "   Training sindy_x Loss: 0.9703533053398132\n",
      "   Training sindy_regularization Loss: 0.9531264901161194\n",
      "   Validation Total Loss: 0.00010891496640397236\n",
      "   Validation decoder Loss: 2.3897007849882357e-05\n",
      "   Validation sindy_z Loss: 232.87318420410156\n",
      "   Validation sindy_x Loss: 0.7548669576644897\n",
      "   Validation sindy_regularization Loss: 0.9531264901161194\n",
      "Decoder Loss Ratio: 0.000129, Decoder SINDy Loss Ratio: 0.072092\n",
      "Epoch 121\n",
      "Epoch 121\n",
      "   Training Total Loss: 0.00014012215251568705\n",
      "   Training decoder Loss: 3.313978959340602e-05\n",
      "   Training sindy_z Loss: 257.7676086425781\n",
      "   Training sindy_x Loss: 0.974816620349884\n",
      "   Training sindy_regularization Loss: 0.9500704407691956\n",
      "   Validation Total Loss: 0.00011945836740778759\n",
      "   Validation decoder Loss: 3.354288128321059e-05\n",
      "   Validation sindy_z Loss: 247.6212615966797\n",
      "   Validation sindy_x Loss: 0.7641477584838867\n",
      "   Validation sindy_regularization Loss: 0.9500704407691956\n",
      "Decoder Loss Ratio: 0.000181, Decoder SINDy Loss Ratio: 0.072978\n",
      "Epoch 122\n",
      "Epoch 122\n",
      "   Training Total Loss: 0.00012784064165316522\n",
      "   Training decoder Loss: 2.1776711946586147e-05\n",
      "   Training sindy_z Loss: 253.05763244628906\n",
      "   Training sindy_x Loss: 0.9657905101776123\n",
      "   Training sindy_regularization Loss: 0.9484876990318298\n",
      "   Validation Total Loss: 0.0001070648868335411\n",
      "   Validation decoder Loss: 2.2649177481071092e-05\n",
      "   Validation sindy_z Loss: 243.0420684814453\n",
      "   Validation sindy_x Loss: 0.7493084073066711\n",
      "   Validation sindy_regularization Loss: 0.9484876990318298\n",
      "Decoder Loss Ratio: 0.000122, Decoder SINDy Loss Ratio: 0.071561\n",
      "Epoch 123\n",
      "Epoch 123\n",
      "   Training Total Loss: 0.00012762822734657675\n",
      "   Training decoder Loss: 2.1843483409611508e-05\n",
      "   Training sindy_z Loss: 251.5655975341797\n",
      "   Training sindy_x Loss: 0.9630777835845947\n",
      "   Training sindy_regularization Loss: 0.9476959109306335\n",
      "   Validation Total Loss: 0.00010710240167099983\n",
      "   Validation decoder Loss: 2.2927690224605612e-05\n",
      "   Validation sindy_z Loss: 241.78143310546875\n",
      "   Validation sindy_x Loss: 0.7469775676727295\n",
      "   Validation sindy_regularization Loss: 0.9476959109306335\n",
      "Decoder Loss Ratio: 0.000123, Decoder SINDy Loss Ratio: 0.071338\n",
      "Epoch 124\n",
      "Epoch 124\n",
      "   Training Total Loss: 0.00013060543278697878\n",
      "   Training decoder Loss: 2.4940240109572187e-05\n",
      "   Training sindy_z Loss: 252.1591796875\n",
      "   Training sindy_x Loss: 0.9619593620300293\n",
      "   Training sindy_regularization Loss: 0.9469270706176758\n",
      "   Validation Total Loss: 0.0001100621375371702\n",
      "   Validation decoder Loss: 2.606400812510401e-05\n",
      "   Validation sindy_z Loss: 242.26341247558594\n",
      "   Validation sindy_x Loss: 0.7452885508537292\n",
      "   Validation sindy_regularization Loss: 0.9469270706176758\n",
      "Decoder Loss Ratio: 0.000140, Decoder SINDy Loss Ratio: 0.071177\n",
      "Epoch 125\n",
      "Epoch 125\n",
      "   Training Total Loss: 0.00013073033187538385\n",
      "   Training decoder Loss: 2.5177923816954717e-05\n",
      "   Training sindy_z Loss: 252.2129364013672\n",
      "   Training sindy_x Loss: 0.9609180688858032\n",
      "   Training sindy_regularization Loss: 0.9460609555244446\n",
      "   Validation Total Loss: 0.00010988614667439833\n",
      "   Validation decoder Loss: 2.6123467250727117e-05\n",
      "   Validation sindy_z Loss: 242.36439514160156\n",
      "   Validation sindy_x Loss: 0.7430207133293152\n",
      "   Validation sindy_regularization Loss: 0.9460609555244446\n",
      "Decoder Loss Ratio: 0.000141, Decoder SINDy Loss Ratio: 0.070960\n",
      "Epoch 126\n",
      "Epoch 126\n",
      "   Training Total Loss: 0.00013624224811792374\n",
      "   Training decoder Loss: 3.0279461498139426e-05\n",
      "   Training sindy_z Loss: 266.5727844238281\n",
      "   Training sindy_x Loss: 0.9651955366134644\n",
      "   Training sindy_regularization Loss: 0.9443231821060181\n",
      "   Validation Total Loss: 0.00011419095972087234\n",
      "   Validation decoder Loss: 3.064850898226723e-05\n",
      "   Validation sindy_z Loss: 256.7265625\n",
      "   Validation sindy_x Loss: 0.7409921884536743\n",
      "   Validation sindy_regularization Loss: 0.9443231821060181\n",
      "Decoder Loss Ratio: 0.000165, Decoder SINDy Loss Ratio: 0.070767\n",
      "Epoch 127\n",
      "Epoch 127\n",
      "   Training Total Loss: 0.00012497822172008455\n",
      "   Training decoder Loss: 2.0185290850349702e-05\n",
      "   Training sindy_z Loss: 263.3828430175781\n",
      "   Training sindy_x Loss: 0.9536865949630737\n",
      "   Training sindy_regularization Loss: 0.9424275755882263\n",
      "   Validation Total Loss: 0.00010388223745394498\n",
      "   Validation decoder Loss: 2.087086068058852e-05\n",
      "   Validation sindy_z Loss: 253.2669677734375\n",
      "   Validation sindy_x Loss: 0.7358710169792175\n",
      "   Validation sindy_regularization Loss: 0.9424275755882263\n",
      "Decoder Loss Ratio: 0.000112, Decoder SINDy Loss Ratio: 0.070278\n",
      "Epoch 128\n",
      "Epoch 128\n",
      "   Training Total Loss: 0.00012468337081372738\n",
      "   Training decoder Loss: 2.0150284399278462e-05\n",
      "   Training sindy_z Loss: 261.6864318847656\n",
      "   Training sindy_x Loss: 0.9511904120445251\n",
      "   Training sindy_regularization Loss: 0.9414056539535522\n",
      "   Validation Total Loss: 0.00010378922161180526\n",
      "   Validation decoder Loss: 2.0945770302205347e-05\n",
      "   Validation sindy_z Loss: 251.75390625\n",
      "   Validation sindy_x Loss: 0.7342939376831055\n",
      "   Validation sindy_regularization Loss: 0.9414056539535522\n",
      "Decoder Loss Ratio: 0.000113, Decoder SINDy Loss Ratio: 0.070127\n",
      "Epoch 129\n",
      "Epoch 129\n",
      "   Training Total Loss: 0.00012397865066304803\n",
      "   Training decoder Loss: 1.9927658286178485e-05\n",
      "   Training sindy_z Loss: 260.477294921875\n",
      "   Training sindy_x Loss: 0.9464493989944458\n",
      "   Training sindy_regularization Loss: 0.9406051635742188\n",
      "   Validation Total Loss: 0.0001032695799949579\n",
      "   Validation decoder Loss: 2.0619385395548306e-05\n",
      "   Validation sindy_z Loss: 250.49867248535156\n",
      "   Validation sindy_x Loss: 0.7324414253234863\n",
      "   Validation sindy_regularization Loss: 0.9406051635742188\n",
      "Decoder Loss Ratio: 0.000111, Decoder SINDy Loss Ratio: 0.069950\n",
      "Epoch 130\n",
      "Epoch 130\n",
      "   Training Total Loss: 0.0001344513293588534\n",
      "   Training decoder Loss: 2.9495846320060082e-05\n",
      "   Training sindy_z Loss: 273.8192138671875\n",
      "   Training sindy_x Loss: 0.9557569026947021\n",
      "   Training sindy_regularization Loss: 0.9379784464836121\n",
      "   Validation Total Loss: 0.00011274819553364068\n",
      "   Validation decoder Loss: 2.9494878617697395e-05\n",
      "   Validation sindy_z Loss: 262.9272766113281\n",
      "   Validation sindy_x Loss: 0.7387353777885437\n",
      "   Validation sindy_regularization Loss: 0.9379784464836121\n",
      "Decoder Loss Ratio: 0.000159, Decoder SINDy Loss Ratio: 0.070551\n",
      "Epoch 131\n",
      "Epoch 131\n",
      "   Training Total Loss: 0.00012309165322221816\n",
      "   Training decoder Loss: 1.9085489839199e-05\n",
      "   Training sindy_z Loss: 269.7195739746094\n",
      "   Training sindy_x Loss: 0.9464067816734314\n",
      "   Training sindy_regularization Loss: 0.9365492463111877\n",
      "   Validation Total Loss: 0.00010208573075942695\n",
      "   Validation decoder Loss: 1.9894105207640678e-05\n",
      "   Validation sindy_z Loss: 259.0737609863281\n",
      "   Validation sindy_x Loss: 0.728261411190033\n",
      "   Validation sindy_regularization Loss: 0.9365492463111877\n",
      "Decoder Loss Ratio: 0.000107, Decoder SINDy Loss Ratio: 0.069551\n",
      "Epoch 132\n",
      "Epoch 132\n",
      "   Training Total Loss: 0.00012259886716492474\n",
      "   Training decoder Loss: 1.869801417342387e-05\n",
      "   Training sindy_z Loss: 268.7067565917969\n",
      "   Training sindy_x Loss: 0.9454342722892761\n",
      "   Training sindy_regularization Loss: 0.9357431530952454\n",
      "   Validation Total Loss: 0.0001016910609905608\n",
      "   Validation decoder Loss: 1.95934026123723e-05\n",
      "   Validation sindy_z Loss: 258.2803649902344\n",
      "   Validation sindy_x Loss: 0.7274022102355957\n",
      "   Validation sindy_regularization Loss: 0.9357431530952454\n",
      "Decoder Loss Ratio: 0.000106, Decoder SINDy Loss Ratio: 0.069469\n",
      "Epoch 133\n",
      "Epoch 133\n",
      "   Training Total Loss: 0.00012958636216353625\n",
      "   Training decoder Loss: 2.5706478481879458e-05\n",
      "   Training sindy_z Loss: 268.7906799316406\n",
      "   Training sindy_x Loss: 0.9452919363975525\n",
      "   Training sindy_regularization Loss: 0.9350693821907043\n",
      "   Validation Total Loss: 0.00010900384222622961\n",
      "   Validation decoder Loss: 2.6993009669240564e-05\n",
      "   Validation sindy_z Loss: 258.46673583984375\n",
      "   Validation sindy_x Loss: 0.7266014814376831\n",
      "   Validation sindy_regularization Loss: 0.9350693821907043\n",
      "Decoder Loss Ratio: 0.000145, Decoder SINDy Loss Ratio: 0.069392\n",
      "Epoch 134\n",
      "Epoch 134\n",
      "   Training Total Loss: 0.00012390919437166303\n",
      "   Training decoder Loss: 2.0690004021162167e-05\n",
      "   Training sindy_z Loss: 269.91546630859375\n",
      "   Training sindy_x Loss: 0.9387295246124268\n",
      "   Training sindy_regularization Loss: 0.9346243739128113\n",
      "   Validation Total Loss: 0.00010338445281377062\n",
      "   Validation decoder Loss: 2.1794834538013674e-05\n",
      "   Validation sindy_z Loss: 259.7905578613281\n",
      "   Validation sindy_x Loss: 0.7224338054656982\n",
      "   Validation sindy_regularization Loss: 0.9346243739128113\n",
      "Decoder Loss Ratio: 0.000117, Decoder SINDy Loss Ratio: 0.068994\n",
      "Epoch 135\n",
      "Epoch 135\n",
      "   Training Total Loss: 0.00012182576028862968\n",
      "   Training decoder Loss: 1.9016228179680184e-05\n",
      "   Training sindy_z Loss: 275.5699768066406\n",
      "   Training sindy_x Loss: 0.9347201585769653\n",
      "   Training sindy_regularization Loss: 0.9337520003318787\n",
      "   Validation Total Loss: 0.0001013732107821852\n",
      "   Validation decoder Loss: 2.0167082766420208e-05\n",
      "   Validation sindy_z Loss: 265.354736328125\n",
      "   Validation sindy_x Loss: 0.7186861038208008\n",
      "   Validation sindy_regularization Loss: 0.9337520003318787\n",
      "Decoder Loss Ratio: 0.000109, Decoder SINDy Loss Ratio: 0.068636\n",
      "Epoch 136\n",
      "Epoch 136\n",
      "   Training Total Loss: 0.00012145818618591875\n",
      "   Training decoder Loss: 1.8310616724193096e-05\n",
      "   Training sindy_z Loss: 275.96923828125\n",
      "   Training sindy_x Loss: 0.9381378889083862\n",
      "   Training sindy_regularization Loss: 0.9333780407905579\n",
      "   Validation Total Loss: 0.00010012761049438268\n",
      "   Validation decoder Loss: 1.8904889657278545e-05\n",
      "   Validation sindy_z Loss: 265.84423828125\n",
      "   Validation sindy_x Loss: 0.7188894748687744\n",
      "   Validation sindy_regularization Loss: 0.9333780407905579\n",
      "Decoder Loss Ratio: 0.000102, Decoder SINDy Loss Ratio: 0.068656\n",
      "Epoch 137\n",
      "Epoch 137\n",
      "   Training Total Loss: 0.00014883093535900116\n",
      "   Training decoder Loss: 4.5394623157335445e-05\n",
      "   Training sindy_z Loss: 276.7850646972656\n",
      "   Training sindy_x Loss: 0.9410464763641357\n",
      "   Training sindy_regularization Loss: 0.9331656098365784\n",
      "   Validation Total Loss: 0.00012734693882521242\n",
      "   Validation decoder Loss: 4.53983448096551e-05\n",
      "   Validation sindy_z Loss: 266.5240783691406\n",
      "   Validation sindy_x Loss: 0.7261694073677063\n",
      "   Validation sindy_regularization Loss: 0.9331656098365784\n",
      "Decoder Loss Ratio: 0.000245, Decoder SINDy Loss Ratio: 0.069351\n",
      "Epoch 138\n",
      "Epoch 138\n",
      "   Training Total Loss: 0.00012073039397364482\n",
      "   Training decoder Loss: 1.8428239854983985e-05\n",
      "   Training sindy_z Loss: 276.39520263671875\n",
      "   Training sindy_x Loss: 0.9297642707824707\n",
      "   Training sindy_regularization Loss: 0.9325727820396423\n",
      "   Validation Total Loss: 0.00010006081720348448\n",
      "   Validation decoder Loss: 1.9340961443958804e-05\n",
      "   Validation sindy_z Loss: 266.0798034667969\n",
      "   Validation sindy_x Loss: 0.7139413356781006\n",
      "   Validation sindy_regularization Loss: 0.9325727820396423\n",
      "Decoder Loss Ratio: 0.000104, Decoder SINDy Loss Ratio: 0.068183\n",
      "Epoch 139\n",
      "Epoch 139\n",
      "   Training Total Loss: 0.00013037373719271272\n",
      "   Training decoder Loss: 2.7623209462035447e-05\n",
      "   Training sindy_z Loss: 278.4747619628906\n",
      "   Training sindy_x Loss: 0.9342658519744873\n",
      "   Training sindy_regularization Loss: 0.9323949217796326\n",
      "   Validation Total Loss: 0.00011032885231543332\n",
      "   Validation decoder Loss: 2.9548007660196163e-05\n",
      "   Validation sindy_z Loss: 267.9889221191406\n",
      "   Validation sindy_x Loss: 0.7145689725875854\n",
      "   Validation sindy_regularization Loss: 0.9323949217796326\n",
      "Decoder Loss Ratio: 0.000159, Decoder SINDy Loss Ratio: 0.068243\n",
      "Epoch 140\n",
      "Epoch 140\n",
      "   Training Total Loss: 0.00012530654203146696\n",
      "   Training decoder Loss: 2.316771679033991e-05\n",
      "   Training sindy_z Loss: 278.5380859375\n",
      "   Training sindy_x Loss: 0.9281766414642334\n",
      "   Training sindy_regularization Loss: 0.9321162104606628\n",
      "   Validation Total Loss: 0.00010398432641522959\n",
      "   Validation decoder Loss: 2.3552896891487762e-05\n",
      "   Validation sindy_z Loss: 268.0669860839844\n",
      "   Validation sindy_x Loss: 0.7111026644706726\n",
      "   Validation sindy_regularization Loss: 0.9321162104606628\n",
      "Decoder Loss Ratio: 0.000127, Decoder SINDy Loss Ratio: 0.067912\n",
      "Epoch 141\n",
      "Epoch 141\n",
      "   Training Total Loss: 0.00012725590204354376\n",
      "   Training decoder Loss: 2.4354772904189304e-05\n",
      "   Training sindy_z Loss: 296.115966796875\n",
      "   Training sindy_x Loss: 0.9359387159347534\n",
      "   Training sindy_regularization Loss: 0.9307258129119873\n",
      "   Validation Total Loss: 0.00010560670489212498\n",
      "   Validation decoder Loss: 2.4994738851091824e-05\n",
      "   Validation sindy_z Loss: 285.2780456542969\n",
      "   Validation sindy_x Loss: 0.7130470871925354\n",
      "   Validation sindy_regularization Loss: 0.9307258129119873\n",
      "Decoder Loss Ratio: 0.000135, Decoder SINDy Loss Ratio: 0.068098\n",
      "Epoch 142\n",
      "Epoch 142\n",
      "   Training Total Loss: 0.0001182675187010318\n",
      "   Training decoder Loss: 1.624468495720066e-05\n",
      "   Training sindy_z Loss: 291.3180236816406\n",
      "   Training sindy_x Loss: 0.9272856712341309\n",
      "   Training sindy_regularization Loss: 0.9294263124465942\n",
      "   Validation Total Loss: 9.720020170789212e-05\n",
      "   Validation decoder Loss: 1.7172311345348135e-05\n",
      "   Validation sindy_z Loss: 280.4911193847656\n",
      "   Validation sindy_x Loss: 0.7073363065719604\n",
      "   Validation sindy_regularization Loss: 0.9294263124465942\n",
      "Decoder Loss Ratio: 0.000092, Decoder SINDy Loss Ratio: 0.067552\n",
      "Epoch 143\n",
      "Epoch 143\n",
      "   Training Total Loss: 0.00011763210204662755\n",
      "   Training decoder Loss: 1.6069961930043064e-05\n",
      "   Training sindy_z Loss: 289.2416076660156\n",
      "   Training sindy_x Loss: 0.9227253198623657\n",
      "   Training sindy_regularization Loss: 0.9289607405662537\n",
      "   Validation Total Loss: 9.672515443526208e-05\n",
      "   Validation decoder Loss: 1.6857888113008812e-05\n",
      "   Validation sindy_z Loss: 278.6557922363281\n",
      "   Validation sindy_x Loss: 0.705776572227478\n",
      "   Validation sindy_regularization Loss: 0.9289607405662537\n",
      "Decoder Loss Ratio: 0.000091, Decoder SINDy Loss Ratio: 0.067403\n",
      "Epoch 144\n",
      "Epoch 144\n",
      "   Training Total Loss: 0.00011880921374540776\n",
      "   Training decoder Loss: 1.708647505438421e-05\n",
      "   Training sindy_z Loss: 290.18603515625\n",
      "   Training sindy_x Loss: 0.9243813753128052\n",
      "   Training sindy_regularization Loss: 0.928460419178009\n",
      "   Validation Total Loss: 9.776609658729285e-05\n",
      "   Validation decoder Loss: 1.788954068615567e-05\n",
      "   Validation sindy_z Loss: 279.6143798828125\n",
      "   Validation sindy_x Loss: 0.7059195041656494\n",
      "   Validation sindy_regularization Loss: 0.928460419178009\n",
      "Decoder Loss Ratio: 0.000096, Decoder SINDy Loss Ratio: 0.067417\n",
      "Epoch 145\n",
      "Epoch 145\n",
      "   Training Total Loss: 0.00012135305587435141\n",
      "   Training decoder Loss: 1.9647519366117194e-05\n",
      "   Training sindy_z Loss: 291.8980407714844\n",
      "   Training sindy_x Loss: 0.9242871999740601\n",
      "   Training sindy_regularization Loss: 0.9276822209358215\n",
      "   Validation Total Loss: 0.00010084348468808457\n",
      "   Validation decoder Loss: 2.1015519450884312e-05\n",
      "   Validation sindy_z Loss: 281.2526550292969\n",
      "   Validation sindy_x Loss: 0.7055114507675171\n",
      "   Validation sindy_regularization Loss: 0.9276822209358215\n",
      "Decoder Loss Ratio: 0.000113, Decoder SINDy Loss Ratio: 0.067378\n",
      "Epoch 146\n",
      "Epoch 146\n",
      "   Training Total Loss: 0.0001203315332531929\n",
      "   Training decoder Loss: 1.928025812958367e-05\n",
      "   Training sindy_z Loss: 292.02215576171875\n",
      "   Training sindy_x Loss: 0.9178164005279541\n",
      "   Training sindy_regularization Loss: 0.9269644618034363\n",
      "   Validation Total Loss: 9.95942173176445e-05\n",
      "   Validation decoder Loss: 2.018466875597369e-05\n",
      "   Validation sindy_z Loss: 281.43817138671875\n",
      "   Validation sindy_x Loss: 0.7013990879058838\n",
      "   Validation sindy_regularization Loss: 0.9269644618034363\n",
      "Decoder Loss Ratio: 0.000109, Decoder SINDy Loss Ratio: 0.066985\n",
      "Epoch 147\n",
      "Epoch 147\n",
      "   Training Total Loss: 0.0001400825713062659\n",
      "   Training decoder Loss: 3.79177181457635e-05\n",
      "   Training sindy_z Loss: 299.83056640625\n",
      "   Training sindy_x Loss: 0.9290310144424438\n",
      "   Training sindy_regularization Loss: 0.9261761903762817\n",
      "   Validation Total Loss: 0.0001196510493173264\n",
      "   Validation decoder Loss: 3.961270340369083e-05\n",
      "   Validation sindy_z Loss: 288.8843688964844\n",
      "   Validation sindy_x Loss: 0.7077658772468567\n",
      "   Validation sindy_regularization Loss: 0.9261761903762817\n",
      "Decoder Loss Ratio: 0.000213, Decoder SINDy Loss Ratio: 0.067593\n",
      "Epoch 148\n",
      "Epoch 148\n",
      "   Training Total Loss: 0.00011447805445641279\n",
      "   Training decoder Loss: 1.3766055417363532e-05\n",
      "   Training sindy_z Loss: 296.9360656738281\n",
      "   Training sindy_x Loss: 0.9146076440811157\n",
      "   Training sindy_regularization Loss: 0.9251245260238647\n",
      "   Validation Total Loss: 9.368205792270601e-05\n",
      "   Validation decoder Loss: 1.463089392927941e-05\n",
      "   Validation sindy_z Loss: 286.2159118652344\n",
      "   Validation sindy_x Loss: 0.6979992389678955\n",
      "   Validation sindy_regularization Loss: 0.9251245260238647\n",
      "Decoder Loss Ratio: 0.000079, Decoder SINDy Loss Ratio: 0.066661\n",
      "Epoch 149\n",
      "Epoch 149\n",
      "   Training Total Loss: 0.00011602931772358716\n",
      "   Training decoder Loss: 1.5163421267061494e-05\n",
      "   Training sindy_z Loss: 297.5643615722656\n",
      "   Training sindy_x Loss: 0.9162054061889648\n",
      "   Training sindy_regularization Loss: 0.92453533411026\n",
      "   Validation Total Loss: 9.488189243711531e-05\n",
      "   Validation decoder Loss: 1.5885356333456002e-05\n",
      "   Validation sindy_z Loss: 286.87786865234375\n",
      "   Validation sindy_x Loss: 0.6975117921829224\n",
      "   Validation sindy_regularization Loss: 0.92453533411026\n",
      "Decoder Loss Ratio: 0.000086, Decoder SINDy Loss Ratio: 0.066614\n",
      "Epoch 150\n",
      "Epoch 150\n",
      "   Training Total Loss: 0.00012821833661291748\n",
      "   Training decoder Loss: 2.6822030122275464e-05\n",
      "   Training sindy_z Loss: 317.218017578125\n",
      "   Training sindy_x Loss: 0.9216917753219604\n",
      "   Training sindy_regularization Loss: 0.9227125644683838\n",
      "   Validation Total Loss: 0.00010609124728944153\n",
      "   Validation decoder Loss: 2.682723970792722e-05\n",
      "   Validation sindy_z Loss: 306.4677734375\n",
      "   Validation sindy_x Loss: 0.7003688216209412\n",
      "   Validation sindy_regularization Loss: 0.9227125644683838\n",
      "Decoder Loss Ratio: 0.000144, Decoder SINDy Loss Ratio: 0.066887\n",
      "Epoch 151\n",
      "Epoch 151\n",
      "   Training Total Loss: 0.00011397382331779227\n",
      "   Training decoder Loss: 1.3638444215757772e-05\n",
      "   Training sindy_z Loss: 313.2114562988281\n",
      "   Training sindy_x Loss: 0.9112731218338013\n",
      "   Training sindy_regularization Loss: 0.9208065271377563\n",
      "   Validation Total Loss: 9.294328629039228e-05\n",
      "   Validation decoder Loss: 1.442469238099875e-05\n",
      "   Validation sindy_z Loss: 302.057861328125\n",
      "   Validation sindy_x Loss: 0.6931052803993225\n",
      "   Validation sindy_regularization Loss: 0.9208065271377563\n",
      "Decoder Loss Ratio: 0.000078, Decoder SINDy Loss Ratio: 0.066193\n",
      "Epoch 152\n",
      "Epoch 152\n",
      "   Training Total Loss: 0.00011422118404880166\n",
      "   Training decoder Loss: 1.4042909242562018e-05\n",
      "   Training sindy_z Loss: 311.4466552734375\n",
      "   Training sindy_x Loss: 0.9097911715507507\n",
      "   Training sindy_regularization Loss: 0.9199158549308777\n",
      "   Validation Total Loss: 9.33500487008132e-05\n",
      "   Validation decoder Loss: 1.4912572623870801e-05\n",
      "   Validation sindy_z Loss: 300.4654541015625\n",
      "   Validation sindy_x Loss: 0.6923832297325134\n",
      "   Validation sindy_regularization Loss: 0.9199158549308777\n",
      "Decoder Loss Ratio: 0.000080, Decoder SINDy Loss Ratio: 0.066124\n",
      "Epoch 153\n",
      "Epoch 153\n",
      "   Training Total Loss: 0.00011777230247389525\n",
      "   Training decoder Loss: 1.796394462871831e-05\n",
      "   Training sindy_z Loss: 309.6053161621094\n",
      "   Training sindy_x Loss: 0.9061447381973267\n",
      "   Training sindy_regularization Loss: 0.9193887710571289\n",
      "   Validation Total Loss: 9.71913177636452e-05\n",
      "   Validation decoder Loss: 1.8855238522519358e-05\n",
      "   Validation sindy_z Loss: 298.79278564453125\n",
      "   Validation sindy_x Loss: 0.6914219856262207\n",
      "   Validation sindy_regularization Loss: 0.9193887710571289\n",
      "Decoder Loss Ratio: 0.000102, Decoder SINDy Loss Ratio: 0.066033\n",
      "Epoch 154\n",
      "Epoch 154\n",
      "   Training Total Loss: 0.00012504153710324317\n",
      "   Training decoder Loss: 2.4708377168281004e-05\n",
      "   Training sindy_z Loss: 312.3592834472656\n",
      "   Training sindy_x Loss: 0.9114916324615479\n",
      "   Training sindy_regularization Loss: 0.9184009432792664\n",
      "   Validation Total Loss: 0.00010394366836408153\n",
      "   Validation decoder Loss: 2.5530291168252006e-05\n",
      "   Validation sindy_z Loss: 301.5412902832031\n",
      "   Validation sindy_x Loss: 0.6922937035560608\n",
      "   Validation sindy_regularization Loss: 0.9184009432792664\n",
      "Decoder Loss Ratio: 0.000138, Decoder SINDy Loss Ratio: 0.066116\n",
      "Epoch 155\n",
      "Epoch 155\n",
      "   Training Total Loss: 0.00011501671542646363\n",
      "   Training decoder Loss: 1.5359897588496096e-05\n",
      "   Training sindy_z Loss: 313.5261535644531\n",
      "   Training sindy_x Loss: 0.9048436880111694\n",
      "   Training sindy_regularization Loss: 0.9172449111938477\n",
      "   Validation Total Loss: 9.460650471737608e-05\n",
      "   Validation decoder Loss: 1.654782499826979e-05\n",
      "   Validation sindy_z Loss: 302.7195739746094\n",
      "   Validation sindy_x Loss: 0.6888623237609863\n",
      "   Validation sindy_regularization Loss: 0.9172449111938477\n",
      "Decoder Loss Ratio: 0.000089, Decoder SINDy Loss Ratio: 0.065788\n",
      "Epoch 156\n",
      "Epoch 156\n",
      "   Training Total Loss: 0.00015437994443345815\n",
      "   Training decoder Loss: 5.334365414455533e-05\n",
      "   Training sindy_z Loss: 316.76568603515625\n",
      "   Training sindy_x Loss: 0.9187389612197876\n",
      "   Training sindy_regularization Loss: 0.9162396192550659\n",
      "   Validation Total Loss: 0.00013625975407194346\n",
      "   Validation decoder Loss: 5.745710586779751e-05\n",
      "   Validation sindy_z Loss: 305.8196716308594\n",
      "   Validation sindy_x Loss: 0.6964026093482971\n",
      "   Validation sindy_regularization Loss: 0.9162396192550659\n",
      "Decoder Loss Ratio: 0.000309, Decoder SINDy Loss Ratio: 0.066508\n",
      "Epoch 157\n",
      "Epoch 157\n",
      "   Training Total Loss: 0.00011554016964510083\n",
      "   Training decoder Loss: 1.5919342331471853e-05\n",
      "   Training sindy_z Loss: 320.4106140136719\n",
      "   Training sindy_x Loss: 0.9047266244888306\n",
      "   Training sindy_regularization Loss: 0.9148160815238953\n",
      "   Validation Total Loss: 9.455232793698087e-05\n",
      "   Validation decoder Loss: 1.6778731151134707e-05\n",
      "   Validation sindy_z Loss: 309.6263427734375\n",
      "   Validation sindy_x Loss: 0.6862543821334839\n",
      "   Validation sindy_regularization Loss: 0.9148160815238953\n",
      "Decoder Loss Ratio: 0.000090, Decoder SINDy Loss Ratio: 0.065539\n",
      "Epoch 158\n",
      "Epoch 158\n",
      "   Training Total Loss: 0.00011347858526278287\n",
      "   Training decoder Loss: 1.4236896276997868e-05\n",
      "   Training sindy_z Loss: 320.3927001953125\n",
      "   Training sindy_x Loss: 0.9010632038116455\n",
      "   Training sindy_regularization Loss: 0.913537323474884\n",
      "   Validation Total Loss: 9.274156764149666e-05\n",
      "   Validation decoder Loss: 1.5118014744075481e-05\n",
      "   Validation sindy_z Loss: 309.62677001953125\n",
      "   Validation sindy_x Loss: 0.6848818063735962\n",
      "   Validation sindy_regularization Loss: 0.913537323474884\n",
      "Decoder Loss Ratio: 0.000081, Decoder SINDy Loss Ratio: 0.065408\n",
      "Epoch 159\n",
      "Epoch 159\n",
      "   Training Total Loss: 0.00012028496712446213\n",
      "   Training decoder Loss: 2.0826340914936736e-05\n",
      "   Training sindy_z Loss: 321.3218078613281\n",
      "   Training sindy_x Loss: 0.9033528566360474\n",
      "   Training sindy_regularization Loss: 0.9123337864875793\n",
      "   Validation Total Loss: 9.937020513461903e-05\n",
      "   Validation decoder Loss: 2.1694324459531344e-05\n",
      "   Validation sindy_z Loss: 310.4079284667969\n",
      "   Validation sindy_x Loss: 0.6855254769325256\n",
      "   Validation sindy_regularization Loss: 0.9123337864875793\n",
      "Decoder Loss Ratio: 0.000117, Decoder SINDy Loss Ratio: 0.065469\n",
      "Epoch 160\n",
      "Epoch 160\n",
      "   Training Total Loss: 0.0001229493791470304\n",
      "   Training decoder Loss: 2.3360116756521165e-05\n",
      "   Training sindy_z Loss: 323.0286865234375\n",
      "   Training sindy_x Loss: 0.9047651290893555\n",
      "   Training sindy_regularization Loss: 0.9112747311592102\n",
      "   Validation Total Loss: 0.00010279644629918039\n",
      "   Validation decoder Loss: 2.51213841693243e-05\n",
      "   Validation sindy_z Loss: 312.1831359863281\n",
      "   Validation sindy_x Loss: 0.6856231689453125\n",
      "   Validation sindy_regularization Loss: 0.9112747311592102\n",
      "Decoder Loss Ratio: 0.000135, Decoder SINDy Loss Ratio: 0.065479\n",
      "Epoch 161\n",
      "Epoch 161\n",
      "   Training Total Loss: 0.0001237034157384187\n",
      "   Training decoder Loss: 2.4675473468960263e-05\n",
      "   Training sindy_z Loss: 325.2276306152344\n",
      "   Training sindy_x Loss: 0.8993158340454102\n",
      "   Training sindy_regularization Loss: 0.9096364378929138\n",
      "   Validation Total Loss: 0.00010344670590711758\n",
      "   Validation decoder Loss: 2.5978166377171874e-05\n",
      "   Validation sindy_z Loss: 314.197509765625\n",
      "   Validation sindy_x Loss: 0.6837217211723328\n",
      "   Validation sindy_regularization Loss: 0.9096364378929138\n",
      "Decoder Loss Ratio: 0.000140, Decoder SINDy Loss Ratio: 0.065297\n",
      "Epoch 162\n",
      "Epoch 162\n",
      "   Training Total Loss: 0.00011209293734282255\n",
      "   Training decoder Loss: 1.3499696251528803e-05\n",
      "   Training sindy_z Loss: 327.6239318847656\n",
      "   Training sindy_x Loss: 0.8951152563095093\n",
      "   Training sindy_regularization Loss: 0.9081723093986511\n",
      "   Validation Total Loss: 9.146321099251509e-05\n",
      "   Validation decoder Loss: 1.4430343981075566e-05\n",
      "   Validation sindy_z Loss: 316.7480773925781\n",
      "   Validation sindy_x Loss: 0.6795114874839783\n",
      "   Validation sindy_regularization Loss: 0.9081723093986511\n",
      "Decoder Loss Ratio: 0.000078, Decoder SINDy Loss Ratio: 0.064895\n",
      "Epoch 163\n",
      "Epoch 163\n",
      "   Training Total Loss: 0.00011567565525183454\n",
      "   Training decoder Loss: 1.6906678865780123e-05\n",
      "   Training sindy_z Loss: 328.6187744140625\n",
      "   Training sindy_x Loss: 0.8970025777816772\n",
      "   Training sindy_regularization Loss: 0.9068726301193237\n",
      "   Validation Total Loss: 9.473774116486311e-05\n",
      "   Validation decoder Loss: 1.7742730051395483e-05\n",
      "   Validation sindy_z Loss: 317.73388671875\n",
      "   Validation sindy_x Loss: 0.6792628765106201\n",
      "   Validation sindy_regularization Loss: 0.9068726301193237\n",
      "Decoder Loss Ratio: 0.000096, Decoder SINDy Loss Ratio: 0.064871\n",
      "Epoch 164\n",
      "Epoch 164\n",
      "   Training Total Loss: 0.00011612002708716318\n",
      "   Training decoder Loss: 1.735777004796546e-05\n",
      "   Training sindy_z Loss: 330.5455017089844\n",
      "   Training sindy_x Loss: 0.8970532417297363\n",
      "   Training sindy_regularization Loss: 0.9056931734085083\n",
      "   Validation Total Loss: 9.426286851521581e-05\n",
      "   Validation decoder Loss: 1.7463838958065026e-05\n",
      "   Validation sindy_z Loss: 319.7941589355469\n",
      "   Validation sindy_x Loss: 0.677420973777771\n",
      "   Validation sindy_regularization Loss: 0.9056931734085083\n",
      "Decoder Loss Ratio: 0.000094, Decoder SINDy Loss Ratio: 0.064695\n",
      "Epoch 165\n",
      "Epoch 165\n",
      "   Training Total Loss: 0.00011967960017500445\n",
      "   Training decoder Loss: 2.0961513655493036e-05\n",
      "   Training sindy_z Loss: 335.1686706542969\n",
      "   Training sindy_x Loss: 0.896762490272522\n",
      "   Training sindy_regularization Loss: 0.9041842222213745\n",
      "   Validation Total Loss: 9.875908290268853e-05\n",
      "   Validation decoder Loss: 2.2037007511244155e-05\n",
      "   Validation sindy_z Loss: 324.33203125\n",
      "   Validation sindy_x Loss: 0.676802396774292\n",
      "   Validation sindy_regularization Loss: 0.9041842222213745\n",
      "Decoder Loss Ratio: 0.000119, Decoder SINDy Loss Ratio: 0.064636\n",
      "Epoch 166\n",
      "Epoch 166\n",
      "   Training Total Loss: 0.00012107606016797945\n",
      "   Training decoder Loss: 2.2600081138079986e-05\n",
      "   Training sindy_z Loss: 337.4056091308594\n",
      "   Training sindy_x Loss: 0.894515872001648\n",
      "   Training sindy_regularization Loss: 0.9024394750595093\n",
      "   Validation Total Loss: 9.9458426120691e-05\n",
      "   Validation decoder Loss: 2.278367719554808e-05\n",
      "   Validation sindy_z Loss: 326.55548095703125\n",
      "   Validation sindy_x Loss: 0.6765035390853882\n",
      "   Validation sindy_regularization Loss: 0.9024394750595093\n",
      "Decoder Loss Ratio: 0.000123, Decoder SINDy Loss Ratio: 0.064608\n",
      "Epoch 167\n",
      "Epoch 167\n",
      "   Training Total Loss: 0.0001154820347437635\n",
      "   Training decoder Loss: 1.7485153875895776e-05\n",
      "   Training sindy_z Loss: 338.1758117675781\n",
      "   Training sindy_x Loss: 0.8898478746414185\n",
      "   Training sindy_regularization Loss: 0.9012094140052795\n",
      "   Validation Total Loss: 9.33574847294949e-05\n",
      "   Validation decoder Loss: 1.7006419511744753e-05\n",
      "   Validation sindy_z Loss: 327.5384521484375\n",
      "   Validation sindy_x Loss: 0.6733896732330322\n",
      "   Validation sindy_regularization Loss: 0.9012094140052795\n",
      "Decoder Loss Ratio: 0.000092, Decoder SINDy Loss Ratio: 0.064310\n",
      "Epoch 168\n",
      "Epoch 168\n",
      "   Training Total Loss: 0.0001150070020230487\n",
      "   Training decoder Loss: 1.733482349663973e-05\n",
      "   Training sindy_z Loss: 339.3547668457031\n",
      "   Training sindy_x Loss: 0.8867321014404297\n",
      "   Training sindy_regularization Loss: 0.8998973369598389\n",
      "   Validation Total Loss: 9.372799831908196e-05\n",
      "   Validation decoder Loss: 1.762789543136023e-05\n",
      "   Validation sindy_z Loss: 328.6535339355469\n",
      "   Validation sindy_x Loss: 0.6710113286972046\n",
      "   Validation sindy_regularization Loss: 0.8998973369598389\n",
      "Decoder Loss Ratio: 0.000095, Decoder SINDy Loss Ratio: 0.064083\n",
      "Epoch 169\n",
      "Epoch 169\n",
      "   Training Total Loss: 0.00012276302732061595\n",
      "   Training decoder Loss: 2.431990287732333e-05\n",
      "   Training sindy_z Loss: 361.0906982421875\n",
      "   Training sindy_x Loss: 0.8946326971054077\n",
      "   Training sindy_regularization Loss: 0.8979860544204712\n",
      "   Validation Total Loss: 9.924222104018554e-05\n",
      "   Validation decoder Loss: 2.2605865524383262e-05\n",
      "   Validation sindy_z Loss: 350.4819641113281\n",
      "   Validation sindy_x Loss: 0.6765648722648621\n",
      "   Validation sindy_regularization Loss: 0.8979860544204712\n",
      "Decoder Loss Ratio: 0.000122, Decoder SINDy Loss Ratio: 0.064614\n",
      "Epoch 170\n",
      "Epoch 170\n",
      "   Training Total Loss: 0.00010783097968669608\n",
      "   Training decoder Loss: 1.0341283086745534e-05\n",
      "   Training sindy_z Loss: 358.0035400390625\n",
      "   Training sindy_x Loss: 0.8853570222854614\n",
      "   Training sindy_regularization Loss: 0.8953998684883118\n",
      "   Validation Total Loss: 8.616635750513524e-05\n",
      "   Validation decoder Loss: 1.0484258382348344e-05\n",
      "   Validation sindy_z Loss: 346.825439453125\n",
      "   Validation sindy_x Loss: 0.6672810316085815\n",
      "   Validation sindy_regularization Loss: 0.8953998684883118\n",
      "Decoder Loss Ratio: 0.000056, Decoder SINDy Loss Ratio: 0.063727\n",
      "Epoch 171\n",
      "Epoch 171\n",
      "   Training Total Loss: 0.0001080975416698493\n",
      "   Training decoder Loss: 1.0729562745837029e-05\n",
      "   Training sindy_z Loss: 355.760498046875\n",
      "   Training sindy_x Loss: 0.8842488527297974\n",
      "   Training sindy_regularization Loss: 0.8943095803260803\n",
      "   Validation Total Loss: 8.664301276439801e-05\n",
      "   Validation decoder Loss: 1.1024800187442452e-05\n",
      "   Validation sindy_z Loss: 344.6687927246094\n",
      "   Validation sindy_x Loss: 0.6667511463165283\n",
      "   Validation sindy_regularization Loss: 0.8943095803260803\n",
      "Decoder Loss Ratio: 0.000059, Decoder SINDy Loss Ratio: 0.063676\n",
      "Epoch 172\n",
      "Epoch 172\n",
      "   Training Total Loss: 0.00011962423741351813\n",
      "   Training decoder Loss: 2.2359401555149816e-05\n",
      "   Training sindy_z Loss: 353.590087890625\n",
      "   Training sindy_x Loss: 0.8833134174346924\n",
      "   Training sindy_regularization Loss: 0.893349289894104\n",
      "   Validation Total Loss: 9.90457265288569e-05\n",
      "   Validation decoder Loss: 2.3486785721615888e-05\n",
      "   Validation sindy_z Loss: 342.39599609375\n",
      "   Validation sindy_x Loss: 0.6662545204162598\n",
      "   Validation sindy_regularization Loss: 0.893349289894104\n",
      "Decoder Loss Ratio: 0.000127, Decoder SINDy Loss Ratio: 0.063629\n",
      "Epoch 173\n",
      "Epoch 173\n",
      "   Training Total Loss: 0.00010836915316758677\n",
      "   Training decoder Loss: 1.129425254475791e-05\n",
      "   Training sindy_z Loss: 354.9237060546875\n",
      "   Training sindy_x Loss: 0.8815234303474426\n",
      "   Training sindy_regularization Loss: 0.8922566175460815\n",
      "   Validation Total Loss: 8.729488035896793e-05\n",
      "   Validation decoder Loss: 1.1849330803670455e-05\n",
      "   Validation sindy_z Loss: 343.6156311035156\n",
      "   Validation sindy_x Loss: 0.665229856967926\n",
      "   Validation sindy_regularization Loss: 0.8922566175460815\n",
      "Decoder Loss Ratio: 0.000064, Decoder SINDy Loss Ratio: 0.063531\n",
      "Epoch 174\n",
      "Epoch 174\n",
      "   Training Total Loss: 0.00011352504225214943\n",
      "   Training decoder Loss: 1.6436924852314405e-05\n",
      "   Training sindy_z Loss: 356.6451416015625\n",
      "   Training sindy_x Loss: 0.8817890882492065\n",
      "   Training sindy_regularization Loss: 0.8909204006195068\n",
      "   Validation Total Loss: 9.170461271423846e-05\n",
      "   Validation decoder Loss: 1.633140527701471e-05\n",
      "   Validation sindy_z Loss: 345.4390869140625\n",
      "   Validation sindy_x Loss: 0.6646400094032288\n",
      "   Validation sindy_regularization Loss: 0.8909204006195068\n",
      "Decoder Loss Ratio: 0.000088, Decoder SINDy Loss Ratio: 0.063475\n",
      "Epoch 175\n",
      "Epoch 175\n",
      "   Training Total Loss: 0.00013258469698484987\n",
      "   Training decoder Loss: 3.4824035537894815e-05\n",
      "   Training sindy_z Loss: 362.129638671875\n",
      "   Training sindy_x Loss: 0.8886497616767883\n",
      "   Training sindy_regularization Loss: 0.8895688652992249\n",
      "   Validation Total Loss: 0.0001125616327044554\n",
      "   Validation decoder Loss: 3.699470835272223e-05\n",
      "   Validation sindy_z Loss: 351.0001220703125\n",
      "   Validation sindy_x Loss: 0.6667124032974243\n",
      "   Validation sindy_regularization Loss: 0.8895688652992249\n",
      "Decoder Loss Ratio: 0.000199, Decoder SINDy Loss Ratio: 0.063673\n",
      "Epoch 176\n",
      "Epoch 176\n",
      "   Training Total Loss: 0.00012297251669224352\n",
      "   Training decoder Loss: 2.574491736595519e-05\n",
      "   Training sindy_z Loss: 361.986083984375\n",
      "   Training sindy_x Loss: 0.8834906816482544\n",
      "   Training sindy_regularization Loss: 0.8878528475761414\n",
      "   Validation Total Loss: 0.00010144976840820163\n",
      "   Validation decoder Loss: 2.6104622520506382e-05\n",
      "   Validation sindy_z Loss: 350.7515869140625\n",
      "   Validation sindy_x Loss: 0.6646661758422852\n",
      "   Validation sindy_regularization Loss: 0.8878528475761414\n",
      "Decoder Loss Ratio: 0.000141, Decoder SINDy Loss Ratio: 0.063477\n",
      "Epoch 177\n",
      "Epoch 177\n",
      "   Training Total Loss: 0.000113181427877862\n",
      "   Training decoder Loss: 1.6357093045371585e-05\n",
      "   Training sindy_z Loss: 364.4727783203125\n",
      "   Training sindy_x Loss: 0.8796160221099854\n",
      "   Training sindy_regularization Loss: 0.8862738013267517\n",
      "   Validation Total Loss: 9.20252496143803e-05\n",
      "   Validation decoder Loss: 1.7028874935931526e-05\n",
      "   Validation sindy_z Loss: 353.2840881347656\n",
      "   Validation sindy_x Loss: 0.661336362361908\n",
      "   Validation sindy_regularization Loss: 0.8862738013267517\n",
      "Decoder Loss Ratio: 0.000092, Decoder SINDy Loss Ratio: 0.063159\n",
      "Epoch 178\n",
      "Epoch 178\n",
      "   Training Total Loss: 0.00012550993415061384\n",
      "   Training decoder Loss: 2.831839447026141e-05\n",
      "   Training sindy_z Loss: 366.7544860839844\n",
      "   Training sindy_x Loss: 0.8834352493286133\n",
      "   Training sindy_regularization Loss: 0.8848013281822205\n",
      "   Validation Total Loss: 0.00010373823897680268\n",
      "   Validation decoder Loss: 2.856733772205189e-05\n",
      "   Validation sindy_z Loss: 355.2709045410156\n",
      "   Validation sindy_x Loss: 0.6632288694381714\n",
      "   Validation sindy_regularization Loss: 0.8848013281822205\n",
      "Decoder Loss Ratio: 0.000154, Decoder SINDy Loss Ratio: 0.063340\n",
      "Epoch 179\n",
      "Epoch 179\n",
      "   Training Total Loss: 0.00011713463754858822\n",
      "   Training decoder Loss: 2.0508219677140005e-05\n",
      "   Training sindy_z Loss: 366.3688659667969\n",
      "   Training sindy_x Loss: 0.8779129981994629\n",
      "   Training sindy_regularization Loss: 0.8835126161575317\n",
      "   Validation Total Loss: 9.554767166264355e-05\n",
      "   Validation decoder Loss: 2.085791311401408e-05\n",
      "   Validation sindy_z Loss: 355.281494140625\n",
      "   Validation sindy_x Loss: 0.6585463881492615\n",
      "   Validation sindy_regularization Loss: 0.8835126161575317\n",
      "Decoder Loss Ratio: 0.000112, Decoder SINDy Loss Ratio: 0.062893\n",
      "Epoch 180\n",
      "Epoch 180\n",
      "   Training Total Loss: 0.00013849370589014143\n",
      "   Training decoder Loss: 4.0568585973232985e-05\n",
      "   Training sindy_z Loss: 387.1060485839844\n",
      "   Training sindy_x Loss: 0.8910567164421082\n",
      "   Training sindy_regularization Loss: 0.8819454312324524\n",
      "   Validation Total Loss: 0.00011525295849423856\n",
      "   Validation decoder Loss: 3.88840890082065e-05\n",
      "   Validation sindy_z Loss: 375.0512390136719\n",
      "   Validation sindy_x Loss: 0.6754941940307617\n",
      "   Validation sindy_regularization Loss: 0.8819454312324524\n",
      "Decoder Loss Ratio: 0.000209, Decoder SINDy Loss Ratio: 0.064511\n",
      "Epoch 181\n",
      "Epoch 181\n",
      "   Training Total Loss: 0.00010644100257195532\n",
      "   Training decoder Loss: 1.0105903129442595e-05\n",
      "   Training sindy_z Loss: 382.4231262207031\n",
      "   Training sindy_x Loss: 0.875404953956604\n",
      "   Training sindy_regularization Loss: 0.879460334777832\n",
      "   Validation Total Loss: 8.439658267889172e-05\n",
      "   Validation decoder Loss: 1.0040722372650634e-05\n",
      "   Validation sindy_z Loss: 370.7997131347656\n",
      "   Validation sindy_x Loss: 0.6556126475334167\n",
      "   Validation sindy_regularization Loss: 0.879460334777832\n",
      "Decoder Loss Ratio: 0.000054, Decoder SINDy Loss Ratio: 0.062613\n",
      "Epoch 182\n",
      "Epoch 182\n",
      "   Training Total Loss: 0.00010606437717797235\n",
      "   Training decoder Loss: 9.9327717180131e-06\n",
      "   Training sindy_z Loss: 380.7149963378906\n",
      "   Training sindy_x Loss: 0.8734877109527588\n",
      "   Training sindy_regularization Loss: 0.8782835602760315\n",
      "   Validation Total Loss: 8.40664142742753e-05\n",
      "   Validation decoder Loss: 9.800915904634167e-06\n",
      "   Validation sindy_z Loss: 369.1626892089844\n",
      "   Validation sindy_x Loss: 0.6548265814781189\n",
      "   Validation sindy_regularization Loss: 0.8782835602760315\n",
      "Decoder Loss Ratio: 0.000053, Decoder SINDy Loss Ratio: 0.062538\n",
      "Epoch 183\n",
      "Epoch 183\n",
      "   Training Total Loss: 0.00010918053885689005\n",
      "   Training decoder Loss: 1.291356784349773e-05\n",
      "   Training sindy_z Loss: 383.7891845703125\n",
      "   Training sindy_x Loss: 0.8749431371688843\n",
      "   Training sindy_regularization Loss: 0.8772655725479126\n",
      "   Validation Total Loss: 8.695508586242795e-05\n",
      "   Validation decoder Loss: 1.2745616913889535e-05\n",
      "   Validation sindy_z Loss: 372.13775634765625\n",
      "   Validation sindy_x Loss: 0.6543681621551514\n",
      "   Validation sindy_regularization Loss: 0.8772655725479126\n",
      "Decoder Loss Ratio: 0.000069, Decoder SINDy Loss Ratio: 0.062494\n",
      "Epoch 184\n",
      "Epoch 184\n",
      "   Training Total Loss: 0.00010990781447617337\n",
      "   Training decoder Loss: 1.3855296856490895e-05\n",
      "   Training sindy_z Loss: 384.9822082519531\n",
      "   Training sindy_x Loss: 0.8729251027107239\n",
      "   Training sindy_regularization Loss: 0.876001238822937\n",
      "   Validation Total Loss: 8.786733815213665e-05\n",
      "   Validation decoder Loss: 1.37510596687207e-05\n",
      "   Validation sindy_z Loss: 373.321044921875\n",
      "   Validation sindy_x Loss: 0.6535627245903015\n",
      "   Validation sindy_regularization Loss: 0.876001238822937\n",
      "Decoder Loss Ratio: 0.000074, Decoder SINDy Loss Ratio: 0.062417\n",
      "Epoch 185\n",
      "Epoch 185\n",
      "   Training Total Loss: 0.00012046422489220276\n",
      "   Training decoder Loss: 2.4085598852252588e-05\n",
      "   Training sindy_z Loss: 389.750732421875\n",
      "   Training sindy_x Loss: 0.876318097114563\n",
      "   Training sindy_regularization Loss: 0.8746815323829651\n",
      "   Validation Total Loss: 9.821941057452932e-05\n",
      "   Validation decoder Loss: 2.4073742679320276e-05\n",
      "   Validation sindy_z Loss: 378.0712585449219\n",
      "   Validation sindy_x Loss: 0.6539885401725769\n",
      "   Validation sindy_regularization Loss: 0.8746815323829651\n",
      "Decoder Loss Ratio: 0.000130, Decoder SINDy Loss Ratio: 0.062458\n",
      "Epoch 186\n",
      "Epoch 186\n",
      "   Training Total Loss: 0.00012101413449272513\n",
      "   Training decoder Loss: 2.4868357286322862e-05\n",
      "   Training sindy_z Loss: 388.2810363769531\n",
      "   Training sindy_x Loss: 0.8741470575332642\n",
      "   Training sindy_regularization Loss: 0.8731078505516052\n",
      "   Validation Total Loss: 9.92034183582291e-05\n",
      "   Validation decoder Loss: 2.5171935703838244e-05\n",
      "   Validation sindy_z Loss: 376.5437316894531\n",
      "   Validation sindy_x Loss: 0.6530041098594666\n",
      "   Validation sindy_regularization Loss: 0.8731078505516052\n",
      "Decoder Loss Ratio: 0.000136, Decoder SINDy Loss Ratio: 0.062364\n",
      "Epoch 187\n",
      "Epoch 187\n",
      "   Training Total Loss: 0.00011726843513315544\n",
      "   Training decoder Loss: 2.1407697204267606e-05\n",
      "   Training sindy_z Loss: 390.3782653808594\n",
      "   Training sindy_x Loss: 0.8714231252670288\n",
      "   Training sindy_regularization Loss: 0.8718421459197998\n",
      "   Validation Total Loss: 9.458913700655103e-05\n",
      "   Validation decoder Loss: 2.0723884517792612e-05\n",
      "   Validation sindy_z Loss: 378.7508544921875\n",
      "   Validation sindy_x Loss: 0.6514683365821838\n",
      "   Validation sindy_regularization Loss: 0.8718421459197998\n",
      "Decoder Loss Ratio: 0.000112, Decoder SINDy Loss Ratio: 0.062217\n",
      "Epoch 188\n",
      "Epoch 188\n",
      "   Training Total Loss: 0.00011816849291790277\n",
      "   Training decoder Loss: 2.163683166145347e-05\n",
      "   Training sindy_z Loss: 402.7790832519531\n",
      "   Training sindy_x Loss: 0.8782880306243896\n",
      "   Training sindy_regularization Loss: 0.8702862858772278\n",
      "   Validation Total Loss: 9.605468949303031e-05\n",
      "   Validation decoder Loss: 2.17805354623124e-05\n",
      "   Validation sindy_z Loss: 390.8930358886719\n",
      "   Validation sindy_x Loss: 0.6557129621505737\n",
      "   Validation sindy_regularization Loss: 0.8702862858772278\n",
      "Decoder Loss Ratio: 0.000117, Decoder SINDy Loss Ratio: 0.062622\n",
      "Epoch 189\n",
      "Epoch 189\n",
      "   Training Total Loss: 0.0001060702561517246\n",
      "   Training decoder Loss: 1.0605854185996577e-05\n",
      "   Training sindy_z Loss: 398.0338439941406\n",
      "   Training sindy_x Loss: 0.8678148984909058\n",
      "   Training sindy_regularization Loss: 0.8682918548583984\n",
      "   Validation Total Loss: 8.38396736071445e-05\n",
      "   Validation decoder Loss: 1.0340800145058893e-05\n",
      "   Validation sindy_z Loss: 386.3059997558594\n",
      "   Validation sindy_x Loss: 0.6481595635414124\n",
      "   Validation sindy_regularization Loss: 0.8682918548583984\n",
      "Decoder Loss Ratio: 0.000056, Decoder SINDy Loss Ratio: 0.061901\n",
      "Epoch 190\n",
      "Epoch 190\n",
      "   Training Total Loss: 0.0001087463169824332\n",
      "   Training decoder Loss: 1.3095374015392736e-05\n",
      "   Training sindy_z Loss: 400.8671569824219\n",
      "   Training sindy_x Loss: 0.8697962760925293\n",
      "   Training sindy_regularization Loss: 0.8671309351921082\n",
      "   Validation Total Loss: 8.637661812826991e-05\n",
      "   Validation decoder Loss: 1.2886798685940448e-05\n",
      "   Validation sindy_z Loss: 388.9312438964844\n",
      "   Validation sindy_x Loss: 0.648185133934021\n",
      "   Validation sindy_regularization Loss: 0.8671309351921082\n",
      "Decoder Loss Ratio: 0.000069, Decoder SINDy Loss Ratio: 0.061903\n",
      "Epoch 191\n",
      "Epoch 191\n",
      "   Training Total Loss: 0.00011344681115588173\n",
      "   Training decoder Loss: 1.76318808371434e-05\n",
      "   Training sindy_z Loss: 409.2691345214844\n",
      "   Training sindy_x Loss: 0.8715821504592896\n",
      "   Training sindy_regularization Loss: 0.8656718730926514\n",
      "   Validation Total Loss: 9.203449008055031e-05\n",
      "   Validation decoder Loss: 1.8362981791142374e-05\n",
      "   Validation sindy_z Loss: 397.2845764160156\n",
      "   Validation sindy_x Loss: 0.6501479744911194\n",
      "   Validation sindy_regularization Loss: 0.8656718730926514\n",
      "Decoder Loss Ratio: 0.000099, Decoder SINDy Loss Ratio: 0.062091\n",
      "Epoch 192\n",
      "Epoch 192\n",
      "   Training Total Loss: 0.00011005342821590602\n",
      "   Training decoder Loss: 1.4727158486493863e-05\n",
      "   Training sindy_z Loss: 405.2165222167969\n",
      "   Training sindy_x Loss: 0.8668659329414368\n",
      "   Training sindy_regularization Loss: 0.863968014717102\n",
      "   Validation Total Loss: 8.77970815054141e-05\n",
      "   Validation decoder Loss: 1.4558556358679198e-05\n",
      "   Validation sindy_z Loss: 393.2998962402344\n",
      "   Validation sindy_x Loss: 0.645988404750824\n",
      "   Validation sindy_regularization Loss: 0.863968014717102\n",
      "Decoder Loss Ratio: 0.000078, Decoder SINDy Loss Ratio: 0.061693\n",
      "Epoch 193\n",
      "Epoch 193\n",
      "   Training Total Loss: 0.00010628779273247346\n",
      "   Training decoder Loss: 1.1048157830373384e-05\n",
      "   Training sindy_z Loss: 407.8424072265625\n",
      "   Training sindy_x Loss: 0.866115927696228\n",
      "   Training sindy_regularization Loss: 0.862805187702179\n",
      "   Validation Total Loss: 8.410849113715813e-05\n",
      "   Validation decoder Loss: 1.0885562005569227e-05\n",
      "   Validation sindy_z Loss: 395.5950622558594\n",
      "   Validation sindy_x Loss: 0.6459488272666931\n",
      "   Validation sindy_regularization Loss: 0.862805187702179\n",
      "Decoder Loss Ratio: 0.000059, Decoder SINDy Loss Ratio: 0.061690\n",
      "Epoch 194\n",
      "Epoch 194\n",
      "   Training Total Loss: 0.00010755644325399771\n",
      "   Training decoder Loss: 1.2476830306695774e-05\n",
      "   Training sindy_z Loss: 408.5360107421875\n",
      "   Training sindy_x Loss: 0.8646513223648071\n",
      "   Training sindy_regularization Loss: 0.8614479303359985\n",
      "   Validation Total Loss: 8.535305823897943e-05\n",
      "   Validation decoder Loss: 1.224138577526901e-05\n",
      "   Validation sindy_z Loss: 396.24176025390625\n",
      "   Validation sindy_x Loss: 0.6449719667434692\n",
      "   Validation sindy_regularization Loss: 0.8614479303359985\n",
      "Decoder Loss Ratio: 0.000066, Decoder SINDy Loss Ratio: 0.061596\n",
      "Epoch 195\n",
      "Epoch 195\n",
      "   Training Total Loss: 0.0001087884302251041\n",
      "   Training decoder Loss: 1.3679515177500434e-05\n",
      "   Training sindy_z Loss: 421.6491394042969\n",
      "   Training sindy_x Loss: 0.865117073059082\n",
      "   Training sindy_regularization Loss: 0.8597215414047241\n",
      "   Validation Total Loss: 8.667726069688797e-05\n",
      "   Validation decoder Loss: 1.3563588254328351e-05\n",
      "   Validation sindy_z Loss: 409.3411865234375\n",
      "   Validation sindy_x Loss: 0.6451646685600281\n",
      "   Validation sindy_regularization Loss: 0.8597215414047241\n",
      "Decoder Loss Ratio: 0.000073, Decoder SINDy Loss Ratio: 0.061615\n",
      "Epoch 196\n",
      "Epoch 196\n",
      "   Training Total Loss: 0.00011035127681680024\n",
      "   Training decoder Loss: 1.5335277566919103e-05\n",
      "   Training sindy_z Loss: 418.69189453125\n",
      "   Training sindy_x Loss: 0.8643685579299927\n",
      "   Training sindy_regularization Loss: 0.8579142093658447\n",
      "   Validation Total Loss: 8.806811820250005e-05\n",
      "   Validation decoder Loss: 1.5238456398947164e-05\n",
      "   Validation sindy_z Loss: 406.5317077636719\n",
      "   Validation sindy_x Loss: 0.6425052881240845\n",
      "   Validation sindy_regularization Loss: 0.8579142093658447\n",
      "Decoder Loss Ratio: 0.000082, Decoder SINDy Loss Ratio: 0.061361\n",
      "Epoch 197\n",
      "Epoch 197\n",
      "   Training Total Loss: 0.00010765887418529019\n",
      "   Training decoder Loss: 1.2692158634308726e-05\n",
      "   Training sindy_z Loss: 417.6576232910156\n",
      "   Training sindy_x Loss: 0.863986611366272\n",
      "   Training sindy_regularization Loss: 0.8568059206008911\n",
      "   Validation Total Loss: 8.571065700380132e-05\n",
      "   Validation decoder Loss: 1.2945040907652583e-05\n",
      "   Validation sindy_z Loss: 405.28912353515625\n",
      "   Validation sindy_x Loss: 0.6419755816459656\n",
      "   Validation sindy_regularization Loss: 0.8568059206008911\n",
      "Decoder Loss Ratio: 0.000070, Decoder SINDy Loss Ratio: 0.061310\n",
      "Epoch 198\n",
      "Epoch 198\n",
      "   Training Total Loss: 0.00017429025319870561\n",
      "   Training decoder Loss: 7.694576925132424e-05\n",
      "   Training sindy_z Loss: 439.1666259765625\n",
      "   Training sindy_x Loss: 0.8879749774932861\n",
      "   Training sindy_regularization Loss: 0.8546992540359497\n",
      "   Validation Total Loss: 0.00014783903316129\n",
      "   Validation decoder Loss: 7.197094964794815e-05\n",
      "   Validation sindy_z Loss: 426.14813232421875\n",
      "   Validation sindy_x Loss: 0.673210859298706\n",
      "   Validation sindy_regularization Loss: 0.8546992540359497\n",
      "Decoder Loss Ratio: 0.000388, Decoder SINDy Loss Ratio: 0.064293\n",
      "Epoch 199\n",
      "Epoch 199\n",
      "   Training Total Loss: 0.00010337748244637623\n",
      "   Training decoder Loss: 8.65846777742263e-06\n",
      "   Training sindy_z Loss: 435.20751953125\n",
      "   Training sindy_x Loss: 0.8619606494903564\n",
      "   Training sindy_regularization Loss: 0.8522946834564209\n",
      "   Validation Total Loss: 8.066921873250976e-05\n",
      "   Validation decoder Loss: 8.217103641072754e-06\n",
      "   Validation sindy_z Loss: 422.58807373046875\n",
      "   Validation sindy_x Loss: 0.6392917037010193\n",
      "   Validation sindy_regularization Loss: 0.8522946834564209\n",
      "Decoder Loss Ratio: 0.000044, Decoder SINDy Loss Ratio: 0.061054\n",
      "Epoch 200\n",
      "Epoch 200\n",
      "   Training Total Loss: 0.00010548474529059604\n",
      "   Training decoder Loss: 1.0888186807278544e-05\n",
      "   Training sindy_z Loss: 434.0492858886719\n",
      "   Training sindy_x Loss: 0.8608434200286865\n",
      "   Training sindy_regularization Loss: 0.8512216210365295\n",
      "   Validation Total Loss: 8.306997187901288e-05\n",
      "   Validation decoder Loss: 1.0666995876817964e-05\n",
      "   Validation sindy_z Loss: 421.3780212402344\n",
      "   Validation sindy_x Loss: 0.6389076113700867\n",
      "   Validation sindy_regularization Loss: 0.8512216210365295\n",
      "Decoder Loss Ratio: 0.000057, Decoder SINDy Loss Ratio: 0.061017\n",
      "Epoch 201\n",
      "Epoch 201\n",
      "   Training Total Loss: 0.00010447696695337072\n",
      "   Training decoder Loss: 9.98954965325538e-06\n",
      "   Training sindy_z Loss: 433.7244567871094\n",
      "   Training sindy_x Loss: 0.8598392009735107\n",
      "   Training sindy_regularization Loss: 0.8503499627113342\n",
      "   Validation Total Loss: 8.239309681812301e-05\n",
      "   Validation decoder Loss: 1.0057036888611037e-05\n",
      "   Validation sindy_z Loss: 421.0470275878906\n",
      "   Validation sindy_x Loss: 0.638325572013855\n",
      "   Validation sindy_regularization Loss: 0.8503499627113342\n",
      "Decoder Loss Ratio: 0.000054, Decoder SINDy Loss Ratio: 0.060962\n",
      "Epoch 202\n",
      "Epoch 202\n",
      "   Training Total Loss: 0.0001324033655691892\n",
      "   Training decoder Loss: 3.751180338440463e-05\n",
      "   Training sindy_z Loss: 441.7094421386719\n",
      "   Training sindy_x Loss: 0.8640183210372925\n",
      "   Training sindy_regularization Loss: 0.848972737789154\n",
      "   Validation Total Loss: 0.00011288315727142617\n",
      "   Validation decoder Loss: 4.048524351674132e-05\n",
      "   Validation sindy_z Loss: 429.52490234375\n",
      "   Validation sindy_x Loss: 0.6390819549560547\n",
      "   Validation sindy_regularization Loss: 0.848972737789154\n",
      "Decoder Loss Ratio: 0.000218, Decoder SINDy Loss Ratio: 0.061034\n",
      "Epoch 203\n",
      "Epoch 203\n",
      "   Training Total Loss: 0.0001056671972037293\n",
      "   Training decoder Loss: 1.1326956155244261e-05\n",
      "   Training sindy_z Loss: 440.2707824707031\n",
      "   Training sindy_x Loss: 0.8586717844009399\n",
      "   Training sindy_regularization Loss: 0.8473060727119446\n",
      "   Validation Total Loss: 8.345062815351412e-05\n",
      "   Validation decoder Loss: 1.1307387467240915e-05\n",
      "   Validation sindy_z Loss: 427.6957702636719\n",
      "   Validation sindy_x Loss: 0.636701762676239\n",
      "   Validation sindy_regularization Loss: 0.8473060727119446\n",
      "Decoder Loss Ratio: 0.000061, Decoder SINDy Loss Ratio: 0.060807\n",
      "Epoch 204\n",
      "Epoch 204\n",
      "   Training Total Loss: 0.00010455378651386127\n",
      "   Training decoder Loss: 1.0450108675286174e-05\n",
      "   Training sindy_z Loss: 449.803466796875\n",
      "   Training sindy_x Loss: 0.8564639091491699\n",
      "   Training sindy_regularization Loss: 0.8457289338111877\n",
      "   Validation Total Loss: 8.249788515968248e-05\n",
      "   Validation decoder Loss: 1.0494420166651253e-05\n",
      "   Validation sindy_z Loss: 437.0104675292969\n",
      "   Validation sindy_x Loss: 0.6354618072509766\n",
      "   Validation sindy_regularization Loss: 0.8457289338111877\n",
      "Decoder Loss Ratio: 0.000057, Decoder SINDy Loss Ratio: 0.060688\n",
      "Epoch 205\n",
      "Epoch 205\n",
      "   Training Total Loss: 0.00011317148891976103\n",
      "   Training decoder Loss: 1.8864793673856184e-05\n",
      "   Training sindy_z Loss: 446.7720642089844\n",
      "   Training sindy_x Loss: 0.8586325645446777\n",
      "   Training sindy_regularization Loss: 0.8443438410758972\n",
      "   Validation Total Loss: 9.105868957703933e-05\n",
      "   Validation decoder Loss: 1.904125565488357e-05\n",
      "   Validation sindy_z Loss: 434.00164794921875\n",
      "   Validation sindy_x Loss: 0.6357400417327881\n",
      "   Validation sindy_regularization Loss: 0.8443438410758972\n",
      "Decoder Loss Ratio: 0.000103, Decoder SINDy Loss Ratio: 0.060715\n",
      "Epoch 206\n",
      "Epoch 206\n",
      "   Training Total Loss: 0.00011270342656644061\n",
      "   Training decoder Loss: 1.831575900723692e-05\n",
      "   Training sindy_z Loss: 452.1189880371094\n",
      "   Training sindy_x Loss: 0.8595844507217407\n",
      "   Training sindy_regularization Loss: 0.8429227471351624\n",
      "   Validation Total Loss: 9.052074165083468e-05\n",
      "   Validation decoder Loss: 1.8583619748824276e-05\n",
      "   Validation sindy_z Loss: 439.0928039550781\n",
      "   Validation sindy_x Loss: 0.6350789666175842\n",
      "   Validation sindy_regularization Loss: 0.8429227471351624\n",
      "Decoder Loss Ratio: 0.000100, Decoder SINDy Loss Ratio: 0.060652\n",
      "Epoch 207\n",
      "Epoch 207\n",
      "   Training Total Loss: 0.00011734113650163636\n",
      "   Training decoder Loss: 2.315949313924648e-05\n",
      "   Training sindy_z Loss: 456.678955078125\n",
      "   Training sindy_x Loss: 0.8576949834823608\n",
      "   Training sindy_regularization Loss: 0.8412147760391235\n",
      "   Validation Total Loss: 9.483025496592745e-05\n",
      "   Validation decoder Loss: 2.286531889694743e-05\n",
      "   Validation sindy_z Loss: 443.82427978515625\n",
      "   Validation sindy_x Loss: 0.6355278491973877\n",
      "   Validation sindy_regularization Loss: 0.8412147760391235\n",
      "Decoder Loss Ratio: 0.000123, Decoder SINDy Loss Ratio: 0.060694\n",
      "Epoch 208\n",
      "Epoch 208\n",
      "   Training Total Loss: 0.00010546201519900933\n",
      "   Training decoder Loss: 1.147511738963658e-05\n",
      "   Training sindy_z Loss: 458.9488220214844\n",
      "   Training sindy_x Loss: 0.855900764465332\n",
      "   Training sindy_regularization Loss: 0.8396825194358826\n",
      "   Validation Total Loss: 8.396180055569857e-05\n",
      "   Validation decoder Loss: 1.2223802514199633e-05\n",
      "   Validation sindy_z Loss: 445.91571044921875\n",
      "   Validation sindy_x Loss: 0.633411705493927\n",
      "   Validation sindy_regularization Loss: 0.8396825194358826\n",
      "Decoder Loss Ratio: 0.000066, Decoder SINDy Loss Ratio: 0.060492\n",
      "Epoch 209\n",
      "Epoch 209\n",
      "   Training Total Loss: 0.0001123541223932989\n",
      "   Training decoder Loss: 1.821136538637802e-05\n",
      "   Training sindy_z Loss: 463.7110900878906\n",
      "   Training sindy_x Loss: 0.8576023578643799\n",
      "   Training sindy_regularization Loss: 0.8382519483566284\n",
      "   Validation Total Loss: 9.129112731898203e-05\n",
      "   Validation decoder Loss: 1.947452074091416e-05\n",
      "   Validation sindy_z Loss: 450.44775390625\n",
      "   Validation sindy_x Loss: 0.6343408226966858\n",
      "   Validation sindy_regularization Loss: 0.8382519483566284\n",
      "Decoder Loss Ratio: 0.000105, Decoder SINDy Loss Ratio: 0.060581\n",
      "Epoch 210\n",
      "Epoch 210\n",
      "   Training Total Loss: 0.00010744571773102507\n",
      "   Training decoder Loss: 1.3565502740675583e-05\n",
      "   Training sindy_z Loss: 467.1740417480469\n",
      "   Training sindy_x Loss: 0.8551275730133057\n",
      "   Training sindy_regularization Loss: 0.8367461562156677\n",
      "   Validation Total Loss: 8.567316399421543e-05\n",
      "   Validation decoder Loss: 1.4089610886003356e-05\n",
      "   Validation sindy_z Loss: 454.24444580078125\n",
      "   Validation sindy_x Loss: 0.6321609616279602\n",
      "   Validation sindy_regularization Loss: 0.8367461562156677\n",
      "Decoder Loss Ratio: 0.000076, Decoder SINDy Loss Ratio: 0.060373\n",
      "Epoch 211\n",
      "Epoch 211\n",
      "   Training Total Loss: 0.00010208819003310055\n",
      "   Training decoder Loss: 8.303106369567104e-06\n",
      "   Training sindy_z Loss: 474.9986877441406\n",
      "   Training sindy_x Loss: 0.8543350100517273\n",
      "   Training sindy_regularization Loss: 0.8351582288742065\n",
      "   Validation Total Loss: 7.927857950562611e-05\n",
      "   Validation decoder Loss: 7.966689736349508e-06\n",
      "   Validation sindy_z Loss: 461.9535217285156\n",
      "   Validation sindy_x Loss: 0.6296030282974243\n",
      "   Validation sindy_regularization Loss: 0.8351582288742065\n",
      "Decoder Loss Ratio: 0.000043, Decoder SINDy Loss Ratio: 0.060129\n",
      "Epoch 212\n",
      "Epoch 212\n",
      "   Training Total Loss: 0.000108244305010885\n",
      "   Training decoder Loss: 1.4622090020566247e-05\n",
      "   Training sindy_z Loss: 472.2133483886719\n",
      "   Training sindy_x Loss: 0.8528454303741455\n",
      "   Training sindy_regularization Loss: 0.8337675929069519\n",
      "   Validation Total Loss: 8.610873919678852e-05\n",
      "   Validation decoder Loss: 1.484593940404011e-05\n",
      "   Validation sindy_z Loss: 459.04486083984375\n",
      "   Validation sindy_x Loss: 0.6292513012886047\n",
      "   Validation sindy_regularization Loss: 0.8337675929069519\n",
      "Decoder Loss Ratio: 0.000080, Decoder SINDy Loss Ratio: 0.060095\n",
      "Epoch 213\n",
      "Epoch 213\n",
      "   Training Total Loss: 0.00012154533033026382\n",
      "   Training decoder Loss: 2.7568694349611178e-05\n",
      "   Training sindy_z Loss: 476.84912109375\n",
      "   Training sindy_x Loss: 0.856522798538208\n",
      "   Training sindy_regularization Loss: 0.8324357271194458\n",
      "   Validation Total Loss: 0.00010028045653598383\n",
      "   Validation decoder Loss: 2.8762060537701473e-05\n",
      "   Validation sindy_z Loss: 464.4070129394531\n",
      "   Validation sindy_x Loss: 0.6319404244422913\n",
      "   Validation sindy_regularization Loss: 0.8324357271194458\n",
      "Decoder Loss Ratio: 0.000155, Decoder SINDy Loss Ratio: 0.060352\n",
      "Epoch 214\n",
      "Epoch 214\n",
      "   Training Total Loss: 0.00011708775855368003\n",
      "   Training decoder Loss: 2.334645250812173e-05\n",
      "   Training sindy_z Loss: 481.366455078125\n",
      "   Training sindy_x Loss: 0.8543363809585571\n",
      "   Training sindy_regularization Loss: 0.8307667374610901\n",
      "   Validation Total Loss: 9.632683213567361e-05\n",
      "   Validation decoder Loss: 2.5208830265910365e-05\n",
      "   Validation sindy_z Loss: 468.1485290527344\n",
      "   Validation sindy_x Loss: 0.6281033754348755\n",
      "   Validation sindy_regularization Loss: 0.8307667374610901\n",
      "Decoder Loss Ratio: 0.000136, Decoder SINDy Loss Ratio: 0.059985\n",
      "Epoch 215\n",
      "Epoch 215\n",
      "   Training Total Loss: 0.00011427269782871008\n",
      "   Training decoder Loss: 2.0304931240389124e-05\n",
      "   Training sindy_z Loss: 491.4378662109375\n",
      "   Training sindy_x Loss: 0.8567746877670288\n",
      "   Training sindy_regularization Loss: 0.8290300369262695\n",
      "   Validation Total Loss: 9.100109309656546e-05\n",
      "   Validation decoder Loss: 1.974405131477397e-05\n",
      "   Validation sindy_z Loss: 478.1458740234375\n",
      "   Validation sindy_x Loss: 0.6296674013137817\n",
      "   Validation sindy_regularization Loss: 0.8290300369262695\n",
      "Decoder Loss Ratio: 0.000106, Decoder SINDy Loss Ratio: 0.060135\n",
      "Epoch 216\n",
      "Epoch 216\n",
      "   Training Total Loss: 0.00010678497346816584\n",
      "   Training decoder Loss: 1.3502991350833327e-05\n",
      "   Training sindy_z Loss: 488.7071533203125\n",
      "   Training sindy_x Loss: 0.8500665426254272\n",
      "   Training sindy_regularization Loss: 0.8275333046913147\n",
      "   Validation Total Loss: 8.432789036305621e-05\n",
      "   Validation decoder Loss: 1.3553941244026646e-05\n",
      "   Validation sindy_z Loss: 475.24713134765625\n",
      "   Validation sindy_x Loss: 0.6249861121177673\n",
      "   Validation sindy_regularization Loss: 0.8275333046913147\n",
      "Decoder Loss Ratio: 0.000073, Decoder SINDy Loss Ratio: 0.059688\n",
      "Epoch 217\n",
      "Epoch 217\n",
      "   Training Total Loss: 0.00011230292147956789\n",
      "   Training decoder Loss: 1.9018169041373767e-05\n",
      "   Training sindy_z Loss: 492.1005554199219\n",
      "   Training sindy_x Loss: 0.850216269493103\n",
      "   Training sindy_regularization Loss: 0.8263131380081177\n",
      "   Validation Total Loss: 8.971869829110801e-05\n",
      "   Validation decoder Loss: 1.9099934434052557e-05\n",
      "   Validation sindy_z Loss: 478.8790588378906\n",
      "   Validation sindy_x Loss: 0.6235563158988953\n",
      "   Validation sindy_regularization Loss: 0.8263131380081177\n",
      "Decoder Loss Ratio: 0.000103, Decoder SINDy Loss Ratio: 0.059551\n",
      "Epoch 218\n",
      "Epoch 218\n",
      "   Training Total Loss: 0.00010637497325660661\n",
      "   Training decoder Loss: 1.2992290066904388e-05\n",
      "   Training sindy_z Loss: 506.4796142578125\n",
      "   Training sindy_x Loss: 0.8513597249984741\n",
      "   Training sindy_regularization Loss: 0.824670672416687\n",
      "   Validation Total Loss: 8.442002581432462e-05\n",
      "   Validation decoder Loss: 1.3600340935226995e-05\n",
      "   Validation sindy_z Loss: 493.74273681640625\n",
      "   Validation sindy_x Loss: 0.6257297396659851\n",
      "   Validation sindy_regularization Loss: 0.824670672416687\n",
      "Decoder Loss Ratio: 0.000073, Decoder SINDy Loss Ratio: 0.059759\n",
      "Epoch 219\n",
      "Epoch 219\n",
      "   Training Total Loss: 0.00010689035116229206\n",
      "   Training decoder Loss: 1.3751891856372822e-05\n",
      "   Training sindy_z Loss: 501.9249267578125\n",
      "   Training sindy_x Loss: 0.8490653038024902\n",
      "   Training sindy_regularization Loss: 0.8231930136680603\n",
      "   Validation Total Loss: 8.474414062220603e-05\n",
      "   Validation decoder Loss: 1.4274348359322175e-05\n",
      "   Validation sindy_z Loss: 488.9804992675781\n",
      "   Validation sindy_x Loss: 0.6223786473274231\n",
      "   Validation sindy_regularization Loss: 0.8231930136680603\n",
      "Decoder Loss Ratio: 0.000077, Decoder SINDy Loss Ratio: 0.059439\n",
      "Epoch 220\n",
      "Epoch 220\n",
      "   Training Total Loss: 0.00011784269736381248\n",
      "   Training decoder Loss: 2.456874426570721e-05\n",
      "   Training sindy_z Loss: 506.0428771972656\n",
      "   Training sindy_x Loss: 0.8505588173866272\n",
      "   Training sindy_regularization Loss: 0.821806788444519\n",
      "   Validation Total Loss: 9.587188833393157e-05\n",
      "   Validation decoder Loss: 2.5295468731201254e-05\n",
      "   Validation sindy_z Loss: 492.6640930175781\n",
      "   Validation sindy_x Loss: 0.6235834956169128\n",
      "   Validation sindy_regularization Loss: 0.821806788444519\n",
      "Decoder Loss Ratio: 0.000136, Decoder SINDy Loss Ratio: 0.059554\n",
      "Epoch 221\n",
      "Epoch 221\n",
      "   Training Total Loss: 0.00011938240641029552\n",
      "   Training decoder Loss: 2.603126449685078e-05\n",
      "   Training sindy_z Loss: 512.4451904296875\n",
      "   Training sindy_x Loss: 0.8515150547027588\n",
      "   Training sindy_regularization Loss: 0.8199635148048401\n",
      "   Validation Total Loss: 9.860005957307294e-05\n",
      "   Validation decoder Loss: 2.7979409424006008e-05\n",
      "   Validation sindy_z Loss: 498.7315979003906\n",
      "   Validation sindy_x Loss: 0.6242101788520813\n",
      "   Validation sindy_regularization Loss: 0.8199635148048401\n",
      "Decoder Loss Ratio: 0.000151, Decoder SINDy Loss Ratio: 0.059614\n",
      "Epoch 222\n",
      "Epoch 222\n",
      "   Training Total Loss: 0.000105303741293028\n",
      "   Training decoder Loss: 1.2483773389249109e-05\n",
      "   Training sindy_z Loss: 512.447998046875\n",
      "   Training sindy_x Loss: 0.8463377952575684\n",
      "   Training sindy_regularization Loss: 0.8186189532279968\n",
      "   Validation Total Loss: 8.309587428811938e-05\n",
      "   Validation decoder Loss: 1.3031212802161463e-05\n",
      "   Validation sindy_z Loss: 499.130615234375\n",
      "   Validation sindy_x Loss: 0.6187847852706909\n",
      "   Validation sindy_regularization Loss: 0.8186189532279968\n",
      "Decoder Loss Ratio: 0.000070, Decoder SINDy Loss Ratio: 0.059095\n",
      "Epoch 223\n",
      "Epoch 223\n",
      "   Training Total Loss: 0.00010358999134041369\n",
      "   Training decoder Loss: 1.0892050340771675e-05\n",
      "   Training sindy_z Loss: 516.43603515625\n",
      "   Training sindy_x Loss: 0.8452467918395996\n",
      "   Training sindy_regularization Loss: 0.8173268437385559\n",
      "   Validation Total Loss: 8.072502532741055e-05\n",
      "   Validation decoder Loss: 1.0662388376658782e-05\n",
      "   Validation sindy_z Loss: 502.9541015625\n",
      "   Validation sindy_x Loss: 0.6188936829566956\n",
      "   Validation sindy_regularization Loss: 0.8173268437385559\n",
      "Decoder Loss Ratio: 0.000057, Decoder SINDy Loss Ratio: 0.059106\n",
      "Epoch 224\n",
      "Epoch 224\n",
      "   Training Total Loss: 0.00011374642053851858\n",
      "   Training decoder Loss: 2.083215440507047e-05\n",
      "   Training sindy_z Loss: 527.4902954101562\n",
      "   Training sindy_x Loss: 0.8475712537765503\n",
      "   Training sindy_regularization Loss: 0.815714418888092\n",
      "   Validation Total Loss: 9.179504559142515e-05\n",
      "   Validation decoder Loss: 2.177036185457837e-05\n",
      "   Validation sindy_z Loss: 514.1304931640625\n",
      "   Validation sindy_x Loss: 0.6186754107475281\n",
      "   Validation sindy_regularization Loss: 0.815714418888092\n",
      "Decoder Loss Ratio: 0.000117, Decoder SINDy Loss Ratio: 0.059085\n",
      "Epoch 225\n",
      "Epoch 225\n",
      "   Training Total Loss: 0.00010944595851469785\n",
      "   Training decoder Loss: 1.682447145867627e-05\n",
      "   Training sindy_z Loss: 526.658935546875\n",
      "   Training sindy_x Loss: 0.8448175191879272\n",
      "   Training sindy_regularization Loss: 0.8139738440513611\n",
      "   Validation Total Loss: 8.685630018590018e-05\n",
      "   Validation decoder Loss: 1.7117712559411302e-05\n",
      "   Validation sindy_z Loss: 513.19775390625\n",
      "   Validation sindy_x Loss: 0.615988552570343\n",
      "   Validation sindy_regularization Loss: 0.8139738440513611\n",
      "Decoder Loss Ratio: 0.000092, Decoder SINDy Loss Ratio: 0.058828\n",
      "Epoch 226\n",
      "Epoch 226\n",
      "   Training Total Loss: 0.00010986418055836111\n",
      "   Training decoder Loss: 1.72201034729369e-05\n",
      "   Training sindy_z Loss: 529.8328247070312\n",
      "   Training sindy_x Loss: 0.845172643661499\n",
      "   Training sindy_regularization Loss: 0.8126816153526306\n",
      "   Validation Total Loss: 8.685127249918878e-05\n",
      "   Validation decoder Loss: 1.7197613487951458e-05\n",
      "   Validation sindy_z Loss: 516.230712890625\n",
      "   Validation sindy_x Loss: 0.6152684688568115\n",
      "   Validation sindy_regularization Loss: 0.8126816153526306\n",
      "Decoder Loss Ratio: 0.000093, Decoder SINDy Loss Ratio: 0.058760\n",
      "Epoch 227\n",
      "Epoch 227\n",
      "   Training Total Loss: 0.00010325155017198995\n",
      "   Training decoder Loss: 1.0831866347871255e-05\n",
      "   Training sindy_z Loss: 541.747802734375\n",
      "   Training sindy_x Loss: 0.8430862426757812\n",
      "   Training sindy_regularization Loss: 0.8111063241958618\n",
      "   Validation Total Loss: 8.04161827545613e-05\n",
      "   Validation decoder Loss: 1.0867554919968825e-05\n",
      "   Validation sindy_z Loss: 528.6791381835938\n",
      "   Validation sindy_x Loss: 0.6143757104873657\n",
      "   Validation sindy_regularization Loss: 0.8111063241958618\n",
      "Decoder Loss Ratio: 0.000059, Decoder SINDy Loss Ratio: 0.058674\n",
      "Epoch 228\n",
      "Epoch 228\n",
      "   Training Total Loss: 0.00010789929365273565\n",
      "   Training decoder Loss: 1.5559322491753846e-05\n",
      "   Training sindy_z Loss: 541.2046508789062\n",
      "   Training sindy_x Loss: 0.842461347579956\n",
      "   Training sindy_regularization Loss: 0.8093838095664978\n",
      "   Validation Total Loss: 8.570850332034752e-05\n",
      "   Validation decoder Loss: 1.6383384718210436e-05\n",
      "   Validation sindy_z Loss: 527.9752807617188\n",
      "   Validation sindy_x Loss: 0.6123127937316895\n",
      "   Validation sindy_regularization Loss: 0.8093838095664978\n",
      "Decoder Loss Ratio: 0.000088, Decoder SINDy Loss Ratio: 0.058477\n",
      "Epoch 229\n",
      "Epoch 229\n",
      "   Training Total Loss: 0.00011411502055125311\n",
      "   Training decoder Loss: 2.1579968233709224e-05\n",
      "   Training sindy_z Loss: 547.5516967773438\n",
      "   Training sindy_x Loss: 0.84455406665802\n",
      "   Training sindy_regularization Loss: 0.8079652786254883\n",
      "   Validation Total Loss: 9.120962931774557e-05\n",
      "   Validation decoder Loss: 2.1857762476429343e-05\n",
      "   Validation sindy_z Loss: 533.797119140625\n",
      "   Validation sindy_x Loss: 0.6127221584320068\n",
      "   Validation sindy_regularization Loss: 0.8079652786254883\n",
      "Decoder Loss Ratio: 0.000118, Decoder SINDy Loss Ratio: 0.058516\n",
      "Epoch 230\n",
      "Epoch 230\n",
      "   Training Total Loss: 0.00011270717368461192\n",
      "   Training decoder Loss: 2.0382152797537856e-05\n",
      "   Training sindy_z Loss: 547.8404541015625\n",
      "   Training sindy_x Loss: 0.8425880670547485\n",
      "   Training sindy_regularization Loss: 0.8066216111183167\n",
      "   Validation Total Loss: 8.937934035202488e-05\n",
      "   Validation decoder Loss: 2.0237437638570555e-05\n",
      "   Validation sindy_z Loss: 534.51611328125\n",
      "   Validation sindy_x Loss: 0.6107569336891174\n",
      "   Validation sindy_regularization Loss: 0.8066216111183167\n",
      "Decoder Loss Ratio: 0.000109, Decoder SINDy Loss Ratio: 0.058329\n",
      "Epoch 231\n",
      "Epoch 231\n",
      "   Training Total Loss: 0.00010819469025591388\n",
      "   Training decoder Loss: 1.6127869457704946e-05\n",
      "   Training sindy_z Loss: 551.2250366210938\n",
      "   Training sindy_x Loss: 0.8401525616645813\n",
      "   Training sindy_regularization Loss: 0.8051567673683167\n",
      "   Validation Total Loss: 8.511887426720932e-05\n",
      "   Validation decoder Loss: 1.6145273548318073e-05\n",
      "   Validation sindy_z Loss: 537.9398803710938\n",
      "   Validation sindy_x Loss: 0.6092203855514526\n",
      "   Validation sindy_regularization Loss: 0.8051567673683167\n",
      "Decoder Loss Ratio: 0.000087, Decoder SINDy Loss Ratio: 0.058182\n",
      "Epoch 232\n",
      "Epoch 232\n",
      "   Training Total Loss: 0.00010363440378569067\n",
      "   Training decoder Loss: 1.1788943083956838e-05\n",
      "   Training sindy_z Loss: 560.7783813476562\n",
      "   Training sindy_x Loss: 0.8381102085113525\n",
      "   Training sindy_regularization Loss: 0.8034436702728271\n",
      "   Validation Total Loss: 8.028923184610903e-05\n",
      "   Validation decoder Loss: 1.1613543392741121e-05\n",
      "   Validation sindy_z Loss: 547.7020263671875\n",
      "   Validation sindy_x Loss: 0.6064125299453735\n",
      "   Validation sindy_regularization Loss: 0.8034436702728271\n",
      "Decoder Loss Ratio: 0.000063, Decoder SINDy Loss Ratio: 0.057914\n",
      "Epoch 233\n",
      "Epoch 233\n",
      "   Training Total Loss: 0.00011565415479708463\n",
      "   Training decoder Loss: 2.353898344154004e-05\n",
      "   Training sindy_z Loss: 566.7145385742188\n",
      "   Training sindy_x Loss: 0.8409931659698486\n",
      "   Training sindy_regularization Loss: 0.80158531665802\n",
      "   Validation Total Loss: 9.392201900482178e-05\n",
      "   Validation decoder Loss: 2.5060138796106912e-05\n",
      "   Validation sindy_z Loss: 552.942138671875\n",
      "   Validation sindy_x Loss: 0.6084602475166321\n",
      "   Validation sindy_regularization Loss: 0.80158531665802\n",
      "Decoder Loss Ratio: 0.000135, Decoder SINDy Loss Ratio: 0.058109\n",
      "Epoch 234\n",
      "Epoch 234\n",
      "   Training Total Loss: 9.972662519430742e-05\n",
      "   Training decoder Loss: 8.084127330221236e-06\n",
      "   Training sindy_z Loss: 567.4970703125\n",
      "   Training sindy_x Loss: 0.8364022970199585\n",
      "   Training sindy_regularization Loss: 0.8002273440361023\n",
      "   Validation Total Loss: 7.6403419370763e-05\n",
      "   Validation decoder Loss: 8.015288585738745e-06\n",
      "   Validation sindy_z Loss: 554.1046752929688\n",
      "   Validation sindy_x Loss: 0.6038585901260376\n",
      "   Validation sindy_regularization Loss: 0.8002273440361023\n",
      "Decoder Loss Ratio: 0.000043, Decoder SINDy Loss Ratio: 0.057670\n",
      "Epoch 235\n",
      "Epoch 235\n",
      "   Training Total Loss: 0.00010314382961951196\n",
      "   Training decoder Loss: 1.1537249520188197e-05\n",
      "   Training sindy_z Loss: 571.4708251953125\n",
      "   Training sindy_x Loss: 0.8361676335334778\n",
      "   Training sindy_regularization Loss: 0.7989813089370728\n",
      "   Validation Total Loss: 7.974336040206254e-05\n",
      "   Validation decoder Loss: 1.141035227192333e-05\n",
      "   Validation sindy_z Loss: 558.226318359375\n",
      "   Validation sindy_x Loss: 0.6034319996833801\n",
      "   Validation sindy_regularization Loss: 0.7989813089370728\n",
      "Decoder Loss Ratio: 0.000061, Decoder SINDy Loss Ratio: 0.057629\n",
      "Epoch 236\n",
      "Epoch 236\n",
      "   Training Total Loss: 0.00010138763173017651\n",
      "   Training decoder Loss: 9.872226655716076e-06\n",
      "   Training sindy_z Loss: 575.4768676757812\n",
      "   Training sindy_x Loss: 0.8354109525680542\n",
      "   Training sindy_regularization Loss: 0.7974315285682678\n",
      "   Validation Total Loss: 7.795306737534702e-05\n",
      "   Validation decoder Loss: 9.861197213467676e-06\n",
      "   Validation sindy_z Loss: 562.142578125\n",
      "   Validation sindy_x Loss: 0.6011756062507629\n",
      "   Validation sindy_regularization Loss: 0.7974315285682678\n",
      "Decoder Loss Ratio: 0.000053, Decoder SINDy Loss Ratio: 0.057414\n",
      "Epoch 237\n",
      "Epoch 237\n",
      "   Training Total Loss: 0.00010713316441979259\n",
      "   Training decoder Loss: 1.5599822290823795e-05\n",
      "   Training sindy_z Loss: 578.8411254882812\n",
      "   Training sindy_x Loss: 0.8357482552528381\n",
      "   Training sindy_regularization Loss: 0.79585200548172\n",
      "   Validation Total Loss: 8.38259220472537e-05\n",
      "   Validation decoder Loss: 1.565836282679811e-05\n",
      "   Validation sindy_z Loss: 565.2073364257812\n",
      "   Validation sindy_x Loss: 0.6020903587341309\n",
      "   Validation sindy_regularization Loss: 0.79585200548172\n",
      "Decoder Loss Ratio: 0.000084, Decoder SINDy Loss Ratio: 0.057501\n",
      "Epoch 238\n",
      "Epoch 238\n",
      "   Training Total Loss: 0.00010671347263269126\n",
      "   Training decoder Loss: 1.526195410406217e-05\n",
      "   Training sindy_z Loss: 593.3999633789062\n",
      "   Training sindy_x Loss: 0.8351117372512817\n",
      "   Training sindy_regularization Loss: 0.7940346002578735\n",
      "   Validation Total Loss: 8.387642446905375e-05\n",
      "   Validation decoder Loss: 1.584136589372065e-05\n",
      "   Validation sindy_z Loss: 579.8560791015625\n",
      "   Validation sindy_x Loss: 0.6009471416473389\n",
      "   Validation sindy_regularization Loss: 0.7940346002578735\n",
      "Decoder Loss Ratio: 0.000085, Decoder SINDy Loss Ratio: 0.057392\n",
      "Epoch 239\n",
      "Epoch 239\n",
      "   Training Total Loss: 0.00010199975804425776\n",
      "   Training decoder Loss: 1.0814830602612346e-05\n",
      "   Training sindy_z Loss: 590.2029418945312\n",
      "   Training sindy_x Loss: 0.8325819969177246\n",
      "   Training sindy_regularization Loss: 0.7926729321479797\n",
      "   Validation Total Loss: 7.83888463047333e-05\n",
      "   Validation decoder Loss: 1.0813640983542427e-05\n",
      "   Validation sindy_z Loss: 576.95458984375\n",
      "   Validation sindy_x Loss: 0.5964848399162292\n",
      "   Validation sindy_regularization Loss: 0.7926729321479797\n",
      "Decoder Loss Ratio: 0.000058, Decoder SINDy Loss Ratio: 0.056966\n",
      "Epoch 240\n",
      "Epoch 240\n",
      "   Training Total Loss: 0.00011528792674653232\n",
      "   Training decoder Loss: 2.3958771635079756e-05\n",
      "   Training sindy_z Loss: 597.20751953125\n",
      "   Training sindy_x Loss: 0.8341537714004517\n",
      "   Training sindy_regularization Loss: 0.7913782596588135\n",
      "   Validation Total Loss: 9.101330215344205e-05\n",
      "   Validation decoder Loss: 2.3339443941949867e-05\n",
      "   Validation sindy_z Loss: 583.7423095703125\n",
      "   Validation sindy_x Loss: 0.5976007580757141\n",
      "   Validation sindy_regularization Loss: 0.7913782596588135\n",
      "Decoder Loss Ratio: 0.000126, Decoder SINDy Loss Ratio: 0.057072\n",
      "Epoch 241\n",
      "Epoch 241\n",
      "   Training Total Loss: 0.00011072734923800454\n",
      "   Training decoder Loss: 1.9641254766611382e-05\n",
      "   Training sindy_z Loss: 600.5498657226562\n",
      "   Training sindy_x Loss: 0.8318654894828796\n",
      "   Training sindy_regularization Loss: 0.7899542450904846\n",
      "   Validation Total Loss: 8.719598554307595e-05\n",
      "   Validation decoder Loss: 1.9759798306040466e-05\n",
      "   Validation sindy_z Loss: 587.63134765625\n",
      "   Validation sindy_x Loss: 0.5953664779663086\n",
      "   Validation sindy_regularization Loss: 0.7899542450904846\n",
      "Decoder Loss Ratio: 0.000106, Decoder SINDy Loss Ratio: 0.056859\n",
      "Epoch 242\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoefficient_mask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibrary_dim\u001b[39m\u001b[38;5;124m'\u001b[39m], params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatent_dim\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m      8\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlorenz_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS_\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     results_dict \u001b[38;5;241m=\u001b[39m train_network(training_data, validation_data, params)\n\u001b[0;32m     11\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresults_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams}, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m df\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_results_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ianma\\Desktop\\Study\\Python\\CS4240_DeepLearning_Group41_ReproducibilityProject\\Autoencoders-Reproduction\\examples\\../src\\training.py:34\u001b[0m, in \u001b[0;36mtrain_network\u001b[1;34m(training_data, val_data, params)\u001b[0m\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     33\u001b[0m loss_val, _, _ \u001b[38;5;241m=\u001b[39m autoencoder_network\u001b[38;5;241m.\u001b[39mdefine_loss(train_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m], train_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdx\u001b[39m\u001b[38;5;124m'\u001b[39m], params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m---> 34\u001b[0m loss_val\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#inputs, targets = inputs.to(device), targets.to(device) # Send data to device (CPU/GPU)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# optimizer.zero_grad()   # Zero the parameter gradients\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# loss.backward()         # Backward pass: compute gradient of the loss with respect to model parameters\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# optimizer.step()        \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ianma\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_experiments = 1\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_experiments):\n",
    "    print('EXPERIMENT %d' % i)\n",
    "\n",
    "    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "\n",
    "    params['save_name'] = 'lorenz_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "    \n",
    "    results_dict = train_network(training_data, validation_data, params)\n",
    "    df = df.append({**results_dict, **params}, ignore_index=True)\n",
    "\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
